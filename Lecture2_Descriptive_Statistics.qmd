---
title: "Lecture 2 – Descriptive statistics"
author: "Caspar J. van Lissa"
date: "`r format(Sys.Date(), '%d %b %Y')`"
format: revealjs
server: shiny
---

```{r setup, include = FALSE}
library(ggplot2)           # only for making figures
knitr::opts_chunk$set(
  echo = FALSE,            
  message = FALSE, warning = FALSE,
  dev = "png",
  fig.width = 6, fig.height = 4, fig.align = "center"
)
```

# Learning Objectives {.smaller .tiny data-font-size="60%"}

- **Central tendency**  
  - Calculate the mean, median, and mode.  
  - Decide which measure is most appropriate given the variable’s scale, shape, and outliers.

- **Weighted mean**  
  - Compute a weighted mean and explain when weighting is necessary (e.g., unequal group sizes).

- **Variability**  
  - Compute and interpret the range, variance, and standard deviation.  
  - *Visual intuition*: turn each deviation from the mean into a square and show how the total area (sum of squares) motivates the variance formula.

- **Effect of transformations & outliers**  
  - Predict how adding/subtracting or multiplying/dividing every score—and how extreme outliers—alter the mean and SD.

- **Degrees of freedom**  
  - Explain why the sample variance divides by **n – 1** (only *n – 1* independent pieces of information remain after estimating the mean).


---

## What Do We Mean by a *Statistical Model*? {.smaller}

A statistical model is a *story* about how data arise:

> **observed value = systematic part (signal) + random part (noise)**

Descriptive statistics give us the **first draft** of that story:  
* one number to stand in for the whole data set (**signal**), and  
* one number that tells how far scores wander from that centre (**noise**).

---

## Why Descriptive Statistics?

| Question                                 | Statistic                        |
|------------------------------------------|----------------------------------|
| What value is *typical*?                 | **Centre** → mean / median / mode |
| How much do individual scores *differ*?  | **Spread** → range / variance / SD |

Everything else in the course builds on these two headlines.

---

# Central Tendency

*A single value that stands for the whole distribution.*

> **What’s a distribution?**  
> Think of it as the **shape** (or pattern) of all the observed scores: how many low values, how many high values, and everything in between.  
>  
> *Example:* a class-quiz histogram might show most students clustering around 7/10, a few scoring 10, and a long tail of lower marks.

Our goal is to find **one number**—mean, median, or mode—that represents that entire pattern as faithfully as possible.

---

## Mean — The Balance Point {.smaller}

**Definition**  
The mean is **the sum of the scores divided by the number of scores**.

$$
\text{Population:}\quad
\mu = \frac{\sum_{i=1}^{N} X_i}{N}
\qquad
\text{Sample:}\quad
M = \frac{\sum_{i=1}^{n} X_i}{n}
$$

**Key properties**

| Situation                                   | Effect on Mean |
|---------------------------------------------|----------------|
| Add a constant $k$ to every score           | $+k$           |
| Multiply every score by $c$                 | $\times c$     |
| Change one score by $\Delta$                | $+\Delta/n$    |
| Add / remove a score equal to the mean      | No change      |

---

## Mean — Example {.smaller}

Suppose five exam scores: 4, 6, 7, 3, 10  

**Compute the mean**

$$
M = \frac{4 + 6 + 7 + 3 + 10}{5} = \frac{30}{5} = 6
$$

**Check the key properties**

| Operation                                   | New scores                | Predicted mean             | Verified mean |
|---------------------------------------------|---------------------------|----------------------------|---------------|
| Add $k = 2$ to every score                  | 6, 8, 9, 5, 12            | $6 + 2 = 8$                | 8             |
| Multiply every score by $c = 3$             | 12, 18, 21, 9, 30         | $6 \times 3 = 18$          | 18            |
| Change one score by $\Delta = +3$ (10 → 13) | 4, 6, 7, 3, 13            | $6 + \tfrac{3}{5} = 6.6$   | 6.6           |
| Add a new score equal to the mean (6)       | 4, 6, 7, 3, 10, 6         | —                          | 6             |

---

---

## Combining Means – Two Groups {.smaller}

Suppose you have **two sub-samples** with equal or unequal sizes:

| Group | Size $n$ | Mean $M$ | Sum of scores $\sum X$ |
|-------|---------:|---------:|-----------------------:|
| A | $n_{A}$ | $M_{A}$ | $n_{A} M_{A}$ |
| B | $n_{B}$ | $M_{B}$ | $n_{B} M_{B}$ |

**Overall mean** is simply

$$
M_{\text{overall}} \;=\;
\frac{\sum X_{\text{total}}}{n_{\text{total}}}
=
\frac{\,n_{A} M_{A} + n_{B} M_{B}\,}{\,n_{A} + n_{B}\,}
$$

*Same logic you use for a single mean—just add up **all** scores and divide by **all** people.*

---

## Weighted Mean – Unequal Group Sizes {.smaller}

When groups **differ in size**, the larger group should influence the overall mean more.  
The previous expression is therefore called a **weighted mean**—weights are the group sizes.

**Formula (two groups)**

$$
M_{\text{overall}}
= \frac{n_{A} M_{A} + n_{B} M_{B}}{n_{A} + n_{B}}
$$

*Numerical example*  
Group A: $n_{A}=12$, $M_{A}=6$  Group B: $n_{B}=8$, $M_{B}=7$

$$
M_{\text{overall}}
= \frac{12 \times 6 \;+\; 8 \times 7}{12 + 8}
= \frac{72 + 56}{20}
= 6.4
$$

> If both groups had **equal** size ($n_{A}=n_{B}$), each would carry equal weight and  
> $M_{\text{overall}}$ would be the simple midpoint between their means.

---

## Median — the Middle Score

> **Conceptually:** the median is the *middle milestone*—the 50th percentile—so half the data lie at or below it and half at or above it, making it a robust “typical” value even when the distribution is skewed.

- Order the scores; median splits them 50 % / 50 %.  
- **Robust** to skew & outliers (e.g., income).  
- Not defined by a formula but by position.

---

## Median — Example

**Dataset (unordered)**  
52, 70, 55, 65, 63, 57, 60, 59, 67  

---

1. **Order the scores**

   52  55  57  59  **60**  63  65  67  70  

   Since $n = 9$ (odd), the median is the $(n+1)/2 = 5^{\text{th}}$ score:

   $$\tilde{X} = 60$$  

---

2. **If $n$ is even**

   Append a tenth score (72) and reorder:

   52  55  57  59  60  63  65  67  70  72  

   Median = mean of the two middle scores (5th & 6th):

   $$\tilde{X} = \frac{60 + 63}{2} = 61.5$$  

---

3. **Robustness to an outlier**

   Replace the largest score with 720:

   52  55  57  59  **60**  63  65  67  720  

   Median is still **60** (mean would jump to 126), showing the median’s resistance to extreme values.


---

## Mode — Most Frequent

> **Conceptually:** the mode is the *crowd favorite*—the value or category that appears most often—so it marks the peak of the distribution and spotlights what’s most typical when “typical” means “most common.”

- Only measure that works for **nominal** data.  
- Handy with discrete counts (a “modal” family has 2 children).  
- Multiple modes hint at sub-groups.

---

## Mode — Example (1 / 2) {.smaller}

**Numeric dataset (children per family)**  
2, 3, 2, 4, 1, 2, 2, 3, 1, 2  

| Children | Count |
|----------|-------|
| 1        | 2     |
| 2        | 5     |
| 3        | 2     |
| 4        | 1     |

The most frequent value is **2**, so the **mode = 2**.  
“A modal family has two children.”

---

## Mode — Example (2 / 2) {.smaller}

**Nominal dataset (favourite ice-cream flavour)**  
Chocolate, Vanilla, Strawberry, Chocolate, Vanilla, Chocolate, Mint  

| Flavour     | Count |
|-------------|-------|
| Chocolate   | 3     |
| Vanilla     | 2     |
| Strawberry  | 1     |
| Mint        | 1     |

Mode = **Chocolate** → works for nominal data.

**Multimodal case**  
If we add one more *Vanilla* and one more *Mint*:

Chocolate (3), Vanilla (3), Mint (2), Strawberry (1) → **bimodal** (Chocolate & Vanilla).  
Multiple modes often suggest distinct sub-groups within the sample.

---

### Choosing the Measure of Central Tendency

```{r centre-tree}
decision <- data.frame(
  x = rep(1, 6),
  y = 5:0,
  label = c(
    "Measurement level?",
    "Nominal  →  MODE",
    "Ordinal / Interval / Ratio",
    "Outliers or strong skew?",
    "Yes  →  MEDIAN",
    "No   →  MEAN"
  )
)
ggplot(decision, aes(x, y, label = label)) +
  geom_text(size = 6, hjust = 0) +
  xlim(0.9, 4) + ylim(-0.5, 5.5) +
  theme_void()
```

---

# Variability

*Centre tells us what is typical; variability tells how typical.*

---

## Range

> **Conceptually:** the range is the dataset’s full span—from the smallest to the largest value—so it shows the overall width of the data, but because it uses only those two extremes it is very sensitive to outliers.

$$
\text{Range}=X_{\max}-X_{\min}
$$

---

## Range — Example (1 / 2) {.smaller}

**Dataset**  
4, 6, 7, 3, 10  

$$
X_{\min} = 3, \qquad
X_{\max} = 10, \qquad
\text{Range} = 10 - 3 = 7
$$

---

## Range — Example (2 / 2) {.smaller}

**Effect of a single outlier**

Add one extreme value (42):

4, 6, 7, 3, 10, **42**

$$
X_{\min} = 3, \qquad
X_{\max} = 42, \qquad
\text{Range} = 42 - 3 = 39
$$

Just one score changed, yet the range jumped from 7 to 39—demonstrating how unstable the range can be.  

---

## Deviations & Sum of Squares (SS) {.smaller}

> **Conceptually:** the Sum of Squares is the data’s total “spread energy” — each deviation is squared (so large gaps count a lot) and then added up, giving one number whose size grows with the overall scatter of the data. SS is the raw material from which variance and standard deviation are built.

1. **Deviation** $d_i = X_i - M$  
2. $\sum d_i = 0$  
3. Square deviations to avoid cancellation: $(X_i - M)^2$

$$
SS
\;=\;
\sum_{i=1}^{n} (X_i - M)^2
\;=\;
\sum_{i=1}^{n} X_i^{2}
\;-\;
\frac{\bigl(\sum_{i=1}^{n} X_i\bigr)^2}{n}
$$
---

## Deviations & SS — Example (1 / 2) {.smaller}

Dataset: 4, 6, 7, 3, 10  
Mean \(M = 6\)

| $X_i$ | $d_i = X_i - M$ |
|-------|-----------------|
| 4     | $4-6 = -2$      |
| 6     | $6-6 = 0$       |
| 7     | $7-6 = 1$       |
| 3     | $3-6 = -3$      |
| 10    | $10-6 = 4$      |

Sum of deviations: $-2 + 0 + 1 - 3 + 4 = 0\;\checkmark$


---

## Deviations & SS — Example (2 / 2) {.smaller}

| $X_i$ | $d_i$ | $d_i^{2}$ |
|-------|-------|-----------|
| 4     | $-2$  | 4         |
| 6     | 0     | 0         |
| 7     | 1     | 1         |
| 3     | $-3$  | 9         |
| 10    | 4     | 16        |

**Total Sum of Squares**

$$
SS = 4 + 0 + 1 + 9 + 16 = 30
$$

**Shortcut check**

$$
\sum X_i^{2} = 210, \qquad
\frac{(\sum X_i)^{2}}{n} = \frac{30^{2}}{5} = 180
$$

$$
SS = 210 - 180 = 30 \;\checkmark
$$

---

## Visualising Variance

```{r var-plot}
set.seed(2)
scores <- c(rnorm(30, 50, 8), 90)   # one extreme value
mn <- mean(scores)
ggplot(data.frame(scores), aes(scores)) +
  geom_histogram(binwidth = 5, fill = "steelblue", colour = "white") +
  geom_vline(xintercept = mn, lwd = 1.2) +
  geom_segment(aes(x = mn, xend = 90, y = 0, yend = 0),
               arrow = arrow(type = "closed", length = unit(0.2, "cm")),
               colour = "firebrick", lwd = 1) +
  labs(title="Mean (solid) and an Extreme Deviation (arrow)",
       x = "Score", y = "Count")
```

---

## Variance — Definition {.smaller}

**What is variance?**  

> The **average of the squared deviations** from the mean —yielding a single number that captures how much the scores “fan out” around their center: the larger the average squared distance, the more widely dispersed the data; the smaller it is, the more tightly the scores cluster near the mean.

| Statistic | Formula | Units |
|-----------|---------|-------|
| Population variance | $\displaystyle \sigma^{2} \;=\; \frac{SS}{N}$ | units² |
| Sample variance | $\displaystyle s^{2} \;=\; \frac{SS}{\,n-1\,}$ | units² |

**Why divide the sample SS by $n-1$?**  
Only **$n-1$ degrees of freedom** remain once we have estimated the sample mean ($\bar X$). Using $n-1$ instead of $n$ corrects the bias and makes $s^{2}$ an *unbiased* estimator of the population variance $\sigma^{2}$.

---

## Variance — Numerical Example {.smaller}

Dataset: 4, 6, 7, 3, 10 (mean $M = 6$)

| $X_i$ | $d_i = X_i - M$ | $d_i^{2}$ |
|-------|-----------------|-----------|
| 4     | $-2$            | 4         |
| 6     | 0               | 0         |
| 7     | 1               | 1         |
| 3     | $-3$            | 9         |
| 10    | 4               | 16        |

$$
SS \;=\; 4 + 0 + 1 + 9 + 16 \;=\; 30
\qquad
s^{2} \;=\; \frac{SS}{n-1} \;=\; \frac{30}{4} \;=\; 7.5
$$

So the **sample variance** is **7.5 units²**.

---

## Standard Deviation — Definition {.smaller}

**What does SD tell us?**  

> The **typical distance** (spread) of scores from the mean, expressed in the *same units* as the data.

Because variance squares deviations (units²), we take the **square-root** to get back to the original scale.

| Statistic | Formula | Units |
|-----------|---------|-------|
| Population SD | $\displaystyle \sigma = \sqrt{\sigma^{2}}$ | original |
| Sample SD     | $\displaystyle s = \sqrt{s^{2}}$           | original |

Key idea: One SD ≈ the average amount by which scores deviate from the mean.

---

## Standard Deviation — Example {.smaller}

From the variance slide we found a **sample variance** of $s^{2} = 7.5$.

$$
s \;=\; \sqrt{7.5} \;\approx\; 2.74
$$

**Interpretation**

On average, these scores lie about **2.7 points** away from the mean of 6.  

---

## Variance in Pictures {.smaller}

```{r compare-variance, echo=FALSE, fig.height=4}
library(ggplot2)

# Build a grid of x-values and the corresponding normal PDFs
x <- seq(0, 100, length.out = 1000)
df <- rbind(
  data.frame(x, density = dnorm(x, mean = 50, sd = 3),
             group = "Low SD (σ = 3)"),
  data.frame(x, density = dnorm(x, mean = 50, sd = 12),
             group = "High SD (σ = 12)")
)

ggplot(df, aes(x, density, colour = group, fill = group)) +
  geom_line(size = 1.2) +                     # smooth curves
  geom_area(alpha = .15, position = "identity") +  # light fill
  scale_colour_manual(values = c("High SD (σ = 12)" = "red",
                                 "Low SD (σ = 3)"  = "blue")) +
  scale_fill_manual(values = c("High SD (σ = 12)" = "red",
                               "Low SD (σ = 3)"  = "blue")) +
  labs(title = "Same mean, different spread",
       x = "Value", y = "Density") +
  theme_minimal(base_size = 14) +
  theme(legend.title = element_blank())


```
--- 

### How Transformations Affect SD

| Transformation | Effect on SD |
|----------------|--------------|
| Add constant *k* | no change |
| Multiply by *c*  | SD × *c* |
| Add extreme score | increases SD |

---

## SD — Effect of Transformations {.smaller}

Original dataset: 4, 6, 7, 3, 10 (sample SD ≈ **2.74**)

| Transformation | New scores (after transformation) | New SD | What happened? |
|----------------|------------------------------------|--------|----------------|
| Add $k = 5$    | 9, 11, 12, 8, 15                  | **2.74** | No change |
| Multiply by $c = 3$ | 12, 18, 21, 9, 30           | **8.22** | SD × 3 |
| Add extreme score (42) | 4, 6, 7, 3, 10, 42        | **14.9** | SD ↑ sharply |

**Take-away**

- Adding or subtracting a constant shifts the whole distribution but doesn’t alter spread.  
- Multiplying by a constant stretches or shrinks the spread in direct proportion.  
- A single outlier can inflate the SD dramatically because its squared deviation is huge.

---

## Recap

| Statistic | Formula | Keeps units? | Outlier‑sensitive? |
|-----------|---------|--------------|--------------------|
| Mean      | $M = \frac{\sum X}{n}$            | Yes | **Yes** |
| Median    | 50‑th percentile                   | Yes | No |
| Mode      | Most frequent                      | Yes / NA | No |
| Range     | $X_{\max}-X_{\min}$                | Yes | Yes |
| Variance  | $s^{2}=SS/(n-1)$                   | units$^{2}$ | Yes |
| SD        | $s=\sqrt{s^{2}}$                   | Yes | Yes |

---

## Key Take‑aways

- Mean, median, mode each define “centre” differently.  
- Variance and SD quantify spread; range is quick but crude.  
- Sample variance uses *n – 1* to remain unbiased.  
- Visualising deviations builds intuition for SS and variance.

---

# Next Week

**Lecture 3 — Correlation & Covariance**

Bring your SPSS cheat‑sheet!
