---
title: "Descriptive statistics"
author: "Caspar J. van Lissa"
date: "`r format(Sys.Date(), '%d %b %Y')`"
format: revealjs
server: shiny
---

```{r setup, include = FALSE}
library(ggplot2)           # only for making figures
knitr::opts_chunk$set(
  echo = FALSE,            
  message = FALSE, warning = FALSE,
  dev = "png",
  fig.width = 6, fig.height = 4, fig.align = "center"
)
```

## Learning Objectives

- **Central tendency**
  - What value is *typical*?
  - Mean, median, and mode.  
- **Variability**  
  - How much do individual scores *differ*?
  - Range, variance, and standard deviation.  
- **Effect of transformations & outliers**  

---


## variable and Distribution

```{r}
set.seed(1)
scrs <- cut(rnorm(20), 8, labels = FALSE)+2L

```

* **Variable:** students' grades
* **Scores:** `r paste0(scrs, collapse = ", ")`
* **Distribution:** The general shape of these scores

---

## Summarizing Scores: Frequency Table

```{r}
tab <- as.data.frame.table(table(scrs))
names(tab) <- c("Score", "Frequency")
knitr::kable(tab)
```

---

## Summarizing Scores: Bar Chart

For discrete variables (= not continuous), use a bar chart

* Each value has a bar
* Bars are ordered
* Visually *distinct* to signal that scores are discrete

```{r}
barplot(table(scrs), xlab = "Score", ylab = "Frequency")
```

---

## Summarizing Scores: Histogram

<font size=5>

* Categorize continuous variable into non-overlapping intervals (bins)
* Count number of observations per bin
* Each bin has a bar
* Visually *connected* to signal that scores are continuous

</font>

```{r}
set.seed(2)
x <- rnorm(20, mean = 175, sd = 15)
hist(x, xlab = "Height (cm)", main = NULL)
```

---


## Summarizing Scores: Density Plot

<font size=5>

* Instead of categorizing continuous variable, approximates a continuous distribution
* Uses a "smoothing" algorithm
* Area under the curve is the proportion of scores, which adds to 1
* Less common, because not available in SPSS

</font>

```{r}
plot(density(x), xlab = "Height (cm)", main = "")
```

---

## Central Tendency

*The most typical value of a distribution.*

---

## Mean - The Mathematical Middle {.smaller}

**Definition**: the sum of the scores divided by the number of scores. Mathematically, the mean is the middle point of the data.

$$
\text{Population:}\quad
\mu = \frac{\sum_{i=1}^{N} X_i}{N}
\qquad
\text{Sample:}\quad
M = \frac{\sum_{i=1}^{n} X_i}{n}
$$

**Key properties**

| Situation                                   | Effect on Mean |
|---------------------------------------------|----------------|
| Add a constant $k$ to every score           | $+k$           |
| Multiply every score by $c$                 | $\times c$     |
| Change one score by $\Delta$                | $+\Delta/n$    |
| Add / remove a score equal to the mean      | No change      |

---

## Mean - Example {.smaller}

Suppose five exam scores: 4, 6, 7, 3, 10

```{r}
df = data.frame(Score = c(4, 6, 7, 3, 10))
library(ggplot2)

ggplot(df, aes(x = Score, y = 1)) + scale_y_continuous(limits = c(0, 5)) + geom_point(shape = 21, size = 5, color = "black", fill = "orange") + 
  geom_hline(yintercept = 0, size = 2) +
  theme_minimal() + theme(axis.text.y = element_blank(), axis.title.y = element_blank())
```

---

## Mean

```{r}
df = data.frame(Score = c(4, 6, 7, 3, 10))
library(ggplot2)

dists <- data.frame(
  x = df$Score,
  xend = mean(df$Score),
  y = seq(.2,1, length.out = length(df$Score))
)
dists$yend = dists$y
df$y <- dists$y
ggplot(df, aes(x = Score, y = df$y)) +
  scale_y_continuous(limits = c(0, 5)) +
  scale_x_continuous(breaks = c(1:10), labels = c(1:10)) +
  geom_point(shape = 21, size = 5, color = "black", fill = "orange") + 
  geom_hline(yintercept = 0, size = 2) +
  geom_segment(data = dists, aes(x = x, xend = xend, y = y, yend = yend)) +
  geom_vline(xintercept = mean(df$Score), color = "red", size = 2) +
  theme_minimal() + theme(axis.text.y = element_blank(), axis.title.y = element_blank())
```

---

## Compute the mean

$$
M = \frac{4 + 6 + 7 + 3 + 10}{5} = \frac{30}{5} = 6
$$

| Operation                                   | New scores                | New mean             |
|---------------------------------------------|---------------------------|----------------------------|
| Add $+2$ to every score                  | 6, 8, 9, 5, 12            | $6 + 2 = 8$                |
| Multiply every score by $3$             | 12, 18, 21, 9, 30         | $6 \times 3 = 18$          |
| Change one score by $+3$ | 4, 6, 7, 3, 13            | $6 + \tfrac{3}{5} = 6.6$   |
| Add score equal to mean (6)       | 4, 6, 7, 3, 10, 6         | 6             |

---



## Weighted Mean – Unequal Group Sizes {.smaller}

When groups **differ in size**, the larger group should influence the overall mean more.  
The previous expression is therefore called a **weighted mean**-weights are the group sizes.

**Formula (two groups)**

$$
M_{\text{overall}}
= \frac{n_{A} M_{A} + n_{B} M_{B}}{n_{A} + n_{B}}
$$

*Numerical example*  
Group A: $n_{A}=12$, $M_{A}=6$  Group B: $n_{B}=8$, $M_{B}=7$

$$
M_{\text{overall}}
= \frac{12 \times 6 \;+\; 8 \times 7}{12 + 8}
= \frac{72 + 56}{20}
= 6.4
$$

> If both groups have **equal** size ($n_{A}=n_{B}$), they carry equal weight and  
> $M_{\text{overall}}$ is simply the mean of the means.

---

## Median - Rank Order Middle Score

> **Conceptually:** the median is the *middle score*, or 50th percentile, making it a robust “typical” value even when the distribution is skewed.

- *n*th percentile: *n*% of the scores are below this value
    + 50th percentile: half of scores below this value
- Not defined by a formula but by position.
- Order scores; median is middle score.
- **Robust** to skew & outliers (e.g., income).  

---

## Median

```{r}
ggplot(df[-2, ], aes(x = Score, y = 1)) +
  scale_y_continuous(limits = c(0, 5)) +
  scale_x_continuous(breaks = c(1:10), labels = c(1:10)) +
  geom_point(shape = 21, size = 5, color = "black", fill = "orange") + 
  geom_point(data = df[2, , drop = FALSE], shape = 21, size = 5, color = "black", fill = "red") + 
  geom_hline(yintercept = 0, size = 2) +
  theme_minimal() + theme(axis.text.y = element_blank(), axis.title.y = element_blank())
```

---


## Median - Example

**Dataset (unordered)**  
52, 70, 55, 65, 63, 57, 60, 59, 67  

---

1. **Order the scores**

   52  55  57  59  **60**  63  65  67  70  

   Since $n = 9$ (odd), the median is the $(n+1)/2 = 5^{\text{th}}$ score:

   $$\tilde{X} = 60$$  

---

2. **If $n$ is even**

   Append a tenth score (72) and reorder:

   52  55  57  59  60  63  65  67  70  72  

   Median = mean of the two middle scores (5th & 6th):

   $$\tilde{X} = \frac{60 + 63}{2} = 61.5$$  

---

3. **Robustness to an outlier**

   Replace the largest score with 720:

   52  55  57  59  **60**  63  65  67  720  

   Median is still **60** (mean would jump to 126), showing the median’s resistance to extreme values.


---

## Mode - Most Common Score

> **Conceptually:** in discrete variables, the mode is the value or category that appears most often. In continuous variables, it marks the peak of the distribution.

- Only measure that works for **nominal** data.  
    + But also works with ordinal, interval and ratio
    + But it's rare for two scores to be identical with interval and continuous variables
- Useful for discrete ratio variables (e.g., number of children; modal family has 2).  


---

## Mode

```{r}
ggplot(df[-3, ], aes(x = Score, y = 1)) +
  scale_y_continuous(limits = c(0, 5)) +
  scale_x_continuous(breaks = c(1:10), labels = c(1:10)) +
  geom_point(shape = 21, size = 5, color = "black", fill = "orange") + 
  geom_point(data = df[3, , drop = FALSE], shape = 21, size = 5, color = "black", fill = "red") + 
  geom_point(data = df[3, , drop = FALSE], y = 1.5, shape = 21, size = 5, color = "black", fill = "red") + 
  geom_hline(yintercept = 0, size = 2) +
  theme_minimal() + theme(axis.text.y = element_blank(), axis.title.y = element_blank())
```

---

## Mode - Example (1 / 2) {.smaller}

**Numeric dataset (children per family)**  
2, 3, 2, 4, 1, 2, 2, 3, 1, 2  

| Children | Count |
|----------|-------|
| 1        | 2     |
| 2        | 5     |
| 3        | 2     |
| 4        | 1     |

The most frequent value is **2**, so the **mode = 2**.  
“A modal family has two children.”

---

## Mode - Example (2 / 2) {.smaller}

**Nominal dataset (favourite ice-cream flavour)**  
Chocolate, Vanilla, Strawberry, Chocolate, Vanilla, Chocolate, Mint  

| Flavour     | Count |
|-------------|-------|
| Chocolate   | 3     |
| Vanilla     | 2     |
| Strawberry  | 1     |
| Mint        | 1     |

Mode = **Chocolate**: works for nominal data.

**Multimodal:**

If we add one more *Vanilla* lover, Chocolate (3) and Vanilla (3) are both modes. This is called **bimodal**

---


# Variability

*Center tells us what is typical; variability tells how typical.*

---

## Range

> **Conceptually:** the range is the dataset’s full span-from the smallest to the largest value-so it shows the overall width of the data, but because it uses only those two extremes it is very sensitive to outliers.

$$
\text{Range}=X_{\max}-X_{\min}
$$

---

## Range - Example (1 / 2) {.smaller}

**Dataset**  
4, 6, 7, 3, 10  

$$
X_{\min} = 3, \qquad
X_{\max} = 10, \qquad
\text{Range} = 10 - 3 = 7
$$

---

## Range - Example (2 / 2) {.smaller}

**Effect of a single outlier**

Add one extreme value (42):

4, 6, 7, 3, 10, **42**

$$
X_{\min} = 3, \qquad
X_{\max} = 42, \qquad
\text{Range} = 42 - 3 = 39
$$

Just one score changed, yet the range jumped from 7 to 39-demonstrating how unstable the range can be.  

---

## Deviations & Sum of Squares (SS) {.smaller}

> The Sum of Squares is the total spread of all data points. It is an intermediate step in the calculation of many spread-related statistics.

1. **Deviation** of each observation $d_i = X_i - M$  
2. Adding all deviations always gives $\sum d_i = 0$ 
3. Squaring deviations removes negative values to avoid cancellation: $(X_i - M)^2$

$$
SS
\;=\;
\sum_{i=1}^{n} (X_i - M)^2
\;=\;
\sum_{i=1}^{n} X_i^{2}
\;-\;
\frac{\bigl(\sum_{i=1}^{n} X_i\bigr)^2}{n}
$$
---

## Deviations & SS - Example (1 / 2) {.smaller}

Dataset: 4, 6, 7, 3, 10  
Mean \(M = 6\)

| $X_i$ | $d_i = X_i - M$ |
|-------|-----------------|
| 4     | $4-6 = -2$      |
| 6     | $6-6 = 0$       |
| 7     | $7-6 = 1$       |
| 3     | $3-6 = -3$      |
| 10    | $10-6 = 4$      |

Sum of deviations: $-2 + 0 + 1 - 3 + 4 = 0\;\checkmark$


---

## Deviations & SS - Example (2 / 2) {.smaller}

| $X_i$ | $d_i$ | $d_i^{2}$ |
|-------|-------|-----------|
| 4     | $-2$  | 4         |
| 6     | 0     | 0         |
| 7     | 1     | 1         |
| 3     | $-3$  | 9         |
| 10    | 4     | 16        |

**Total Sum of Squares**

$$
SS = 4 + 0 + 1 + 9 + 16 = 30
$$

**Shortcut check**

$$
\sum X_i^{2} = 210, \qquad
\frac{(\sum X_i)^{2}}{n} = \frac{30^{2}}{5} = 180
$$

$$
SS = 210 - 180 = 30 \;\checkmark
$$

---


## Variance - Definition {.smaller}

> The **average squared deviation** from the mean. Captures average spread of scores around the center: larger variance implies widely dispersed the data; smaller variance implies scores are tightly clustered around the mean.

| Statistic | Formula | Units |
|-----------|---------|-------|
| Population variance | $\displaystyle \sigma^{2} \;=\; \frac{SS}{N}$ | units$^2$ |
| Sample variance | $\displaystyle s^{2} \;=\; \frac{SS}{\,n-1\,}$ | units$^2$ |

## Degrees of Freedom {.smaller}

**Why divide the sample SS by $n-1$?**

* A sample contains *n* unique pieces of information.
* If we estimate the mean from the sample, we have $n-1$ remaining unique pieces of information (plus the mean)
* We pay for each estimated quantity with a "degree of freedom"
* Degrees of freedom of $df$ is a "counter" of how many more things we can estimate
* Once $df$ reaches zero, we have estimated as many statistics as we had pieces of information, so we cannot estimate anything more
Only **$n-1$ degrees of freedom** remain once we have estimated the sample mean ($\bar X$). Using $n-1$ instead of $n$ corrects the bias and makes $s^{2}$ an *unbiased* estimator of the population variance $\sigma^{2}$.

---

## Variance - Numerical Example {.smaller}

Dataset: 4, 6, 7, 3, 10 (mean $M = 6$)

| $X_i$ | $d_i = X_i - M$ | $d_i^{2}$ |
|-------|-----------------|-----------|
| 4     | $-2$            | 4         |
| 6     | 0               | 0         |
| 7     | 1               | 1         |
| 3     | $-3$            | 9         |
| 10    | 4               | 16        |

$$
SS \;=\; 4 + 0 + 1 + 9 + 16 \;=\; 30
\qquad
s^{2} \;=\; \frac{SS}{n-1} \;=\; \frac{30}{4} \;=\; 7.5
$$

So the **sample variance** is **7.5 units²**.

---

## Standard Deviation - Definition {.smaller}

**What does SD tell us?**  

> **Typical distance** of scores from the mean, in the *same units* as the data.

Because variance is expressed in squared units, we take the **square-root** to get back the original scale.

| Statistic | Formula | Units |
|-----------|---------|-------|
| Population SD | $\displaystyle \sigma = \sqrt{\sigma^{2}}$ | original |
| Sample SD     | $\displaystyle s = \sqrt{s^{2}}$           | original |

Conceptually: One SD is the average deviation from the mean.

Mathematically, this is not correct. The variance is computed from squared deviations, so extreme scores have more impact than scores near the mean. That is why we say *standard* deviation, not *average* deviation.

---

## Standard Deviation - Example {.smaller}

From the variance slide we found a **sample variance** of $s^{2} = 7.5$.

$$
s \;=\; \sqrt{7.5} \;\approx\; 2.74
$$

**Interpretation**

On average, these scores lie about **2.7 points** away from the mean of 6.  

---

## Variance in Pictures {.smaller}

```{r compare-variance, echo=FALSE, fig.height=4}
library(ggplot2)

# Build a grid of x-values and the corresponding normal PDFs
x <- seq(0, 100, length.out = 1000)
df <- rbind(
  data.frame(x, density = dnorm(x, mean = 50, sd = 3),
             group = "Low SD (σ = 3)"),
  data.frame(x, density = dnorm(x, mean = 50, sd = 12),
             group = "High SD (σ = 12)")
)

ggplot(df, aes(x, density, colour = group, fill = group)) +
  geom_line(size = 1.2) +                     # smooth curves
  geom_area(alpha = .15, position = "identity") +  # light fill
  scale_colour_manual(values = c("High SD (σ = 12)" = "red",
                                 "Low SD (σ = 3)"  = "blue")) +
  scale_fill_manual(values = c("High SD (σ = 12)" = "red",
                               "Low SD (σ = 3)"  = "blue")) +
  labs(title = "Same mean, different spread",
       x = "Value", y = "Density") +
  theme_minimal(base_size = 14) +
  theme(legend.title = element_blank())


```
--- 

### How Transformations Affect SD

| Transformation | Effect on SD |
|----------------|--------------|
| Add constant *k* | no change |
| Multiply by *c*  | $c*\text{SD}$ |
| Add extreme score | increases SD |

---

## SD - Effect of Transformations {.smaller}

Original dataset: 4, 6, 7, 3, 10; SD = 2.74

| Transformation | New scores (after transformation) | New SD | What happened? |
|----------------|------------------------------------|--------|----------------|
| Add $k = 5$    | 9, 11, 12, 8, 15                  | **2.74** | No change |
| Multiply by $c = 3$ | 12, 18, 21, 9, 30           | **8.22** | 3*SD |
| Add extreme score (42) | 4, 6, 7, 3, 10, 42        | **14.9** | SD increases |

**Take-away**

- Adding or subtracting a constant shifts the whole distribution but doesn’t alter spread.  
- Multiplying by a constant stretches or shrinks the spread in direct proportion.  
- A single outlier can inflate the SD dramatically because its squared deviation is huge.

---

## Recap

| Statistic | Formula | Keeps units? | Outlier‑sensitive? |
|-----------|---------|--------------|--------------------|
| Mean      | $M = \frac{\sum X}{n}$            | Yes | **Yes** |
| Median    | 50‑th percentile                   | Yes | No |
| Mode      | Most frequent                      | Yes / NA | No |
| Range     | $X_{\max}-X_{\min}$                | Yes | Yes |
| Variance  | $s^{2}=SS/(n-1)$                   | units$^{2}$ | Yes |
| SD        | $s=\sqrt{s^{2}}$                   | Yes | Yes |

---

## Key Take‑aways

- Mean, median, mode each define “center” differently.  
- Variance and SD quantify spread; range is quick but crude.  
- Sample variance uses *n – 1* to remain unbiased.  
- Visualising deviations builds intuition for SS and variance.

---

## Bonus plot: Boxplot

```{r}
set.seed(2)
x <- rnorm(20, mean = 175, sd = 15)
boxplot(x, horizontal = TRUE, col = "lightblue", xlab = "Height (cm)")
```

<font size = 4>

* **Median**: 50th percentile, or second quartile (Q2)
    + Thick line in the middle
* **Box**: ranges from 25th percentile (Q1) to 75th percentile (Q3)
* **Interquartile Range (IQR)**: distance between Q3 - Q1
* **Whiskers**: extend to last data point within 1.5*IQR from the box
* **Outliers**: observations outside the whiskers

</font> 

---

