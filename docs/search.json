[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistics 1 and 2",
    "section": "",
    "text": "Overview\nThis GitBook covers the basics of statistics and data analysis. The ability to extract insights from data is an essential skill for both academic and non-academic work, and “data literacy” is increasingly important in a world where data are collected about every aspect of our lives. In this book, you will be able to independently analyze data, interpret and report your findings, and assess the results of analyses performed by others, such as you might find in scientific articles.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "index.html#learning-goals",
    "href": "index.html#learning-goals",
    "title": "Statistics 1 and 2",
    "section": "Learning goals",
    "text": "Learning goals\nThis book covers the following learning goals:\n\ncompute and interpret commonly used descriptive statistics such as the sample mean, the median, the mode, variance and standard deviation, the standard error, and the correlation coefficient.\nrecognize different probability distributions such as the normal distribution, and make computations for these probability distributions.\nexplain the essential aspects of null-hypothesis significance testing, including sampling distributions, Type I and Type II errors, one-tailed versus two-tailed testing, and statistical power.\napply different statistical tests such as the Z-test, the one sample t-test, the one way Between Subjects Analysis of Variance test, and statistical tests related to (multiple) linear regression analysis with continuous and categorical predictors; and clarify the statistical and/or methodological assumptions that apply to the techniques that are discussed in this course.\nexplain basic concepts in regression analysis, including: linear association, least-squares estimation, explained variance, Multiple R, multiple correlation, adjusted R-square, raw and standardized regression coefficients, model-comparison tests, predicted scores, residuals and the assumptions;\nchoose the appropriate analysis technique for answering a specific research problem from the range of techniques that are covered in the course.\nuse the software package SPSS to perform several statistical data analyses and be able to correctly interpret and report the output to an informed audience (e.g., Liberal arts students, researchers from the social sciences/business and economics/cognitive neuroscience).\ndraw valid conclusions from the results of empirical data analyses given specific research questions envisaged.\napply statistical tests in the context of multiple linear regression models with interaction terms and logistic regression models; interpret the corresponding output.\ndescribe the concepts of probabilities, odds and logits; describe the relationship between the three scales; transform one into another (formulae are provided).\napply statistical tests in the context of factorial ANOVA, ANCOVA and Analysis of Repeated measures; interpret the corresponding output; and calculate and interpret effect size estimates relevant for these statistical techniques (e.g., (partial) eta squared)\napply statistical tests in the context of multiple linear regression models with interaction terms and interpret the corresponding output.\ngauge the reliability of measurements from questionnaires and identify problematic items.\nexplore the dimensionality of questionnaire data.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "index.html#using-this-gitbook",
    "href": "index.html#using-this-gitbook",
    "title": "Statistics 1 and 2",
    "section": "Using this GitBook",
    "text": "Using this GitBook\nThis GitBook is “Open Educational Material”. It is intended to replace conventional statistics textbooks, for free.\nAll essential information is contained within this GitBook. To ensure that you always have access to the GitBook, it is recommended that you download it to your local computer as follows:\n\nGo to https://github.com/cjvanlissa/stats12\nClick the green Code button\nSelect “Download ZIP” (see figure below)\nSave the ZIP archive to your drive\nRight-click the downloaded file, and select “Extract here” (or similar option, depending on your operating system)\nYou should now have a folder with the contents of the book.\nTo launch the book in your browser, open the file docs\\index.html.\nThe “data” folder contains all SPSS datasets you need for the course.\nThe “pdfs” folder contains all PDF files you need for the course.\n\nIt is possible that the book will be updated during the course. If this happens, I will notify you via Canvas to re-download the book.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "index.html#contributing-fixing-errors",
    "href": "index.html#contributing-fixing-errors",
    "title": "Statistics 1 and 2",
    "section": "Contributing / Fixing Errors",
    "text": "Contributing / Fixing Errors\nThis book is a work in progress, so you might find errors. Please help me fix them! The best way is to open an issue on github that describes the error. You are also welcome to suggest fixes directly by opening a pull request, if you know how to.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "index.html#sec-software",
    "href": "index.html#sec-software",
    "title": "Statistics 1 and 2",
    "section": "Software",
    "text": "Software\nBy default, it is assumed that you will be making the exercises in this book using the commercial program ‘SPSS’.\nIt is important to note that there are free alternatives to SPSS; you might consider using these on your own computer, instead of buying a license for SPSS:\n\nPSPP, which is designed to be nearly identical to SPSS with all the same basic functionality: https://www.gnu.org/software/pspp/pspp.html\nJASP, which is more modern, looks nicer and is very easy to use – but looks less similar to SPSS: https://jasp-stats.org/",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "index.html#credit",
    "href": "index.html#credit",
    "title": "Statistics 1 and 2",
    "section": "Credit",
    "text": "Credit\nThis book was authored by Caspar J. Van Lissa. Its code and layout are derived from Lisa DeBruine’s “booktem” (DeBruine & Lakens, n.d.).\nAlso see: https://psyteachr.github.io/\n\n\n\n\nDeBruine, L. M., & Lakens, D. (n.d.). Methods Book Template. Retrieved June 4, 2025, from https://debruine.github.io/booktem/",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "1  Introduction to Statistics",
    "section": "",
    "text": "2 Lecture",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Statistics</span>"
    ]
  },
  {
    "objectID": "introduction.html#frequency-distributions",
    "href": "introduction.html#frequency-distributions",
    "title": "1  Introduction to Statistics",
    "section": "\n4.1 Frequency Distributions",
    "text": "4.1 Frequency Distributions",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Statistics</span>"
    ]
  },
  {
    "objectID": "introduction.html#descriptive-statistics",
    "href": "introduction.html#descriptive-statistics",
    "title": "1  Introduction to Statistics",
    "section": "\n4.2 Descriptive Statistics",
    "text": "4.2 Descriptive Statistics",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Statistics</span>"
    ]
  },
  {
    "objectID": "introduction.html#bar-charts-and-histograms",
    "href": "introduction.html#bar-charts-and-histograms",
    "title": "1  Introduction to Statistics",
    "section": "\n4.3 Bar Charts and Histograms",
    "text": "4.3 Bar Charts and Histograms",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Statistics</span>"
    ]
  },
  {
    "objectID": "introduction.html#introducing-spss",
    "href": "introduction.html#introducing-spss",
    "title": "1  Introduction to Statistics",
    "section": "\n5.1 Introducing SPSS",
    "text": "5.1 Introducing SPSS\nWelcome everyone to your first lab session for Statistics 1 and 2. Today, we start working with an introduction to SPSS and we calculate a few basic descriptive statistics.\nEach lab session consists of several assignments and includes explanations on how to carry out the analyses in SPSS.\nYou can work at your own pace. If you experience any problems, or if you have any questions, feel free to ask your teacher.\nYou will receive feedback to your answers after you have submitted the practical.\nGood luck!\n\n5.1.1 Step 1\nHi there!\nDuring the lab sessions of this course you will learn how to work with the statistics program IBM SPSS (SPSS for short).\nBackground information is given throughout the exercises. We will occasionally refer to additional reading materials for this course, or other sources (e.g., youtube videos).\nIf you’re working from a student workplace, SPSS is already installed. If you’re working from your own computer, you either have to purchase SPSS, or you can use a free alternative (see Section 4) - but note that, at this point, the instruction text is still focused on SPSS so if there are any differences it will be your responsibility to figure out how to use your software.\nYour first task is to start the SPSS program. You can easily find SPSS via the Windows Start Menu. SPSS may ask about the coding: use Unicode (button to the left). Then there may be another window open that you can close. In the end you should see an empty spread sheet.\n\n5.1.2 Step 2\nNow you’ve got SPSS running, we’re ready to go!\nWe will start with a number of introductory exercises using the data file stressLAS.sav. To obtain this and other tutorial data files, download the GitBook, and open the data folder to find all files.\nOpen the file in SPSS. Proceed as follows: via the op menu follow the route: File -&gt; open -&gt; data. SPSS now opens a new window. Search for the file StressLAS.sav and open the file in SPSS.\n\n5.1.3 Step 3\nThe file contains data about a study on - you guessed it - stress.\nMore precisely, it contains data on the following variables:\n\n\nstress: Measures whether the participant experiences stress, and where the stress comes from.\n\nsmoke: Measures the smoking behavior of the participant.\n\nrelation: Whether or not the participant is involved in a long-term romantic relationship.\n\noptim: Measures how optimistic the participant is on a scale of 0 to 50.\n\nsatis: Measures of life satisfaction of the participant on a scale of 0 to 50.\n\nnegemo: The amount of negative emotions on a scale of 0 to 50.\n\n5.1.4 Step 4\nAfter opening the data file, you will see the tabs Data View and Variable View at the bottom of your screen.\nMake sure the tab Data View is selected.\nLook at the Data View and describe the data file. What do the rows represent, and what do the columns represent?\n\n5.1.5 Step 5\nNow switch to the Variable View tab.\nThe Variable View lists the variables and their properties. We will not discuss all the columns in detail, but focus on the most important ones, which includes: name, label, values, and measure.\nExplain for each of the columns name, label, values, and measure what aspect of the variable it describes. Also explain the difference between variable name and variable label.\n\n5.1.6 Step 6\nValue Labels\nFor nominal and ordinal variables we have to indicate what the scores represent; that is, we have to assign so called value labels. Value labels are specified under Values.\nIf you click on values for the variable of interest, and then on the blue button with the three dots on the right, SPSS opens a new window that allows you to view, define, or modify the value labels.\nWhat are the value labels for the Stress and what are they for Smoke?\n\n5.1.7 Step 6a\nYou may have noticed that the value labels are missing for the nominal variable Relation.\nAdd the value labels yourself in SPSS such that a score 1 represents “Single” and 2 represents “In a relationship”.\n\n5.1.8 Step 7\nEvery variable has a so-called Measurement Level.\nFirst, summarize the measurement levels in your own words (as if you have to explain it to a fellow student). Then, indicate the measurement level for each of the variables of interest (Stress, Smoking, etc.).\n\n5.1.9 Step 8\nCongratulations, you have completed your first assignment!\nBefore we proceed make sure that you save the data file (via file &gt; save). Because you changed the data, it is important to save the file under a different name. This way, you don’t risk losing the original data.\nIn the next assignment we will generate descriptive statistics for this data.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Statistics</span>"
    ]
  },
  {
    "objectID": "introduction.html#plotting-data",
    "href": "introduction.html#plotting-data",
    "title": "1  Introduction to Statistics",
    "section": "\n5.2 Plotting data",
    "text": "5.2 Plotting data\n\n5.2.1 Step 1\nThe first step in any statistical analysis involves inspection of the data at hand by means of descriptive statistics and/or graphical summaries. Descriptive statistics include the mean, standard deviation, minimum and maximum value. Examples of graphical summaries are bar charts, histograms, and scatter plots.\nIn this assignment we will look at graphical summaries. In particular, we will look at three: bar charts, histogram, and scatter plots.\nYou may use the same data file as for the previous assignments.\n\n5.2.2 Step 2\nFirst, we will create a bar chart for Stress.\nProceed as follows:\nGraphs &gt; legacy dialogs &gt; bar Select Simple and click on define Select Stress under Category Axis (i.e., the variable at the x-axis) Then Click on OK and consult the graph in the output\n\n5.2.3 Step 3\nYou may have noticed that SPSS by default creates a bar chart with the observed frequency depicted on the y-axis. We will now create a new bar chart and instead ask SPSS to show the percentages on the y-axis.\nProceed as follows:\nGraphs &gt; Legacy Dialogs &gt; Bar Again choose Simple and click on Define Under “Bars represent” choose “% of cases” Click on OK. SPSS will now create a bar chart, where the heights of the bars represent percentages.\n\n5.2.4 Step 4\nNext, we will create a histogram for Negative Emotions.\nProceed as follows:\nGraph &gt; Legacy Dialogs &gt; Histogram Select Negative Emotions under variable, and ask SPSS to Display normal curve (check the box). Click on OK.\nInvestigate the histogram; What is shown on the x-axis and what is shown on the y-axis?\nHow to read the histogram:\n\nx-axis: the scores on the negative emotions (here numbers between 0 and 50). bars represent score ranges; the more respondents with a score in that range, the higher the bar.\ny-axis: the observed number of respondents per score range.\n\n5.2.5 Step 5\nFinally, we will create a scatter plot for Negative Emotions and Life Satisfaction. Scatter plots are very useful to get a first impression of whether variables are associated.\nCreate a scatter plot as follows:\nGraphs &gt; legacy dialogs &gt; scatter/dot Choose Simple Scatter Select Negative Emotions on the x-axis, and Life Satisfaction on the y-axis Click OK\nConsult the output. Look at the scatter plot and see if you understand the graph.\nHow to read a scatter plot:\n\nx-axis represents the scores on Negative Emotions.\ny-axis represents the scores on Life Satisfaction.\nEach dot in the graph is a case, representing how the case scores on both Negative Emotions and Life Satisfaction.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Statistics</span>"
    ]
  },
  {
    "objectID": "introduction.html#quiz",
    "href": "introduction.html#quiz",
    "title": "1  Introduction to Statistics",
    "section": "\n5.3 Quiz",
    "text": "5.3 Quiz\n\nDescribe the first bar chart; What is shown on the x-axis? \nFrequency of Responses\nNumeric scores of Stress\nPercentages of Responses\nCategories of Stress\nIn the first bar chart, what is shown on the y-axis? \nNumeric scores of Stress\nPercentages of Responses\nCategories of Stress\nFrequency of Responses\nWhat’s the approximate proportion of people experiencing work-related stress? \n33%\n70%\n66%\nBased on the bar charts, what can you say about differences in stress levels in the sample? Are most people stressed or not? In other words: How is stress distributed across the three categories? \nMost people report life stress\nMost people report work stress\nEvenly distributed\nMost people report no stress\nDescribe the distribution of Negative Emotions. Are the scores normally distributed (i.e., like a bell-shape)? Really consider why this is / is not the case before checking your answer. \nNot normal\nNormal\nBased on the scatter plot from Step 5, would you expect an association between Negative Emotions and Life Satisfaction? \nStrong positive\nSmall positive\nSmall negative\nNo association",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Statistics</span>"
    ]
  },
  {
    "objectID": "introduction.html#descriptive-statistics-1",
    "href": "introduction.html#descriptive-statistics-1",
    "title": "1  Introduction to Statistics",
    "section": "\n5.4 Descriptive Statistics",
    "text": "5.4 Descriptive Statistics\n\n5.4.1 Step 1\nAs explained before, the first step in any statistical analysis involves inspection of the data. In the previous assignment we looked at graphical summaries.\nThis assignment shows you how to explore data using descriptive statistics. Descriptive statistics include values such as the mean, standard deviation, the maximum value and the minimum value.\nUse the same data file as for the previous assignments.\n\n5.4.2 Step 2\nWe will first take a look at the descriptive statistics for Optimism, Life Satisfaction, and Negative Emotions.\nCompute descriptive statistics as follows:\nAnalyze &gt; Descriptive Statistics &gt; Descriptives\nSelect the variables Optimism, Life Satisfaction and Negative Emotions Now click on OK SPSS will open a new window - the output window - including a table with the descriptives for the selected variables.\n\n5.4.3 Step 3\nIn the previous step we computed the average value and standard deviations. However, for nominal and ordinal variables, the average value is meaningless. To explore nominal and ordinal variables we may produce Frequency tables. A frequency table shows the observed percentage for each level of the variable.\nLet’s generate a frequency table for variables Smoke and Relation.\nAnalyze &gt; Descriptive Statistics &gt; Frequencies\nSelect the variables for which you want to have the frequency distribution (i.e., Smoke and Relation) Click OK. SPSS now adds a table with the frequency distributions of the selected variables to the output file.\nNote: SPSS reports percentages and valid percentages. Percentages differ when there are missing values. Because we don’t have missing values here, the numbers are the same. Missing values will be discussed in the next assignment.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Statistics</span>"
    ]
  },
  {
    "objectID": "introduction.html#quiz-1",
    "href": "introduction.html#quiz-1",
    "title": "1  Introduction to Statistics",
    "section": "\n5.5 Quiz",
    "text": "5.5 Quiz\n\nHow many participants are in the sample? \nWhat is the mean value of Optimism? \nFor which of the variables is the spread in the scores highest? \nOPTIM\nSATIS\nNEGEMO\nThe minimum and maximum observed scores for Negative Emotions were: [ , ].\nWhat percentage of participants is a non-smoker? \nWhat percentage of participants is in a relationship? \n\n\n5.5.1 Step 4\nOne of the reasons to first inspect descriptive statistics is to have a first check if there are erroneous values in the data file. Erroneous values are values that are out of range, or impossible given the variable envisaged. For example, a person may have mistyped his/her age (e.g., 511 instead of 51).\nNow it’s your task to check for each variable whether there are erroneous values (out of range values) in the file using descriptive statistics and/or graphs.\nUse the descriptive statistics to find any erroneous values.\nOne way to deal with missing values is by removing the entire case. This is not a recommended practice; however, at this point, it is the only method you have learned.\nTo find the cases that have missing values you may sort the data file on a variable with suspect values from high to low (or low to high).\nThis can be done as follows:\nData &gt; Sort Cases Select the variable on which cases should be sorted Select the cases in descending order Click on OK Go the data view and verify that the cases are now ordered.\nRemove the case(s) (i.e., delete the row from the data file) with invalid values.\n\n5.5.2 Step 5\nNow that we’ve “cleaned” the data file it’s time to answer our first research question!\nThe question is: “Are non-smokers in our sample on average more satisfied with their life than smokers?”\nTo answer this question, we need the mean of life satisfaction per smoking group. In order to generate those, we will use the Split File option in SPSS. This is an option in SPSS that allows us to get results for separate groups.\nData &gt; Split File &gt; Compare Groups Select the groups based on the variable Smoke Click OK\nNotice that you don’t see any changes in the data file or anything in the output file yet (!). However, after running the Split file command, SPSS from now will do the analyses per group, as we will see next.\nCompute the mean of Life Satisfaction (via descriptive statistics) and consult the output.\nYou may notice that SPSS provides the means of the non-smoking and smoking group separately. Compare the means for both groups to answer the following questions.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Statistics</span>"
    ]
  },
  {
    "objectID": "introduction.html#quiz-2",
    "href": "introduction.html#quiz-2",
    "title": "1  Introduction to Statistics",
    "section": "\n5.6 Quiz",
    "text": "5.6 Quiz\n\nWas there an erroneous value in the data file? If so, type the value of that erroneous value here: \nTo answer this question, only use reasoning. If you delete that value, how do you think the mean of that variable will be affected? \nStays the same\nBecomes smaller\nBecomes larger\nTo answer this question, only use reasoning. If you delete that value, how do you think the standard deviation of that variable will be affected? \nBecomes smaller\nStays the same\nBecomes larger\nTo answer this question, only use reasoning. If you delete that value, how do you think the standard deviation of that variable will be affected? \nStays the same\nBecomes smaller\nBecomes larger\nIn this sample, who are more satisfied with life? \nNon-smokers\nSmokers\nDo you think this also holds for the population of all persons? \nNo\nYes\nCan’t tell",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Statistics</span>"
    ]
  },
  {
    "objectID": "introduction.html#missing-values",
    "href": "introduction.html#missing-values",
    "title": "1  Introduction to Statistics",
    "section": "\n5.7 Missing Values",
    "text": "5.7 Missing Values\nThis is a short assignment about missing values.\nMissing values are ‘holes in the data matrix’. Missing data is a common issue in empirical research. Respondents may forget to fill in questions or refuse to answer questions (if the latter is the case, we are in trouble). It is important that missing data are adequately handled in data analysis.\nUse the same data file as for the previous assignments.\nIn the previous assignment we activated the split file option. However, we don’t need this split file in the remaining questions, therefore we have to undo the split file option.\nData &gt; split file Choose “Analyze all cases, do not create groups”\nCompute the frequency distribution of stress. Consult the output, and answer the following questions",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Statistics</span>"
    ]
  },
  {
    "objectID": "introduction.html#quiz-3",
    "href": "introduction.html#quiz-3",
    "title": "1  Introduction to Statistics",
    "section": "\n5.8 Quiz",
    "text": "5.8 Quiz\n\nWhat is the percentage of respondents who experience No Stress? \nWhich type of stress is most common in the sample? \nLife stress\nNo stress\nWork stress\nFor educational purposes only, we will now create missing values in the data file.\nNavigate to the Data view and delete the value for Stress for the first 10 cases. Notice that you only have to delete the scores for the variable Stress, and not the complete case.\nCompute the frequency distribution for Stress again and compare the new table with the previous one.\nExplain what has changed and why.\n\n\nAnswer\n\nWe can see that the values of Percent and Valid Percent have changed and that a ‘missing’ row has been added to the table. It makes sense that the percentages have changed, as there are now missing values. You may have noticed that the values for Percent and Valid Percent differ. Percentage is obtained by dividing the observed frequency by the total (including respondents with a missing value). Valid Percentage is obtained by dividing the observed frequency by the number of respondents with a valid score (thus, not counting the respondents who had a missing value).\n\nImagine I have a sample of 65 participants, with 3 missing value. Of these participants, 15 reported no stress. What is the percentage of no stress, calculated by hand? \nWhat is the percentage out of valid responses (i.e., valid percent), calculated by hand? \n\nBy deleting the values we created empty cells in the data file. SPSS sees these empty cells as system missing. Some researchers instead use specific values to indicate missing values. For example, we may code missing values by 999 if the respondent refused to answer, and 998 if the respondent accidentally skipped the question. These are examples of user missing values, and we have to specify the values to be coded as missing in the Variable view.\nLet’s try this!\nGo to the Data View, and fill in 999 in the cells that have no value on the variable Stress. Then go to the variable view, look for the column ‘Missing’ and click on Missing for Stress. A new window opens. Specify 999 as a discrete missing value. SPSS now knows that the value 999 stands for “missing observation”. Click OK.\nRe-compute the frequency distribution for Stress.\nExamine how the table changed compared to the previous ones.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Statistics</span>"
    ]
  },
  {
    "objectID": "introduction.html#more-descriptive-statistics",
    "href": "introduction.html#more-descriptive-statistics",
    "title": "1  Introduction to Statistics",
    "section": "\n5.9 More Descriptive Statistics",
    "text": "5.9 More Descriptive Statistics\nIn this final assignment, we will continue with descriptive statistics.\nAs mentioned in the lecture, describing the data is an important first step in any research situation.\nFor didactic reasons, we will do some computations by hand, but this is not something you have to do on the exam. However, it is good to experience at least once how the computations work and that the numbers in SPSS are not the result of magic.\nLet’s first look at measures of central tendency:\nConsider the following grades for 10 students: 6, 3, 4, 6, 7, 6, 8, 9, 10, 9.\nCompute (by hand) the mean, median, and mode.\n\n\nRemind me how\n\n\nThe mode is the most common value.\nThe median is the middle value (or mean of two middle values for an equal number)\nThe mean is calculated as the sum of all values, divided by the number of values: \\(\\frac{\\sum_{i=1}^nX_i}{n}\\)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Statistics</span>"
    ]
  },
  {
    "objectID": "introduction.html#quiz-4",
    "href": "introduction.html#quiz-4",
    "title": "1  Introduction to Statistics",
    "section": "\n5.10 Quiz",
    "text": "5.10 Quiz\n\nWhat is the mean? \nWhat is the median? \nWhat is the mode? \n\nMeasures of variation\nNext we will look at a measure of variation (i.e., indicating the amount of spread in the observations).\nConsider the grades of 6 students: 2, 7, 6, 7, 8, 9.\nCompute the variance and standard deviation by hand.\n\n\nRemind me how\n\nThe variance is the “average squared distance between observations and the mean”: \\(\\frac{\\sum_{i=1}^n(X_i-\\bar{X})^2}{n-1}\\)\nThe SD is the square root of the variance\nFollow these steps:\n\nCompute the mean, e.g., \\(\\bar{X} = 5\\)\n\nFor each observation, calculate the distance from the mean; e.g., \\(3-5 = -2\\)\n\nSquare these distances, e.g.: \\((-2)^2 = 4\\)\n\nAdd these distances for all observations\nDivide by number of observations minus 1",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Statistics</span>"
    ]
  },
  {
    "objectID": "introduction.html#quiz-5",
    "href": "introduction.html#quiz-5",
    "title": "1  Introduction to Statistics",
    "section": "\n5.11 Quiz",
    "text": "5.11 Quiz\n\nWhat is the variance? \nWhat is the standard deviation? \n\nWe now will verify the answer to the question in the previous step using SPSS!\nFirst, we have to enter the data in SPSS. Proceed as follows:\nOpen SPSS (use Unicode, and close the opening windows)\nMake sure that you have the data view on the screen\nType in the grades in SPSS (i.e.: 2, 7, 6, 7, 8, 9):\nGo to variable view and change the name of the variable and provide a meaningful label\nSecond, we can compute the variance and standard deviation in SPSS.\nProceed as follows:\nAnalyze &gt; Descriptive statistics &gt; Descriptives\nSelect the variable you just defined Now click op Options. A new window opens which shows many more descriptive options Enable the variance Click Continue and OK\nConsult the table descriptive statistics in the output window.\nWere your computations correct?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Statistics</span>"
    ]
  },
  {
    "objectID": "introduction.html#correlation",
    "href": "introduction.html#correlation",
    "title": "1  Introduction to Statistics",
    "section": "\n5.12 Correlation",
    "text": "5.12 Correlation\nFor the next few questions we need the data file LAS_SocSc_DataLab2.sav. Open the file in SPSS. You will see that the file contains data for six variables, named X1 through X6. We will inspect the associations between pairs of variables (so called bivariate relationships).\nFirst, generate a scatter plot for X1 and X2. Proceed as follows: Graphs &gt; Legacy dialogs &gt; Scatter/dot. Then ask for a Simple scatter. Put X1 on the X-Axis and X2 on the Y-Axis. Describe the association. Take into account whether the relationship follows a straight line (i.e., linearity), is positive or negative (i.e., direction), and whether the relationship seems to be weak, moderate or strong (i.e., strength).\nSecond, generate a scatter plot for X3 and X4. Make sure that X3 is shown on the X-axis and X4 on the Y-axis. Describe the association in terms of linearity, direction and strength.\nThird, generate a scatter plot for X5 and X6. Describe the association in terms of linearity, direction and strength.\n\nIs the relationship between X1-X2 positive? \nTRUE\nFALSE\nIs the relationship between X5-X6 positive? \nTRUE\nFALSE\nIs the relationship between X1-X2 linear? \nTRUE\nFALSE\nIs the relationship between X3-X4 linear? \nTRUE\nFALSE\nGive an indication of the strength of the relationship between X1-X2: \nmoderate\nzero\nweak\nstrong\nGive an indication of the strength of the relationship between X3-X4: \nzero\nweak\nstrong\nmoderate\nGive an indication of the strength of the relationship between X5-X6: \nweak\nzero\nstrong\nmoderate\n\nConsider the relationship between X3 and X4, can you think of an example of two variables that would be associated in this way?\n\n\nShow answer\n\nAny cyclical process;\n\nTime in the day and how far the water reaches up the beach (ebb and flow)\nLocation of the sun in the sky\n\n\n\n5.12.1 Correlation Coefficient\nIn this step we will look at the correlation coefficient as numerical description of linear association.\nNotice that in the previous step we found a non-linear association. The correlation coefficient would not be a valid measure to describe such an association, but nevertheless it is instructive to see why caution should be exercised in drawing conclusions about association from the correlation coefficient alone.\nWe will use SPSS to compute the correlation coefficient.\nAnalyze &gt; Correlate &gt; Bivariate Select X1, X2, … X6 as the variables Click OK\nConsult the table Correlations in the output.\nThere are several values in the table, but we are looking for the Pearson Correlation. The other numbers are the so called significance level, a concept we discuss soon, and the sample size.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Statistics</span>"
    ]
  },
  {
    "objectID": "introduction.html#quiz-6",
    "href": "introduction.html#quiz-6",
    "title": "1  Introduction to Statistics",
    "section": "\n5.13 Quiz",
    "text": "5.13 Quiz\n\nWhat is the correlation coefficient for the variables X1 and X2? \nWhat is the correlation coefficient for the variables X2 and X6? \nWhat is the correlation coefficient for the variables X3 and X4? \nCan we interpret this correlation coefficient? \nYes, otherwise SPSS would give an error\nNo, assumption of normality violated\nNo, assumption of linearity violated\nNo, assumption of association violated\nInterpret the correlation between X5 and X6? \nModerate negative\nModerate positive\nWeak negative\nWeak positive",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Statistics</span>"
    ]
  },
  {
    "objectID": "chapter2_descriptive_statistics.html",
    "href": "chapter2_descriptive_statistics.html",
    "title": "2  Descriptive Statistics",
    "section": "",
    "text": "2.1 Measures of Central Tendency\nMeasures of central tendency are statistics that try to capture the “most common” value in a sample. The most common measure of central tendency is the “average”, which statisticians would call the “mean”. All measures of central tendency summarize the distribution of values of one particular variable as one representative number.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Descriptive Statistics</span>"
    ]
  },
  {
    "objectID": "chapter2_descriptive_statistics.html#sec-central",
    "href": "chapter2_descriptive_statistics.html#sec-central",
    "title": "2  Descriptive Statistics",
    "section": "",
    "text": "2.1.1 Mean: the “average” value\nThe most common measure of central tendency is the mean (or average). It is computed by adding all observed scores, and dividing that total by the number of observations.\nAs a formula, this looks like:\n\\(\\bar{x} = \\frac{\\sum_{i=1}^{n}x_i}{n} = \\frac{x_1 + x_2 + ... + x_n}{n}\\)\nAn advantage of the mean is that every participant’s score contributes to its value equally. This also implies that it is sensitive to extreme values (also called: outliers). If you calculate the mean income in a country where 99% of inhabitants live below the poverty level and 1% are ultra-rich oligarchs, then the mean income will make it look like, on average, people make good money. This sensitivity to extreme values implies that the mean is a good description of the distribution of scores if the distribution is approximately symmetrical (i.e., about 50% of scores are above the mean, and 50% are below it).\nTake a look at the figures below; they show different possible distributions of scores in a sample. On the X-axis is the number line. Exact values are not given here because the important point is the shape of the distribution, but you can imagine that the X-axis is a scale of height from 150-210 centimeter, or a self-report questionnaire scale from 1-10. On the Y-axis is the frequency with which each number is reported by the participants; a higher value on this axis means that this response is more common. The red line indicates the location of the mean.\nNotice that the distributions labeled a-c are all symmetrical: In distribution a, scores cluster around one common value and quickly drop off when you get further away from that common value. In distribution b, scores also cluster around one common value, but they drop off more gradually. In distribution c, every value is exactly equally common. For distributions a-c, the mean would be a good measure of central tendency - it gives you the middle of the distribution. However, also notice that the mean is a better representation of the “most common” value in distributions a-b, but not in distribution c.\n\nlibrary(ggplot2)\nlibrary(ggpubr)\n\nWarning: package 'ggpubr' was built under R version 4.5.1\n\nbase &lt;- ggplot() +\n    xlim(-5, 5) +\n    theme_void() +\n    theme(axis.title.x = element_text(), axis.title.y = element_text(angle = 90))+\n    labs(x = \"Value\", y = \"Frequency\") +\n  geom_vline(xintercept = 0, color = \"red\", linewidth = 2)\np1 &lt;- base + geom_function(fun = dnorm)\np2 &lt;- base + geom_function(fun = function(x){5-abs(x)})\np3 &lt;- base + geom_function(fun = function(x){5})\np4 &lt;- ggplot() +\n    xlim(0, 1) +\n    theme_void() +\n    theme(axis.title.x = element_text(), axis.title.y = element_text(angle = 90))+\n    labs(x = \"Value\", y = \"Frequency\") +\n    geom_vline(xintercept = .5, color = \"red\", linewidth = 2) +\n    geom_function(fun = dbeta, args = list(shape1 = 2, shape2 = 6)) \n\nfigure &lt;- ggarrange(p1, p2, p3, p4,\n                    labels = letters[1:4],\n                    ncol = 4, nrow = 1)\nfigure\n\n\n\n\n\n\n\n\n2.1.2 Median: the middle milestone\nIf you were to order all scores of your variable from lowest to highest, then the median value is the value that splits your sample in half: half of the participants score lower than this value, and half score higher.\nAnother name for the median is the 50th percentile. This just means that 50% of participants score lower than the median (and, by extension, 50% score higher).\nBased on the explanation of the mean, you might already realize that this value should be equal to that of the mean in a perfectly symmetrical distribution. If there are outliers, though, the median is less strongly affected by them than the mean. We can thus say that the median is a measure of central tendency that is more robust to outliers than the mean.\nThe median is not really “calculated”, but it is found by literally sorting all values in order, and then picking the middle value (if you have an odd number of observations), or calculating the mean of the two middle values (if you have an even number of observations).\nIf our variable has these values (which are already ordered):\n2, 3, 6, 7, 100\nThen the median value is the middle value, \\(Med = 6\\). Note that the outlier with value 100 does not really affect it (the mean for this sample would be much higher, \\(M = 23.6\\)).\nIf our variable has these values (which are already ordered):\n1, 2, 3, 6, 7, 100\nThen the median would be the mean of the middle two values: \\((3+6) / 2 = 4.5\\).\nBelow is the picture of the means again, but now, the location of the median is indicated with a blue line. Note that for the symmetrical distributions a-c, the median is identical to the mean - but for the asymmetrical distribution d, the median is a much better representation of the “most common value” than the mean is.\n\np1 &lt;- p1 + geom_vline(xintercept = 0, color = \"blue\", linewidth = 2)\np2 &lt;- p2 + geom_vline(xintercept = 0, color = \"blue\", linewidth = 2)\np3 &lt;- p3  + geom_vline(xintercept = 0, color = \"blue\", linewidth = 2)\np4 &lt;- p4 + geom_vline(xintercept = .17, color = \"blue\", linewidth = 2)\n\nfigure &lt;- ggarrange(p1, p2, p3, p4,\n                    labels = letters[1:4],\n                    ncol = 4, nrow = 1)\nfigure\n\n\n\n\n\n\nFigure 2.1: Location of the median in symmetrical and asymmetrical distributions.\n\n\n\n\n\n2.1.3 Mode: the most common value\nThe mode is the most common value in a sample. We can calculate or find it by creating a frequency table, tabulating how often each score is observed in the sample, and then picking the score that occurs most frequently.\nWhile the mode can be obtained for variables with any measurement level, it is the only valid measure of “central tendency” for nominal data (e.g., sex, major, favourite color). The other measures of central tendency are not valid for nominal data, because these lack a numerical value.\nAgain, note that in a perfectly symmetrical data distribution, the mode will be identical to the mean and the median.\nImagine, for example, that I have students from three majors:\n\n\n\n\nMajor\nFrequency\n\n\n\nSocial Science\n43\n\n\nCognitive Neuroscience\n22\n\n\nBusiness & Economics\n11\n\n\n\n\n\nThe mode of the variable major, in this case, is “Social science”. Do you see why we cannot calculate a mean or median for the variable major? Because the majors don’t have a numerical value.\nHowever, it would be perfectly reasonable for me to say that the mode grade obtained last year was a 6.5. This implies that 6.5 was the most common grade, but it doesn’t tell you how many students got that grade, or whether the average grade was above or below the level required to pass.\nVisually, the location of the mode is the same as the location of the median in plots a, b, and d in Figure Figure 2.1. Plot c does not have a mode; no score is more common than any other score.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Descriptive Statistics</span>"
    ]
  },
  {
    "objectID": "chapter2_descriptive_statistics.html#choosing-a-measure-of-central-tendency",
    "href": "chapter2_descriptive_statistics.html#choosing-a-measure-of-central-tendency",
    "title": "2  Descriptive Statistics",
    "section": "\n2.2 Choosing a Measure of Central Tendency",
    "text": "2.2 Choosing a Measure of Central Tendency\nWhich measure to choose depends, in part, on the measurement level of the variable.\n\n\nNominal: Mode\n\nOrdinal: Mode; if you calculate the mean or median, that means you assume that the distances between all categories are equal (i.e., you’re treating your ordinal variable as interval).\n\nInterval/Ratio: Mode, mean, and median",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Descriptive Statistics</span>"
    ]
  },
  {
    "objectID": "chapter2_descriptive_statistics.html#sec-variability",
    "href": "chapter2_descriptive_statistics.html#sec-variability",
    "title": "2  Descriptive Statistics",
    "section": "\n2.3 Measures of Dispersion",
    "text": "2.3 Measures of Dispersion\nMeasures of central tendency tell us what is a typical score; measures of dispersion tell how typical that score is. Dispersion simply means variability, so from now on, we will use this term.\nHere are several measures of variability:\n\n2.3.1 Range: full span\nThe range is the distance from the smallest to the largest value. You calculate it by subtracting the smallest value from the largest; for example, if your smallest value is 1 and the largest is 5, then the range is \\(5-1 = 4\\).\nAs a formula, this looks like:\n\\(R = x_\\text{largest} - x_\\text{smallest}\\)\nSometimes, the range is also reported as an interval, \\([1, 5]\\), or as minimum and maximum values. The range is an intuitive metric, but it is unstable because its value is fully determined by just two observations (the lowest and highest). The variability of all of the other observations does not affect it.\n\n2.3.2 Sum of Squared Distances to the Mean\nA metric of variability that does take all observations into account is the sum of squared distances to the mean - or “sum of squares”.\nTo calculate it, follow these steps:\n\nCalculate the mean of all observations, e.g. if our observations are 1,2,3, then \\(M = 2\\)\n\nFor each observation, calculate the distance from that mean (subtract the mean), so for our observations 1,2,3, we get \\(1-2 = -1\\), \\(2-2 = 0\\), and \\(3-2 = 1\\).\nSquare all these distances to get rid of negative values, so \\(-1^2 = 1\\), \\(0^2 = 0\\), \\(1^2 = 1\\).\nSum the squared distances, in this case \\(1 + 0 + 1 = 2\\)\n\n\nAs a formula, this looks like:\n\\(SS = \\sum_{i=1}^{n}(x_i - \\bar{x})^2\\)\nNote that if we would not square the distances, the sum would always be zero because the mean is mathematically in the middle of all scores, so the negative distances of values below the mean exactly cancel out the positive distances of values above the mean.\nThe sum of squares has several important properties. First, note that its value depends on the sample size: sums of squares of larger samples tend to be larger than those of smaller samples. Second, note that they are not on a very meaningful scale. Without further information, you cannot interpret what it means to say that the sum of squares for the variable age is 6524. Third, note that squaring distances does mean that high deviations become (quadratically) more influential:\n\nlibrary(ggplot2)\ndf &lt;- data.frame(Deviation = 1:10,\n                 Squared = c(1:10)^2)\nggplot(df, aes(x = Deviation, y = Squared)) + geom_point() + geom_line() + scale_x_continuous(breaks = 1:10) + theme_bw()\n\n\n\nWhen squared, large values are more influential than small values.\n\n\n\n\n2.3.3 Variance: mean squared distance\nOne way to make the sum of squares more interpretable is to divide it by the number of observations. This tells us how far away each observation is from the sample mean, on average.\nHere are three formulas, that all describe the calculation of the variance. The first describes how you calculate the variance from the sum of squares (SS); the second includes the formula for the sum of squares, and the third describes how you calculate it by squaring the raw scores and subtracting a sum of \\(n\\) times the squared mean of X, \\(\\mu_{x}\\):\n\\(s^2 = \\frac{SS}{n} = \\frac{\\sum_{i=1}^{n}(x_i - \\mu_{x})^2}{n} = \\frac{\\sum_{i=1}^{n}x_i^2 - n\\mu_{x}^2}{n}\\)\nNote that here, we divide by the sample size \\(n\\). When using the variance as a descriptive statistic, this is fine.\nHowever, in later lectures, we will use sample statistics to make claims about the population (inferential statistics). Then, it becomes very important to divide by \\(n-1\\) if the population mean is unknown. The formulas then look like this:\n\\(s^2 = \\frac{SS}{n-1} = \\frac{\\sum_{i=1}^{n-1}(x_i - \\bar{x})^2}{n-1} = \\frac{\\sum_{i=1}^{n}x_i^2 - n\\bar{x}^2}{n-1}\\)\nThe consequence of dividing by \\(n-1\\) is that we get a slightly higher value for the variance. We do this to account for the fact that we don’t know the exact value of the population mean; we estimated it from the sample. If we just assume that the sample mean is a perfect representation of the population mean, we will systematically under-estimate the variance. By dividing by \\(n-1\\), we get a slightly larger variance estimate, adjusted for our uncertainty about the value of the population mean.\n\n2.3.4 Standard Deviation\nOne disadvantage of the variance is that it is still on the squared scale we obtained by squaring the distances. So, if your variable measures age in years, than the variance of age is expressed in years squared.\nTo restore the variance to the original units of the variable, we can simply take the square root. So if our variables are measured in euros, centimeters, and milliseconds - then the variances will be expressed in euros\\(^2\\), centimeters\\(^2\\), and milliseconds\\(^2\\). Taking the square root restores the original units; we call the resulting statistic the standard deviation.\nYou can think of the standard deviation as the average deviation between individual scores and the sample mean. Why don’t we just call it the “average deviation” then? Because that would be mathematically inaccurate - when we squared the deviations before taking the average, we allowed larger deviations to have a disproportionately larger impact on the value of the variance. Taking the square root of the end result, the variance, does not cancel out that disproportionate influence of large deviations.\nSo, intuitively it is fine to think of the standard deviation as the “average” deviation, as long as you’re aware that mathematically, this is not exactly correct, because an average value should assign equal weight to each observation, whereas the standard deviation assigns greater weight to extreme observations.\nImagine I tell you that, in one class, the average grade is a 5, with a standard deviation of .5. You would know that most students scored close to a 5, and many of them failed the course. If I told you that the average grade is 5 with a standard deviation of 2, you would know that scores are much more spread out, and a large portion of the students must have passed the course as well.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Descriptive Statistics</span>"
    ]
  },
  {
    "objectID": "chapter2_descriptive_statistics.html#sec-transform",
    "href": "chapter2_descriptive_statistics.html#sec-transform",
    "title": "2  Descriptive Statistics",
    "section": "\n2.4 Effects of Transformations & Outliers",
    "text": "2.4 Effects of Transformations & Outliers\n\n\n\n\n\n\n\nTransformation\nThe mean…\nThe SD…\n\n\n\nAdd / subtract constant\nShifts by that constant\nDoesn’t change\n\n\nMultiply / divide by constant\nScales by that factor\nScales by that factor\n\n\nInject one extreme score\nPulls center toward outlier\nIncreases\n\n\n\nExample: Changing units (e.g., converting centimeters to inches) would rescale both the mean and SD.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Descriptive Statistics</span>"
    ]
  },
  {
    "objectID": "chapter2_descriptive_statistics.html#sec-bridge",
    "href": "chapter2_descriptive_statistics.html#sec-bridge",
    "title": "2  Descriptive Statistics",
    "section": "\n2.5 Why Descriptives Matter",
    "text": "2.5 Why Descriptives Matter\n\n\nData cleaning: Outliers leap out when you know the usual range.\n\n\nAnalysis choices: Skewed or heavy-tailed distributions may call for robust or non-parametric methods.\n\n\nTransparency: Readers can judge your results only if they see the data’s headline features.\n\n\nCommunication: “Participants averaged 8.9 hours of screen time per day (SD = 1 hr)” paints an instant picture.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Descriptive Statistics</span>"
    ]
  },
  {
    "objectID": "chapter2_descriptive_statistics.html#context-of-discovery-vs-justification",
    "href": "chapter2_descriptive_statistics.html#context-of-discovery-vs-justification",
    "title": "2  Descriptive Statistics",
    "section": "\n2.6 Context of Discovery VS Justification",
    "text": "2.6 Context of Discovery VS Justification\n\nknitr::include_graphics(\"images/creativity_verification.jpg\")\n\n\n\n\n\n\nFigure 2.2: An interpretation of De Groot’s empirical cycle, by Wagenmakers, Dutilh, & Sarafoglou, 2018. CC-BY: Artwork by Viktor Beekman, concept by Eric-Jan Wagenmakers\n\n\n\n\nIn the first chapter, we described De Groot’s empirical cycle as a model of cumulative knowledge acquisition through scientific research. A crucial assumption of this cycle, highlighted by Wagenmakers and colleagues (see Figure 2.2), is the distinction between the context of discovery and the context of justification. The context of discovery is exploratory: we peruse data, looking for interesting patterns that might spark a new hypothesis. The context of justification is confirmatory: we test a theory-driven hypothesis. In order to obtain an unbiased test of a hypothesis, the hypothesis cannot be shaped by prior exploration of the data. If we first observe an interesting pattern in data (exploratory), and then conduct a test of that pattern (confirmatory), the test is more likely to confirm the pattern. There are legitimate ways to explore data looking for interesting patterns, and machine learning can be a helpful tool in this search (Van Lissa, 2022a). However, be careful of any cross-contamination between exploration and confirmation. Any pattern observed during exploration can introduce bias in subsequent confirmatory tests (Hoijtink et al., 2023).\nVery often, the first thing researchers do when collecting or accessing a dataset is to calculate and examine descriptive statistics. This common practice introduces a potential risk of cross-contamination between exploration and confirmation: observing the descriptive statistics may influence other downstream analysis decisions. This is not a problem when conducting purely exploratory analyses, and it is also not a problem if the analyses have been preregistered. Preregistration means that the analysis plans have been published in a time-stamped archive before collecting or accessing the data, so it’s possible for others to check whether the reported analyses were executed as planned (Peikert et al., 2023), with changes made after seeing the descriptive analyses. In all other cases: be mindful of the risk of introducing bias. For an example of how preregistered hypothesis tests can be combined with rigorous exploration using machine learning, see Van Lissa (2022b).\n\n\n\n\n\n\n\n\n\n\n#Lecture",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Descriptive Statistics</span>"
    ]
  },
  {
    "objectID": "chapter2_descriptive_statistics.html#descriptive-statistics",
    "href": "chapter2_descriptive_statistics.html#descriptive-statistics",
    "title": "2  Descriptive Statistics",
    "section": "\n4.1 Descriptive Statistics",
    "text": "4.1 Descriptive Statistics\n\n4.1.1 Step 1\nAs explained before, the first step in any statistical analysis involves inspection of the data. In the previous assignment we looked at graphical summaries.\nThis assignment shows you how to explore data using descriptive statistics—values such as the mean, standard deviation, maximum, and minimum.\n\nUse the same data file as in the previous tutorial.\n\n\n4.1.2 Step 2 – Descriptives for Key Variables\nWe will first examine the descriptive statistics for Optimism, Life Satisfaction, and Negative Emotions.\nCompute descriptive statistics as follows:\n\n\nAnalyze &gt; Descriptive Statistics &gt; Descriptives\n\nSelect Optimism, Life Satisfaction, Negative Emotions\n\nClick OK\n\n\nSPSS opens a new Output window with a table of descriptives for the selected variables.\n\n4.1.3 Step 3 – Frequency Tables\nIn the previous step we computed the average value and standard deviations. However, for nominal and ordinal variables, the average value is meaningless. To explore nominal and ordinal variables we may produce frequency tables. A frequency table shows the observed percentage for each level of the variable.\nGenerate frequencies for Smoke and Relation:\n\n\nAnalyze &gt; Descriptive Statistics &gt; Frequencies\n\nSelect Smoke and Relation\n\nClick OK\n\n\nSPSS now adds a table with the frequency distributions of the selected variables to the output file.\nNote: SPSS reports Percent and Valid Percent. These differ only when missing values are present (none in this dataset).\n\n4.1.3.1 Extra – Spotting Multimodality\nSometimes a single mean or median masks sub-groups.\n\n\nGraphs &gt; Legacy Dialogs &gt; Histogram\n\nChoose Life Satisfaction for Variable and click OK\n\n\nIf you notice two peaks, colour the bars by Relation (single vs. relationship):\n\n\nGraphs &gt; Chart Builder\n\nDrag Histogram onto the canvas\n\nPlace Life Satisfaction on the x-axis\n\nDrag Relation into Cluster on X\n\nClick OK\n\n\nTake-away: multiple modes often reveal hidden clusters that may need separate analysis.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Descriptive Statistics</span>"
    ]
  },
  {
    "objectID": "chapter2_descriptive_statistics.html#quiz-1-basic-descriptives",
    "href": "chapter2_descriptive_statistics.html#quiz-1-basic-descriptives",
    "title": "2  Descriptive Statistics",
    "section": "\n4.2 Quiz 1 – Basic Descriptives",
    "text": "4.2 Quiz 1 – Basic Descriptives\n\nHow many participants are in the sample? \nWhat is the mean value of Optimism? \nFor which of the variables is the spread in the scores highest? \nSATIS\nOPTIM\nNEGEMO\nThe minimum and maximum observed scores for Negative Emotions were: [, ].\nWhat percentage of participants is a non-smoker? \nWhat percentage of participants is in a relationship? \n\n:::\n\n4.2.1 Weighted Mean\nSuppose Class A (n = 12, mean = 6) and Class B (n = 8, mean = 7) are merged.\nSPSS effectively multiplies each mean by its n, sums those products, and divides by the total 20 students, yielding 6.4.\nQuick SPSS route\n\nMerge the two files if separate (Data &gt; Merge Files).\n\nRun Analyze &gt; Descriptive Statistics &gt; Descriptives on the combined score column.\n\n4.2.2 Step 4 – Finding Erroneous Values\nOne reason to inspect descriptives first is to spot erroneous values (e.g., age 511 instead of 51).\nUse the descriptives to find any out-of-range values, then:\n\n\nData &gt; Sort Cases\n\nSort the suspect variable ascending or descending\n\nDelete rows with invalid values\n\nAt this stage we remove entire cases; later you’ll learn gentler missing-data techniques.\n\n4.2.3 Step 5 – Group Comparison with Split File\nResearch question: “Are non-smokers more satisfied with life than smokers?”\n\n\nData &gt; Split File &gt; Compare Groups → choose Smoke\n\nRun Analyze &gt; Descriptives on Life Satisfaction\n\n\nSPSS now outputs separate means for smokers and non-smokers.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Descriptive Statistics</span>"
    ]
  },
  {
    "objectID": "chapter2_descriptive_statistics.html#quiz-2-group-means",
    "href": "chapter2_descriptive_statistics.html#quiz-2-group-means",
    "title": "2  Descriptive Statistics",
    "section": "\n4.3 Quiz 2 – Group Means",
    "text": "4.3 Quiz 2 – Group Means\n\nWas there an erroneous value in the data file? Enter it here: \nIf you delete that value, how will the mean change? \nBecomes larger\nStays the same\nBecomes smaller\nIf you delete that value, how will the standard deviation change? \nStays the same\nBecomes smaller\nBecomes larger\nWho is more satisfied in this sample? \nNon-smokers\nSmokers\nDoes this difference necessarily hold in the population? \nCan’t tell\nYes\nNo\n\n\n4.3.1 Step 6 – Quick Check: How Recoding Affects Spread\nAdd 10 points to every Life-Satisfaction score:\n\n\nTransform &gt; Compute Variable\n\nTarget variable: SATIS_plus10\n\nNumeric expression: SATIS + 10 → OK\n\n\nRun Descriptives on both variables:\n\nMean shifts up by 10\n\nSD is unchanged\n\nMultiply by 3 (expression SATIS * 3):\n\nMean × 3\n\nSD × 3",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Descriptive Statistics</span>"
    ]
  },
  {
    "objectID": "chapter2_descriptive_statistics.html#more-descriptive-statistics",
    "href": "chapter2_descriptive_statistics.html#more-descriptive-statistics",
    "title": "2  Descriptive Statistics",
    "section": "\n4.4 More Descriptive Statistics",
    "text": "4.4 More Descriptive Statistics\nDescribing the data is an essential first step in any research context.\n\n4.4.1 Central Tendency by Hand\nGrades: 6 3 4 6 7 6 8 9 10 9\nCompute mean, median, mode by hand.\n\n\nRemind me how\n\n\nMode = most common value\n\nMedian = middle value (or midpoint)\n\nMean = sum / n\n\n\n\n\n4.4.1.1 Quiz 3 – Hand Computation\n\nMean \nMedian \nMode \n\n\n4.4.2 Variation by Hand\nGrades: 2 7 6 7 8 9\nCompute variance and standard deviation.\n\n\nRemind me how\n\nVariance = average squared distance from mean\nSD = √ variance\n\n\nWhy divide by n – 1?\nAfter the mean is fixed, only n – 1 deviations are free to vary, so dividing by n – 1 keeps the sample variance unbiased.\n\n\n4.4.2.1 Quiz 4 – Hand Computation\n\nVariance \nStandard Deviation \n\n\n4.4.3 Verifying in SPSS\nEnter the six grades, name the variable, then:\n\n\nAnalyze &gt; Descriptive Statistics &gt; Descriptives\n\n\nOptions… &gt; Variance → Continue &gt; OK\n\n\nConfirm SPSS matches your hand calculations.\n\n\n\n\nHoijtink, H., Bruin, J. de, Duken, S. B., Flores, J., Frankenhuis, W., & Lissa, C. J. van. (2023). The Open Empirical Cycle for Hypothesis Evaluation in Psychology. https://doi.org/10.31234/osf.io/wsxbh\n\n\nPeikert, A., Ernst, M. S., & Brandmaier, A. M. (2023). Why does preregistration increase the persuasiveness of evidence? A Bayesian rationalization [Preprint]. https://osf.io/cs8wb. https://doi.org/10.31234/osf.io/cs8wb\n\n\nVan Lissa, C. J. (2022a). Developmental data science: How machine learning can advance theory formation in Developmental Psychology. Infant and Child Development, 32(6), 1–12. https://doi.org/10.1002/icd.2370\n\n\nVan Lissa, C. J. (2022b). Complementing preregistered confirmatory analyses with rigorous, reproducible exploration using machine learning. Religion, Brain & Behavior, 0(0), 1–5. https://doi.org/10.1080/2153599X.2022.2070254",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Descriptive Statistics</span>"
    ]
  },
  {
    "objectID": "Chapter3_Correlation.html",
    "href": "Chapter3_Correlation.html",
    "title": "\n3  Bivariate Descriptive Statistics\n",
    "section": "",
    "text": "3.1 Covariance\nThe word “covariance” means: varying, or moving, together. Let’s have a look at mock data from five students on hours studied and final grade obtained:\nset.seed(2)\ngrads &lt;- data.frame(\n  Hours = round(runif(5, 2, 20))\n)\ngrads$Grade &lt;- round(scales::rescale(.7*grads$Hours + rnorm(5), to = c(1, 10)))\nknitr::kable(grads)\n\n\n\nHours\nGrade\n\n\n\n5\n3\n\n\n15\n9\n\n\n12\n6\n\n\n5\n1\n\n\n19\n10\nWe can visualize these data using a “scatterplot”; a simple graph where each observation is shown as a dot with X-coordinate determined by their value on the X variable (Hours), and Y-coordinate determined by the Y variable (Grade):\nlibrary(ggplot2)\nggplot(grads, aes(x = Hours, y = Grade)) + geom_point() + theme_bw()\nNotice that, if you squint, it appears like there might be some pattern in the data: more hours studied tends to go hand in hand with a higher grade. There might be a positive association between these variables! In the next sections, we go about quantifying this association numerically, step by step.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bivariate Descriptive Statistics</span>"
    ]
  },
  {
    "objectID": "Chapter3_Correlation.html#covariance",
    "href": "Chapter3_Correlation.html#covariance",
    "title": "\n3  Bivariate Descriptive Statistics\n",
    "section": "",
    "text": "3.1.1 Sum of Products (SP)\nThe first stage in quantifying the association between two variables is to compute the sum of products of deviations (SP). The SP is similar to the sum of squares (SS), but whereas the SS captures the variability of one variable, the SP measures how two variables vary together.\nTo calculate the SP, take the following steps:\n\n3.1.1.1 Step 1: Calculate the variables’ means\nTake the mean of each column (bold in the table below):\n\nlibrary(kableExtra)\nmns &lt;- grads\nmns[] &lt;- lapply(mns, as.character)\nmns &lt;- rbind(mns, colMeans(grads))\nnames(mns) &lt;- c(\"X\", \"Y\")\nkable(mns) |&gt;\n  kable_styling() |&gt;\n  row_spec(nrow(mns),bold=T,hline_after = T)\n\n\n\nX\nY\n\n\n\n5\n3\n\n\n15\n9\n\n\n12\n6\n\n\n5\n1\n\n\n19\n10\n\n\n11.2\n5.8\n\n\n\n\n\n\n3.1.1.2 Step 2: Calculate Deviations\nFor each variable, calculate the deviations by subtracting the mean from the observed scores:\n\nlibrary(kableExtra)\ndevs &lt;- grads\ndevs &lt;- cbind(devs, sweep(devs, 2, colMeans(devs)))\nnames(devs) &lt;- c(\"X\", \"Y\", \"X-mean(X)\", \"Y-mean(Y)\")\nkable(devs)\n\n\n\nX\nY\nX-mean(X)\nY-mean(Y)\n\n\n\n5\n3\n-6.2\n-2.8\n\n\n15\n9\n3.8\n3.2\n\n\n12\n6\n0.8\n0.2\n\n\n5\n1\n-6.2\n-4.8\n\n\n19\n10\n7.8\n4.2\n\n\n\n\n\n\n3.1.1.3 Step 3: Multiply Deviations\nIf we were to calculate the SS, we would now square the deviations and add them up in each column. To get the SP, instead of squaring the deviations - we multiply them across variables. Note that if the deviations for both variables have the same sign, then this will give a positive result (positive times positive is positive, and negative times negative is positive too). Moreover, if the deviations from both variables are high, the product will be a high number too. So the SP tends to be a large positive number if high positive (or negative) deviations on one variable go hand in hand with high positive (or negative) deviations on the other variable.\n\nprods &lt;- devs\nprods &lt;- cbind(prods, apply(devs[, 3:4], 1, prod))\nnames(prods)[5] &lt;- \"Product\"\nkable(prods)\n\n\n\nX\nY\nX-mean(X)\nY-mean(Y)\nProduct\n\n\n\n5\n3\n-6.2\n-2.8\n17.36\n\n\n15\n9\n3.8\n3.2\n12.16\n\n\n12\n6\n0.8\n0.2\n0.16\n\n\n5\n1\n-6.2\n-4.8\n29.76\n\n\n19\n10\n7.8\n4.2\n32.76\n\n\n\n\n\nNow, we calculate the SP just by taking the sum of the column of products: 92.2.\nNote that if the SP is positive, then there is a positive association between the variables; if it is negative, there is a negative association. In this case, the association is positive.\nHere is a formula describing what we just did: we took the sum \\(\\Sigma\\) of the product \\(()()\\) of the deviations of X from the mean of X, \\(X-\\bar{X}\\) times the deviations of Y from the mean of Y, \\(Y-\\bar{Y}\\):\n\\[\nSP = \\sum \\bigl(X - \\bar{X}\\bigr)\\bigl(Y - \\bar{Y}\\bigr)\n\\]\n\n3.1.2 Covariance\nTo get the covariance from the sum of products, we divide by the sample size, so in this case, \\(\\frac{92.2}{5}\\).\nAnother way to think about this is: we standardize the SP by the sample size \\(n\\). This gives us the “average co-deviation” per participant. That number is called the covariance.\nIf the covariance is positive, there is a positive association between the two variables. If it is negative, there is a negative association.\nBut how strong is the association? It is hard to say, because the size of the covariance depends on the units and scale of the two variables involved.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bivariate Descriptive Statistics</span>"
    ]
  },
  {
    "objectID": "Chapter3_Correlation.html#correlation",
    "href": "Chapter3_Correlation.html#correlation",
    "title": "\n3  Bivariate Descriptive Statistics\n",
    "section": "\n3.2 Correlation",
    "text": "3.2 Correlation\nTo answer the question of how strong the association is, we must standardize the covariance to drop the units of both variables. This gives us the so-called Pearson correlation coefficient (r). Specifically, the covariance is divided by the product of the standard deviations of X and Y. This standardization results in a number between -1 and +1, where 0 means no association, -1 means perfect negative association, and +1 means perfect positive association. This number, the correlation coefficient, tells us both the direction (-/+) and strength (value) of association between two variables. Because the correlation coefficients is unit-free, or standardized, it can also be compared across variables measured on different scales and across studies.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bivariate Descriptive Statistics</span>"
    ]
  },
  {
    "objectID": "Chapter3_Correlation.html#limitations",
    "href": "Chapter3_Correlation.html#limitations",
    "title": "\n3  Bivariate Descriptive Statistics\n",
    "section": "\n3.3 Limitations",
    "text": "3.3 Limitations\nWhile correlation coefficients are useful, they must be interpreted with care.\nTo illustrate the limitations of correlations, the statistician Anscombe (1973) created four data sets with identical correlation coefficients, \\(r = 0.82\\). When plotting the data, however, it becomes clear that the correlation coefficient can only be meaningfully interpreted for the first dataset (figure a below).\n\nplts &lt;- lapply(1:4, function(i){\n  df &lt;- anscombe[, paste0(c(\"x\", \"y\"), i)]\n  names(df) &lt;- c(\"X\", \"Y\")\n\n  ggplot(df, aes(x = X, y = Y)) + geom_point(shape = 21, size = 3, fill = \"orange\") + theme_linedraw()\n})\nggpubr::ggarrange(plotlist = plts, ncol = 2, nrow = 2, labels = \"auto\")\n\n\n\n\n\n\nFigure 3.1: Anscombe’s quartet, 1973\n\n\n\n\nThe first and most important limitation is that, Pearson’s correlation coefficient only meaningfully captures linear associations, or: patterns that look like a straight line. Note that figure a in Figure 3.1 shows such a linear pattern of association; the correlation coefficient of \\(r = .82\\) tells us that there is a strong - but not perfect - positive association.\nFigure b in Figure 3.1 , on the other hand, shows a perfect non-linear association. All dots are perfectly in line; the line is just not straight. This illustrates that Pearson’s correlation coefficient is not suited for capturing non-linear patterns, even if a strong relationship exists in another form.\nFigure c shows a correlation of \\(r = 1\\) for most of the points - but one outlier brings it down to \\(r = .82\\).\nFigure d shows no association at all for most of the points (they all have the same value for X, and if X does not vary, it cannot covary/correlate with Y) - but a single outlier makes it look like there is a strong correlation..\nSecondly, these plots illustrate that outliers can have a disproportionate impact. In figures c and d, a single extreme observation artificially deflates (c) or inflates (d) the correlation coefficient, potentially leading to misleading conclusions.\nThirdly, a restricted range of scores can obscure or distort relationships. For example, if you were to examine the pattern in figure b of Figure 3.1 for values of X between [4, 9], you would conclude that \\(r = 0.99\\), or near perfect positive correlation. If you examined the same pattern for values of X between (0, 13), you would conclude that \\(r = -0.07\\), or near-zero. If you examined the same pattern for values of X between [13, 20), you would conclude that \\(r = -1.00\\), or perfect negative correlation. Figure Figure 3.2 below zooms into the pattern from figure b, by restricting the range of variable X into three segments:\n\ndf &lt;- anscombe[, paste0(c(\"x\", \"y\"), 2)]\nnames(df) &lt;- c(\"X\", \"Y\")\np1 &lt;- ggplot(df[df$X &lt;= 9, ], aes(x = X, y = Y)) + geom_point(shape = 21, size = 3, fill = \"orange\") + theme_linedraw()+ geom_smooth(method = \"lm\", se = FALSE)\np2 &lt;- ggplot(df[df$X &gt; 9 & df$X &lt; 13, ], aes(x = X, y = Y)) + geom_point(shape = 21, size = 3, fill = \"orange\") + theme_linedraw() + geom_smooth(method = \"lm\", se = FALSE)\np3 &lt;- ggplot(df[df$X &gt;= 13, ], aes(x = X, y = Y)) + geom_point(shape = 21, size = 3, fill = \"orange\") + theme_linedraw() + geom_smooth(method = \"lm\", se = FALSE)\nggpubr::ggarrange(p1,p2,p3, ncol = 3, nrow = 1, labels = \"auto\")\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\nFigure 3.2: Zooming in on panel b of Anscombe’s quartet, restricting the range of X\n\n\n\n\nRestriction of range can easily happen in real life. For example, if your sample only consists of university students, you will probably havce restriction of range on IQ.\nFinally, you may have heard the phrase correlation does not imply causation. Observing a strong association between two variables does not mean that one causes the other. In general, it is not possible to conclude causality from statistics: causality is an assumption, which can be either supported by a theory, or by a particular methodology. In a randomized controlled experiment, participants are randomly assigned to receive either a treatment or control condition. Thus, any differences between the two groups should be due to the experimental treatment, or random chance. We will revisit the topic of causality later.\nAnscombe’s quartet is a good illustration of the limitations of causality, and also demonstrates the value of visually inspecting your data (including with scatter plots) before interpreting any statistics.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bivariate Descriptive Statistics</span>"
    ]
  },
  {
    "objectID": "Chapter3_Correlation.html#summary",
    "href": "Chapter3_Correlation.html#summary",
    "title": "\n3  Bivariate Descriptive Statistics\n",
    "section": "\n3.4 Summary",
    "text": "3.4 Summary\nIn summary, covariance offers an initial metric for gauging whether two variables tend to vary in the same or opposite direction. However, because its magnitude depends on the measurement units of the variables involved, it cannot be directly interpreted in terms of strength. The Pearson correlation coefficient (r) addresses this limitation by standardizing the covariance, yielding a unit-free statistic bounded between –1 and +1. This standardized measure expresses both the direction and strength of a linear relationship, enabling meaningful comparisons across contexts. Nevertheless, interpreting correlations requires caution, particularly with respect to restricted sampling ranges, the influence of outliers, and the fundamental distinction between correlation and causation.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bivariate Descriptive Statistics</span>"
    ]
  },
  {
    "objectID": "Chapter3_Correlation.html#load-data",
    "href": "Chapter3_Correlation.html#load-data",
    "title": "\n3  Bivariate Descriptive Statistics\n",
    "section": "\n5.1 Load Data",
    "text": "5.1 Load Data\nOpen LAS_SocSc_DataLab2.sav (find it in the data folder you downloaded earlier).\nThe file contains six variables (X1 … X6). You’ll inspect three bivariate relationships.\n\n5.1.1 Plot the pairs\nGenerate three simple scatterplots:\n\n\nGraphs › Legacy Dialogs › Scatter/Dot ► Simple Scatter\n\nPairings & axis order\n\n\nX1 (X-axis) vs X2 (Y-axis)\n\n\nX3 (X-axis) vs X4 (Y-axis)\n\n\nX5 (X-axis) vs X6 (Y-axis)\n\n\n\n\nPaste and Run each syntax block.\n\nDescribe linearity, direction, and strength for each plot.\n\n“The relationship between X1 and X2 is positive.” \nTRUE\nFALSE\n“The relationship between X5 and X6 is positive.” \nTRUE\nFALSE\n“The relationship between X1 and X2 is linear.” \nTRUE\nFALSE\n“The relationship between X3 and X4 is linear.” \nTRUE\nFALSE\nStrength of X1–X2:\nmoderate\nstrong\nweak\nzero\nStrength of X3–X4:\nstrong\nweak\nzero\nmoderate\nStrength of X5–X6:\nstrong\nweak\nzero\nmoderate\n\n\n5.1.2 Correlation coefficients\nEven when the pattern is non-linear it’s useful to see why Pearson r can mislead.\nAnalyze › Correlate › Bivariate\nSelect all six variables → OK.\n\nX1–X2 correlation: \nX2–X6 correlation: \nX3–X4 correlation: \nCan we interpret X3–X4’s r at face value?\nNo, assumption of association violated\nNo, assumption of linearity violated\nNo, assumption of normality violated\nYes, otherwise SPSS would give an error\nInterpret X5–X6:\nWeak negative\nModerate negative\nWeak positive\nModerate positive\n\nTake-away: Pearson’s r is good at detecting linear patterns (like X1–X2), but it may be close to zero even when the variables have a strong curved pattern (like X3–X4).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bivariate Descriptive Statistics</span>"
    ]
  },
  {
    "objectID": "Chapter3_Correlation.html#correlation-work-dataset-work.sav",
    "href": "Chapter3_Correlation.html#correlation-work-dataset-work.sav",
    "title": "\n3  Bivariate Descriptive Statistics\n",
    "section": "\n5.2 Correlation – Work Dataset (Work.sav)",
    "text": "5.2 Correlation – Work Dataset (Work.sav)\nHaving practiced on simulated data, let’s now apply the same workflow to a real dataset related to the workplace.\n\nFile location: data/Work.sav\n\n\n5.2.1 Why inspect the plot first?\nBefore trusting Pearson r we check for\n\nan approximately linear pattern, and\n\n\nextreme values that could distort the statistic.\n\n\nSelect the correct reason:\n\nTo check if the relationship is linear\nTo check if the relationship is positive\nTo check if the relationship is strong enough\n\n\n5.2.2 Create the scatter-plot\nGraphs › Legacy Dialogs › Scatter/Dot → Simple Scatter\n\nX-axis =scmental (Mental Pressure)\n\nY-axis =scemoti (Emotional Pressure)\n\nPaste and Run.\n\nThe cloud of data points is roughly linear: \nTRUE\nFALSE\nThere are obvious outliers: \nTRUE\nFALSE\nApproximate strength:\n\nModerately strong and positive\nModerately weak and positive\nModerately strong and negative\nModerately weak and negative\n\n\n5.2.3 Compute Pearson r\n\nAnalyze › Correlate › Bivariate → (scmental, scemoti) → OK\nThe correlation coefficient is (2 decimals): \nInterpretation:\n\nThere is a relationship between mental and emotional pressure.\nThere is no relationship between mental and emotional pressure.\nWe cannot draw a conclusion on whether or not there is a relationship.\nTake-away: Mental and emotional pressure show a moderately strong, significant positive relationship—employees who feel more mentally pressured also tend to feel more emotionally pressured.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Bivariate Descriptive Statistics</span>"
    ]
  },
  {
    "objectID": "probability.html",
    "href": "probability.html",
    "title": "4  Probability Distributions",
    "section": "",
    "text": "5 Lecture\nVIDEO ERRATA: from 10:10 - 10:50 I talk about the probability of Being Dutch and Having a Tattoo, but I’m calculating the probability of Being Dutch and Not Having a Tattoo (I misread the column labels).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Probability Distributions</span>"
    ]
  },
  {
    "objectID": "probability.html#normal-distribution",
    "href": "probability.html#normal-distribution",
    "title": "4  Probability Distributions",
    "section": "\n7.1 Normal Distribution",
    "text": "7.1 Normal Distribution\nIn this assignment you will practice with the normal distribution.\nThe normal distribution deserves special attention as it is commonly used in statistics for the social sciences. The normal distribution was already derived in the 18 century by DeMoivre, Adrian, and also Gauss*, and since then it played a central role in statistics. More importantly, many attributes in the social sciences are by close approximation normally distributed, as was first discovered by Quetelet. Hence, the normal distribution has great empirical relevance, which comes in handy for our research!\n\nFor that reason, the normal distribution is sometimes referred to as a Gaussian curve.\n\nBefore we start, the concept of a random variable needs to be introduced first. A random variable is a numerical outcome of a chance experiment.\nFor example, a random variable is the number of pips when throwing two dice (here the chance experiment is throwing two dice). Also, the proportion of girls in a random sample of 10 children is a random variable (here the chance experiment is the random selection of 10 children).\nWe also distinguish between continuous and discrete (categorical) random variables.\nA continuous variable can take on infinitely many values. For example, the height of a person is a continuous variable. Take any two persons of different height, and we can always find a third person in between. Discrete variables can take on only particular values. For example, the number of correct of correct answers when a person blindly guesses all the answers is a discrete random variable.\n\nif you want to know, see for example Wikipedia\n\nNormal distributions are distributions for continuous random variables.\nLet’s first have another look at different examples of normal distributions:\n\n\n\nDist.\n\\(\\mu\\)\n\\(\\sigma\\)\n\n\n\n1\n–1.0\n0.5\n\n\n2\n0.5\n0.5\n\n\n3\n0.5\n1.5\n\n\n4\n2.0\n1.0\n\n\n\nInspection of the graphs of the bell-shape distributions shows that it is a symmetric distribution. We also see that the distributions differ in location (the point on the x-axis where it reaches its maximum) and the spread. In other words, the distribution is characterized by two parameters: the mean and standard deviation. The mean is denoted by the Greek letter \\(\\mu\\) (pronounced as “moo”) and standard deviation is denoted by the Greek letter \\(\\sigma\\) (pronounced as “sigma”).\nCompare the distributions and see how the parameters determine the location (mean) and spread (standard deviation).\n\n7.1.1 Quiz\n\nCorrectly complete the sentence below by filling in the gaps:\nGiven the example “A student guesses the correct answer to 10 multiple choice questions with four answer categories each” the random experiment is \nguessing the correct answer\nthe correct answer\nthe 4 answer categories\nthe number of correct answers and the random variable is \nthe 4 answer categories\nguessing the correct answer\nthe number of correct answers\nthe correct answer.\nAre the following random variables discrete or continuous?\nNumber of heads in 10 throws with a fair coin is continuous. \nTRUE\nFALSE\nTime by train from Tilburg to Eindhoven is continuous. \nTRUE\nFALSE\nThe number of correct answers on a test is continuous. \nTRUE\nFALSE\nThe mean height in a random sample is continuous. \nTRUE\nFALSE\nThe average number of correct answers in a random sample of 100 students is continuous. \nTRUE\nFALSE\nIf the standard deviation (SD) increases, the distribution becomes \nnarrower\nwider\n\n\n7.1.2 “The Empirical Rules”\nAs a first step we may consider some practical rules for working with the normal distribution, the so called “empirical rules”. In particular, if a random variable is normally distributed the following empirical rules apply:\n68% of the values lie within one standard deviation from the mean. 95% of the values lie within two standard deviations from the mean.\nIf we know that a variable is normally distributed, we can also compute probabilities of certain outcomes, so called events. For example, if we know that the scores on a test are normally distributed, we may want to know the probability that a randomly selected person has a score above a certain cut-off (i.e., satisfies a certain selection criterion).\nIn the next few steps, you will practice on how to compute probabilities under the normal distribution. To do so, we have to be able to work with the standard normal distribution (Z-distribution) and accompanying tables.\n\n7.1.3 Quiz\n\nComplete the following sentences:\nIQ scores are normally distributed with mean 100 and an SD of 15. This means that 95% of the persons in the population has an IQ in between \n70\n85\n15\n55 and \n130\n100\n115\n145.\nStudents loan after completing the bachelor is normally distributed with mean 1500 Euros and an SD of 150. This means that 68% of the students ends up with a loan between \n1200\n1485\n1350\n1000 and \n1450\n1515\n1650\n1800.\nWhat is the mean of the standard normal distribution? \nWhat is the SD of the standard normal distribution? \n\n\n7.1.4 Calculating probabilities\nFor the next series of exercises you need to use a Z-table or calculator (e.g., Excel, Google Sheets, R online, or the Z-table in this GitBook, Appendix A).\nWe have seen that probabilities are related to the area under the curve. This means that for continuous variables we can only find the probability that the outcome falls within a certain interval. For example, the time to complete a task is more than 10 minutes; the IQ is in between 70 and 90.\nNote that there may be different ways to get to the correct answer.\nNumerical Examples\n\n7.1.5 Quiz\n\nConsider a continuous variable X, which is normally distributed with \\(X \\sim(\\mu = 30, \\sigma = 4)\\).\nCompute the following probabilities:\nP(X&gt;36.8): \nP(X&lt;24): \nP(X&lt;35): \nP(28&lt;X&lt;34): \n\n\nExplanation\n\nP(X&gt;36.8):\n\nTransform X into Z: (36.8 − 30)/4 = 1.7\nRead Upper Tail Area for Z = 1.7, which equals 0.0446\nConclusion: P(X&gt;36.8)= 0.0446.\n\nP(X&lt;24):\n\nTransform X into Z: (24 − 30)/4 = -1.5\nBecause the Z-distribution is symmetric, we know that P(Z&lt;−1.5) is equal to P(Z&gt;1.5). The latter probability can be found in the Z-table, which is 0.0668. This is also the probability we are looking for.\nConclusion: P(X&lt;24) = 0.0668.\n\nP(X&lt;35):\n\nThe probability we are looking for equals 1− P(X&gt;35). Thus, we first need P(X&gt;35).\nCompute corresponding Z-value: Z = = 1.25.\nLook for the upper tail area in the Z-table: P(Z&gt;1.25) = .1056.\nThus, the area we are looking for is 1 − .1056 = .8944\nConclusion: P(Z&lt;35) = 0.89444\n\nP(28&lt;X&lt;34):\n\nRemark: there are different ways to come the answer. So the answer below is just one of few possibilities.\nWe need the area under curve between 28 and 34. This area equals 1 minus the tail areas; that is, P(28&lt;X&lt;34) = 1 − P(X&lt;28) − P(X&gt;34)\nLets start with P(X&gt;34). First compute Z= = 1. Via the Z-table we find P(Z&gt;1)= .1587.\nNow determine P(X&lt;28). First compute Z= = −0.5. Via the Z-table we find P(Z&lt;−0.5) = P(Z&gt;0.5) = .3085.\nHence, we have 1 − 0.1587 − 0.3085 = 0.5328\nConclusion: P(28&lt;X&lt;34) = 0.5328.\n\n\nStudents are looking for a new roommate. They read in an article that the time people spend under the shower is in the population normally distributed with mean of 10 and SD of 8 (measured in minutes). Suppose they randomly select a person as their new roommate.\nWhat is the probability that this randomly selected person will spend more than 20 minutes under the shower? \nSuppose “confidence in society” is measured on a continuous scale from 0 (no confidence at all) to 100 (highly confident). Also suppose that confidence is normally distributed in the population with mean 52.6 and SD of 12. One speaks of low confidence if the score falls below 43.\nWhat percentage of the population has low confidence? \nThe scores on a test for aggressive behavior are normally distributed with mean 50 and SD of 10. The test is used to select police officers. In particular, only police officers with scores between 42 and 62 qualify for the job as they are not too aggressive and not too friendly either.\nWhat percentage of the population qualifies as police officer? \n\n\nExplanations\n\nLet X denote time people spend under the shower. We want to know the probability that the person showers for more than 20 minutes; that is, P(X&gt;20) given \\(\\mu\\) = 10 and \\(\\sigma\\) = 8.\nCompute Z value: (20 −10)/8 =1.25. Hence, we need P(Z&gt;1.25); that is, the area beyond Z = 1.25.\nVia the Z-table (look in the column labelled C) we find: P(Z&gt;1.25) = .1056.\nConclusion: the probability that a random selected person will shower more than 20 minutes is 0.106 (about 11%).\nLet X stands for the confidence level. X is normally distributed with mean = 52.6 and SD = 12. We need P(X&lt;43). That is, we need the area under the curve to the left of 43.\nFirst, transform to Z-scores: X=43 =&gt; Z = (43 −52.6)/12 = −0.8. Thus, we need P(Z&lt;−.8).\nThe left-tail areas are not shown in the Z-table. Therefore, to find the area, we will first look for the area in the other tail; that is, we will look for P(Z&gt;0.8) in the Z-table. The probability equals 0.2119. Because the distribution is symmetric, the left tail area is also 0.2119. This gives us the answer.\nConclusion: about 21.2% in the population has low confidence in society.\nLet X be the test scores. We need to compute P(42&lt;X&lt;62). This area can not be directly found in the Z-table, so we have to take some additional steps. First, because the whole area under the curve is 1, we can say that the area we are looking for is equal to 1 minus the areas in the tail; thus, 1 − P(X&lt;42) − P(X&gt;62). These latter probabilities can be read from the Z-table!\nCompute Z-values: 1 − P(Z&lt;−0.8) − P(Z&gt;1.2). Remember that \\(Z = \\frac{Observed-mean}{SD}\\).\nDetermine the tail areas: because the distribution is symmetric, we have P(Z&lt;−0.8)=P(Z&gt;0.8). The latter can found in Z-table, which equals .2119. Probability P(Z&gt;1.2) can be directly read from the Z-table, which is .1151.\nHence, 1 − .2119 − .1151 = 1−.327 = .673.\nConclusion: 67.3% of the population qualifies as police officer.\n\nSuppose the time to complete a certain task is normally distributed with mean 8.6 and standard deviation (SD) of 3.5.\nWhat is the probability that a randomly selected person needs more than 11.4 minutes to complete the task? \nAgain, suppose the time to complete a task is normally distributed with mean 8.6 and standard deviation of 3.5.\nComplete the sentence:\n“95% of the participants completes the task within 1.6 and  minutes.”\nScores on a selection test are normally distributed with a mean of 500 and a standard deviation of 50. A person qualifies for the job if they score between 480 and 580.\nWhat is the probability that a randomly selected person will qualify for the job? \nAn IT company is looking for new programmers. To qualify for the job the programmers need to score high on conscientiousness. Therefore, the job applicants need to complete the Conscientiousness scale from the NEO-PI-R (a popular personality inventory for the Big Five personality traits*) as part of the selection procedure. Research has shown that in the population the scores on the scale are normally distributed with a mean of 133.4 and SD of 18.3. To qualify for the job, the conscientiousness of the programmer needs to be among the highest 20% in the population.\nWhat cut-off should the company use to select new personnel? Round to a whole number. \n\nThe Big Five is a popular model for personality; see Wikipedia for more info on the Big Five.\n\n\n\nExplanations\n\nQuestion 1:\n\nTransform X into Z: (11.4 -8.6)/3.5 = 0.8\nRead Upper Tail Area for Z = 0.8, which equals 0.2119\nConclusion: P(X&gt;36.8)= 0.212\n\nQuestion 2:\n95% of the participants completes the task within 1.6 and 15.6 minutes. You can use the empirical rule that 95% of the observations falls within 2SDs from the mean. Thus, 95% of the observations lies within 8.6−2×3.5 and 8.6+2×3.5\nAnd 8.6+2×3.5 = 15.6\nQuestion 3:\nWe need P(480&lt;X&lt;580). This probability equals 1 − P(X&lt;480) − P(X&gt;580).\nP(X&lt;480) = P(Z&lt;−0.4) = P(Z&gt;0.4) = 0.3446 (via Z-table)\nP(X&gt;580) = P(Z&gt;1.6) = P(Z&gt;1.6) = 0.0548 (via Z-table)\nSo the final answer equals: 1−0.3446−0.0548=0.6006 (0.601 when rounded at three decimal places).\nQuestion 4:\nTo get to the correct answer, these are the steps: - First find the Z-value that marks the highest 20%. This value equals 0.84. - Then compute the corresponding cut-off on the X-scale: X = 0.84×18.3 + 133.4 = 148.772 - Rounded to the nearest integer equals 149.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Probability Distributions</span>"
    ]
  },
  {
    "objectID": "probability.html#missing-values",
    "href": "probability.html#missing-values",
    "title": "4  Probability Distributions",
    "section": "\n7.2 Missing Values",
    "text": "7.2 Missing Values\nFor this assignment, and also later assignments, we will use a (real) data set on Type D personality and several background characteristics (age, gender, and education level (7 ordered levels)).\nType D personality is defined as the tendency towards negative affectivity (NA) (e.g., worry, irritability, gloom) and social inhibition (SI) (e.g., reticence and a lack of self-assurance). Theory suggests that Type D individuals have poorer health outcomes.\nType D is measured with the DS14 scale. The DS14 consists of 14 items, 7 measuring NA and 7 items measuring SI. Answers are given on a five point scale (scored 0 through 4).\n\nsee also Type D personality on Wikipedia.\n\nOpen the data file TypeDDataSSC.sav in SPSS. The data file contains the scores on the DS14 items measuring Type D as well as the background variables for 80 respondents.\nGo to the variable view. The content of the items are given under labels and it is indicated whether the item measures NA or SI.\n\n7.2.1 Quiz\n\nIs the first item in the DS14 an indicator of NA or SI? \nNA\nSI\nGo to the data view in SPSS and inspect the data.\nDo you see any missings? \nNo\nYes\nWhat is the valid N of the variable age? \nHow many system missings do we have on gender? \n\n\n7.2.2 Recoding missing values\nRemember that Empty cells are called system missings. There are reasons to use user-specified missing codes instead; for example, this allows you to keep track of reasons for missingness (which enables you to report more comprehensively on your missing data).\nSo, for this exercise we will define a user-missing code for the missing values. Missing code is number that a researcher uses to designate that the value is missing. The code must be chosen such that it cannot be confused with actual scores. For example, for age the missing code can be 999, because 999 is an impossible age.\nNow, we will first define missings for age.\nGo to the data view; look at the values of age and whenever the value is missing fill in 999. (In total three persons had a missing on age; so you have to fill in 999 three times).\nGo to the variable view. We have to define the missing code under missing. Click on the cell and […], and SPSS opens a new window. Define 999 as missing code.\nIn the previous step we filled in the missing codes manually. For a small data set this is okay, but for large data sets (say thousands of persons on many variables) this would be problematic.\nIn the next few steps we will see how we can define the missings more easily.\nTo do so, we will use the function recode in SPSS. We will first apply the recoding to gender.\nBefore going into the recoding, let’s first look at the frequency table for gender.\nYou may already have this output from answering the Quiz.\n\n7.2.3 Recode into Same Variables\nReplacing user missing values with a missing code using the recode option works as follows:\nNavigate to Transform &gt; Recode into the same variables. SPSS opens a new window.\nSelect gender as the variable to be recoded.\nClick on Old and New Values. SPSS opens a new window. In this window we can specify the recoding. In our case we want to recode System Missing into 999. So, choose “system missing” as old Value, and specify 999 as new value, and click on Add below. (See the more info section below for the SPSS specifications.)\nClick on Continue, and click on OK. SPSS now replaced system missing by 999. Go to the data view and verify that SPSS filled in 999 at the empty places.\nGo to the variable view and specify 999 as the user missing code for gender. (In the same way as you did for age).\nCompute the frequency table for gender again.\nVerify that all “system missings” are now reported as “user missings” instead.\nIn the previous step we only recoded the missings for gender, but we could do that for all variables. It is most convenient to use a code that can be used for all variables. In this case we can use 999 as the missing code for all variables, it’s easy because we can apply this recoding to all variables at once. Just follow the same steps as before, but now select all variables to recode.\nRun the recode command for all variables.\nVerify in the data file that SPSS replaced all system missings by 999.\nNow we also have to specify in the variable view that 999 is the missing codes for all variables. We already changed it for age and gender. To do the same thing for other variables is easy; you can just use copy-paste! Click on Missing for gender, click on the right mouse button, choose copy. Go to the next variable, click on the right mouse button, and with paste you can define the missings for other variables.\nTip: If you like shortcuts: you can also click on missing, type Ctrl C, and then use Ctrl V to copy the information about the missings.\nSo, we specified the missing codes, but we also want to know for each respondent how many missings values he or she had. In other words, for each participant we want to count the number of missings. Participants with too many missings may be excluded from further analysis. Counting the number of missings per person can also be easily accomplished in SPSS.\nTransform &gt; Count Values within Cases. SPSS opens a new window. Specify the name of the target variable (e.g., CountMiss); this is the name of a new variable that gives the number of missings. You may also give the variable a label, say: “Number of Missings”.\nSelect all variables.\nClick on Define Values. SPSS opens a new window. Select System or User Missing at the left and click on add. Click on continue than OK.\nSPSS will now create a new variable that shows how many missings there are for each person on the variables selected in the list.\nGo to the data view and verify that SPSS added a new variable (i.e., a new column with values) named CountMiss.\n\n7.2.4 Quiz\n\nCompute the frequency table for the third DS14 item. How many missing values do we have on this item? \nHow many missings does person 8 have, using the variable CountMiss? \nCompute the frequency table for CountMiss.\nWhat is the maximum number of missings for the participants in this dataset? \nHow many participants have this many missings? \nHow many participants have at least one missing value? \n\nMake sure you save the data file including the variable with the number of missings. We will use it in the next assignment. `",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Probability Distributions</span>"
    ]
  },
  {
    "objectID": "probability.html#select-cases-and-split-file",
    "href": "probability.html#select-cases-and-split-file",
    "title": "4  Probability Distributions",
    "section": "\n7.3 Select Cases and Split File",
    "text": "7.3 Select Cases and Split File\nIn this assignment we will take a closer look at selecting cases and how to do analyses for subgroups.\n\n7.3.1 Selecting Cases\nIn the previous assignment we have seen that some respondents had one or more missing values. Suppose we want to discard these persons in the analysis, which means that for all the remaining analyses we only want to include participants with no missings. This method of handling missing data is called listwise deletion, and it is generally considered bad practice - but it’s also easy, so we will teach it in this course. More advanced courses cover expert methods of handling missing data.\nProceed as follows:\nData &gt; Select cases. SPSS opens a new window.\nChose “If condition is satisfied” and chose ‘if’. SPSS opens a new window again.\nSpecify the condition CountMiss = 0 to select cases with no missings.\nMake sure that the output is specified as “Filter out unselected cases”. Click on OK.\nGo to the data view.\nVerify that SPSS crossed out cases with one or more missings.\nVerify that SPSS added a new variable labelled ‘filter_$’. This is filter variable indicating who is included in the analyses (value = 1) or not (value is 0). If you remove the filter variable, SPSS will use all cases again.\n\n7.3.2 Quiz\n\nWhat is the mean for the variable age of the selected group? \nWhat is the valid sample size for that mean? \n\nNow, run the selection procedue again, but remove the incomplete cases from the data file.\nProceed as follows:\nData &gt; Select cases Choose “Delete Unselected Cases” under output. Click OK. Verify that the incomplete cases are removed.\nBecause you have modified the data, it is prudent to save the new file under a different name (e.g., TypeD_selection.sav). Use this file with only the complete cases (i.e., TypeD_selection.sav) for the remaining steps.\n\n7.3.3 Split File\nSometimes we want to do analyses for subgroups, especially when exploring the data for the first time. For example, we may want to have the descriptive statistics for males and females separately. One way to do this is to use the Split File option. With this option you can tell SPSS that you want to have tables for each subgroup separately.\nLet’s see how it works!\nProceed as follows:\nVia menu follow Data &gt; split file. SPSS opens a new window.\nChoose ‘Compare Groups’ and choose gender as the variable for Groups Based on.\nClick OK.\nImportant: Notice no output appears and no changes are made to the data. This makes sense because we haven’t asked SPSS to generate any output nor to make changes in the data. Yet, SPSS now knows that he has to produce tables for males and females separately once we ask to generate output.\nTo undo the split file, proceed as follows.\nData &gt; Split file Choose Analyze all cases, do not create groups. Click OK. SPSS now no longer produces the output per group.\n\n7.3.4 Quiz\n\nHave SPSS compute the mean and SD for age.\nHow many women are there in the sample?  What is the mean age of men in the sample?  What is the mean age of women in the sample? \nOne of the variables is Education Level. It is an ordinal variable with 7 levels, score 1 represents the lowest level of education, and score 7 the highest.\nCompute the mean age per level of education.\nFor which education level was the mean age highest? \nWhat was the value of the mean age for this education level?",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Probability Distributions</span>"
    ]
  },
  {
    "objectID": "probability.html#recode-and-compute",
    "href": "probability.html#recode-and-compute",
    "title": "4  Probability Distributions",
    "section": "\n7.4 Recode and Compute",
    "text": "7.4 Recode and Compute\nFor this assignment we will continue with the data on Type D and the selection of complete cases.\nBefore you start, make sure that the Split File option is disabled.\nIn practice, you often have to do some data handling before you can actually start doing analyses. For example by coding missing values, or you may have questionnaire data for which some of the questions are formulated contra-indicative and therefore should be reverse coded. Another reason would be that you may have to compute the total score (e.g., sum or average) for a set of questions.\nIn this assignment we will practice some basic data handling skills.\n\n7.4.1 Reverse Scoring Contra Indicative Items\nIf you read the item labels, you will see that the first two SI items (items DS14_1 and DS14_3 in the scale) are contra indicative. This means that for these items higher scores reflect low SI, while for other items higher scores reflect high SI. Therefore, the responses to these items should be recoded first to make sure that all items are scored in the same direction. To do so, we will create new variables that reflect the recoded items. Proceed as follows:\nTransform &gt; Recode into different Variables\nChoose DS14_1 as the Numerical Variable to be recoded\nSpecify a name for the output variable (say DS14_1R)\nGive a label, say: “SI item 1 (recoded)”\nClick on change\nDo not close the window yet, but continue to the next step…\nTo recode, we have to specify the Old Values and New values. Reverse scoring of the DS14 items means that\nold value 0 -&gt; new value 4\nold value 1 -&gt; new value 3\nold value 2 -&gt; new value 2 (*)\nold value 3 -&gt; new value 1\nold value 4 -&gt; new value 0\n(*) You may think this line is superfluous but for the recoding in SPSS you need to specify for every possible value a recoded new value, even if the values remains the same.\nSpecify the old and new values. Each time you specified old and new values click on ADD such that the recoding scheme appears in the little dialog.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Probability Distributions</span>"
    ]
  },
  {
    "objectID": "probability.html#using-syntax",
    "href": "probability.html#using-syntax",
    "title": "4  Probability Distributions",
    "section": "\n7.5 Using Syntax",
    "text": "7.5 Using Syntax\nTo ensure that others can see exactly how you got from raw data to the final dataset used for analysis, it is essential to keep a complete record of any changes made to the data. This is also why we previously argued that you should not overwrite a datafile after altering it.\nUp until now, we ran the analyses by “click-and-point” via the menu. This is a good starting point to explore the software SPSS, but it is not good practice for professional use because there’s no record of what you did to the data in order to get your result.\nNOTE: For all your portfolio assignments, providing syntax is mandatory so I can grade what you DID, not just what you reported!\nTo keep a record of changes made to your data, you can prepare a script that contains all instructions for the analysis instead. By evaluating this script on the data, you should consistently get the same results.\n\n7.5.1 Why syntax?\nUsing syntax is important for several reasons:\n\nFirst, efficiency: it makes life easier. Once you have the syntax, you can easily redo the whole analysis without going through all the points-and-clicks again.\nSecond, communication: When you work together on research projects, it is important that you exactly understand the analyses that were done, even if you didn’t do the analyses yourself. By using syntax, all team members can see what has been done and how.\nThird, documentation & data management: As a researcher you are responsible for data storage and management (!). This not only includes storage of data, but also documentation of the all the steps and analyses you did to come to your results (e.g., handling missing values, detection of outlying values). Ideally, you should provide the materials such that other researchers can easily replicate your analyses starting from the raw data file. Working with SPSS syntax is a great way to do so.\nFourth, necessity: some statistical procedures are only available via SPSS syntax (e.g., simple effects analysis in MANOVA).\n\n\n7.5.2 Help!\nYou don’t need to memorize the commands by heart. SPSS offers help functions. If you highlight the command (e.g., statistics) and click on the button with the paper and the question mark in the top menu. SPSS opens a help file.\nUse the help function to modify the syntax such that SPSS produces a table that also reports the range (e.g., the difference between the largest and smallest value).\n\n7.5.3 How to use syntax\nThere are two ways to use syntax. The first is to create an empty syntax script via File -&gt; New -&gt; Syntax, and then start adding the code from scratch. You can either write the code as text, or create it via SPSS’ various dialog windows. For this course, we recommend using the dialogs:\n\nIn any dialog window, click “Paste” instead of “OK”.\nA new window opens (or existing window comes into focus) with a script file (or “syntax” file). The instructions for the requested analysis are added at the bottom of this file.\nSelect all instructions you wish to execute, and press the green “Play” button.\nYou can re-organize this script file, adding, or removing operations or changing their order. Keep it nice and organized!\n\n\n\nSyntax for recoding\n\nSelect the highlighted lines and press the green “Play” button. Verify in the data view that SPSS added a new variable (i.e., new column) with the recoded values for Item 1.\nSyntax is also useful because it may be more straightforward than the graphical interface. For example, the recode syntax above took a lot of pointing and clicking to get:\nRECODE DS14_1 (0=4) (1=3) (3=1) (4=0) INTO DS14_1R.\nEXECUTE.\nFor recoding more variables, we can copy-paste these instructions and change the variable names.\nFor example, to recode DS14_3 in the same way as you did the recoding for DS14_1 we would write:\nRECODE DS14_1 (0=4) (1=3) (3=1) (4=0) INTO DS14_1R.\nRECODE DS14_3 (0=4) (1=3) (3=1) (4=0) INTO DS14_3R.\nEXECUTE.\nAlternatively, we could simply say:\nCOMPUTE DS14_1R = 4-DS14_1.\nCOMPUTE DS14_3R = 4-DS14_3.\nEXECUTE.\nVerify that this calculation also works.\n\n7.5.4 Commenting\nWhen working with syntax, it is highly recommended to add comments as reminders to your future self of the purpose of each step in the script. These comments should clarify the syntax and give general information (e.g., when was the syntax last modified, who did the modifications, etc.).\nComments are text lines that start with an * and ends with a dot. Comments are printed in grey.\nREMARK: the dot at the end of your text line is really important. If you do not add it, your syntax will run work properly!\nAdd comments including the following information:\n\nWhen was the syntax made?\nWho made syntax?\nWhat does the syntax do?\n\nFor example (CJ is short for Caspar J. Van Lissa):\n* CJ: This script also recodes Likert scales with integer values.\nCOMPUTE DS14_1R = 4-DS14_1.\nCOMPUTE DS14_3R = 4-DS14_3.\nEXECUTE.\nAfter including the comments, run the complete syntax including the comment line (by selecting and running it, or via top menu Run &gt; All).\nIf the syntax runs correctly, the comments were correctly included.\n\n7.5.5 Compute Variable\nFor the analyses we are not interested in the single item scores but in the summed scores. Because the DS14 contains two subscales (consult the item labels to see to which subscale the item belongs), we want to compute the summed scores for the NA and SI items separately.\nLet’s first do this for NA. Proceed as follows:\nTransform &gt; Compute variable. SPSS opens a new window.\nChoose a name for the target variable, say: NAtotal.\nUnder numerical expression you have to say what you want to compute. In this case the sum of the NA items, which is DS14_2 + DS14_4 + … etc. So, select the first item to be summed from the list at the left, type +, select the next item you want to add, and so on. Make sure that you only add up the NA items (in the variable view you can see which items measure NA and which measure SI).\nClick Paste, and run the code.\nAlternatively, copy-paste this syntax, complete it and run it:\nCOMPUTE NAtotal = DS14_2 + DS14_4 + .\nCOMPUTE SItotal = .\nEXECUTE.\n\n7.5.6 Quiz\n\nCompute the frequency table for the recoded DS14_3 item.\nWhat percentage of the respondents had the highest score on this item? \nWhat is the mean of NAtotal? \nCompute the mean of NAtotal for men and women separately. For which group is the mean highest? (Hint: Use the skills you’ve learned in the previous assignments). \nWomen\nMen\nCompute the total scores for SI. Make sure you use the reverse scored items for items 1 and 3 to compute the total score (this implies you have to leave the original item 1 and 3 out).\nWhat is the mean of SI in the total sample? \nWhat is the mean for the subsample of men?",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Probability Distributions</span>"
    ]
  },
  {
    "objectID": "samplingdistribution.html",
    "href": "samplingdistribution.html",
    "title": "5  The Sampling Distribution",
    "section": "",
    "text": "6 Lecture\nVIDEO ERRATA: from 19:40 - 19:50 I incorrectly report the probability of P(Z &gt; 1) as .025, but it is .16.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The Sampling Distribution</span>"
    ]
  },
  {
    "objectID": "samplingdistribution.html#sampling-distribution",
    "href": "samplingdistribution.html#sampling-distribution",
    "title": "5  The Sampling Distribution",
    "section": "\n8.1 Sampling Distribution",
    "text": "8.1 Sampling Distribution\nComplete the following sentences:\nIQ scores in the population of potential students are normally distributed with mean 120 and an SD of 10. If a cohort contains 75 students, 95% of cohorts will have an average IQ in between \n100\n117.69\n118.27\n118.85 and \n121.73\n130\n121.15\n122.31.\nAfter graduating, a cohort of 75 LAS students can expect to earn a starter salary of 2650 Euros, with an SD of 300 euros. What percentage of cohorts will have a mean starter salary greater than 2750 euros? \n4%\n0.2%\n99%\n2%.\nIn a sample of 5000 babies, the average birthweight is 3.213 kg, with an SD of 254 grams. What is the mean birthweight of the sampling distribution? \nBetween 3202.22 and 3223.78 grams\nCan’t say\n3.213 kg\nConsider a continuous variable X, which is normally distributed with \\(X \\sim(\\mu = 30, \\sigma = 4)\\). We draw a sample of 15 participants. What is the probability that the sample mean will be smaller than 32? \nThe proportion of male babies is .51. Assume babies born in each hospital in a given month constitute a random sample of size 100. The standard error of a proportion is given by \\(\\sqrt(p*(1-p) / n) = \\sqrt(.51*.49 / 100) = 0.05\\). What proportion of hospitals will have more than 60% male babies?",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The Sampling Distribution</span>"
    ]
  },
  {
    "objectID": "samplingdistribution.html#in-spss",
    "href": "samplingdistribution.html#in-spss",
    "title": "5  The Sampling Distribution",
    "section": "\n8.2 In SPSS",
    "text": "8.2 In SPSS\n\n8.2.1 SE for Means\nOpen the file called student_questionnaire.sav.\nThese are data from a previous cohort of students. Note that we have data about biometric differences (e.g., age, height, shoesize), as well as school-related questions (which program they are enrolled in), variables about their love for statistics, and about moral preferences (based on the “Morality As Cooperation” questionnaire that I helped develop).\nGo to Analyze -&gt; Descriptives and ask for descriptive statistics on height and shoesize. Click Options, and notice that there’s an option to request the standard error of the mean. Select this option, then paste and run your syntax. Check if it corresponds to the syntax below.\n\n\nAnswer\n\nDESCRIPTIVES VARIABLES=height\n  /STATISTICS=MEAN STDDEV MIN MAX SEMEAN.\nNote the SEMEAN option was added by clicking that option!\n\nThe mean length in the population of Dutch people is 177.434. With this in mind, calculate the probability that a random sample of the same size as this sample would have the mean length you calculated for this sample or smaller. \n\n\nExplanation\n\nThe question asks for the lower-tail probability below a value of 174.62 in a distribution with mean 177.434 and SD .772 (the SE you obtained from SPSS).\n\\(\\frac{174.62-177.34}{.772} = -3.65\\)\nA Z-score of nearly -4, so this probability is going to be extremely small, &lt; .001.\n\n\n8.2.2 SE for Proportions\nGo to Analyze -&gt; Compare Means -&gt; One Sample Proportions.\nThis procedure allows you to estimate proportions and their standard errors. It’s not very common, in fact I learned about it by Googling “standard error for proportion spss”! Any time you need to know how to do something in SPSS, you can find advice on the internet.\nCalculate the proportion for the variable sex, and paste and run your syntax.\n\nPROPORTIONS\n  /ONESAMPLE sex TESTVAL=0.5 TESTTYPES=MIDP SCORE  CITYPES=AGRESTI_COULL JEFFREYS WILSON_SCORE \n  /SUCCESS VALUE=LAST\n  /CRITERIA CILEVEL=95\n  /MISSING SCOPE=ANALYSIS USERMISSING=EXCLUDE.\n\nNote the table labelled “One-Sample Proportions Confidence Intervals”. This table contains confidence intervals for the proportion, calculated according to three different procedures. In the lecture, you also learned a procedure to calculate confidence intervals.\nUsing the procedure from the lecture, calculate a 95% confidence interval for the proportion. You can round the Z-score for this confidence interval to 2.\nThe 95% CI for the proportion of male students is [, ].\nNote that the differences between this procedure and the three procedures in the table only differ in the third decimal.\nHow do you interpret a confidence interval?\n\nThe range of likely population values.A range of values that contains the population parameter with 95% certainty.The population value, with a 95% margin of error.A range of values that, 95% of the time, contains the population parameter.\n\n\n8.2.3 SE for Correlation\nRecall from the first lecture that the correlation coefficient is a measure of linear association between two variables, or: a descriptive statistic that describes how strongly two continuous variables are associated.\nGo to Analyze -&gt; Correlate -&gt; Bivariate. Add the variables work_hours and study_hours, paste and run the syntax.\nThe value of the correlation coefficient is labelled “Pearson Correlation”. What value do you observe? \nThe correlation coefficient ranges from 0-1 (or minus 1). With this in mind, answer the following question:\nTrue or false: This correlation coefficient is near zero. \nTRUE\nFALSE\nThe calculation of a standard error is a bit more complicated, but there’s an “approximation” (a quick approach that gives reasonable results in some cases, but could be wrong in other cases). It is calculated as:\n\\[\nSE_r = \\sqrt{\\frac{1-r^2}{n-2}}\n\\]\nCalculate the SE this way. What is its value? \nAssume for a moment that the true population correlation is zero (r = 0). Using the SE you calculated, what would then be the probability of observing a correlation between 0 and the correlation you actually observed? \n\n\nExplanation\n\nThe question asks for the probability between the mean (0) and a value of .057 in a distribution with mean 0 and SD .075 (the SE you calculated).\nSo we first calculate the right-tailed probability for the value of .057.\n\\(Z = \\frac{.057-0}{.075} = 0.76\\)\nA Z-score of 0.76, so the right-tailed probability is 0.22.\nThen, take .5 (the probability to the right of 0), and subtraCT .22: .28",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>The Sampling Distribution</span>"
    ]
  },
  {
    "objectID": "Week_4.html",
    "href": "Week_4.html",
    "title": "6  Philosophy of Science",
    "section": "",
    "text": "6.1 Deduction and Induction in Hypothesis Testing\nHypothesis testing has roots in the philosophy of logic, or correct reasoning. In logic, arguments consist of a set of premises, which can be true or false, that together lead to a conclusion, which can also be true or false. The most famous example is:\nThis is a deductive argument, which has the property that if the premises are true, then the conclusion must also be true. Deductive arguments are also often thought of as arguments from the general to the specific. In this case, the general rule “all men are mortal” gives rise to the specific claim that one specific man, Socrates, is also mortal.\nThe counterpart to deductive reasoning is inductive reasoning, which proceeds from specific observations or claims to general rules. The most famous example is:\nUnlike the deductive argument above, however, inductive reasoning does not guarantee that true premises always produce true conclusions. Even if it is true that I have only seen white swans, the conclusion is false - black swans exist. David Hume introduced another famous example:\nHere, too, the conclusion is not supported by the premise. This might make us feel uncomfortable - which sane person would reject the conclusion that the sun will rise in the east tomorrow? This discomfort illustrates that people are naturally inclined to reason inductively. As scientists, however, we should be very cautious to remember that this way of reasoning is not guaranteed to produce true conclusions.\nInductive and deductive reasoning are both used in statistical hypothesis testing. Deduction is used when we derive a specific prediction (hypothesis) from a general theory. For example, we could say that:\nIf the premise is true, then we would expect to observe the corresponding pattern in our data.\nInduction comes into play when we draw general conclusions from observed data.\nThis conclusion does not logically follow from the premise. The problem is not resolved by removing the word “causes”:\nIt follows that we can never conclusively “prove” general conclusions from specific observations. The philosopher David Hume wrote extensively about this “problem of induction”: How can we justify the assumption that unobserved cases will follow the same patterns as observed ones? Hume argued that this assumption cannot be logically justified. Our sense that generalization is justified might be based on intuition, but not logic. The problem of induction challenges the very foundation of science. We cannot escape the use of induction when seeking to learn general insights from specific observations, but Hume showed that induction lacks a purely rational justification.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Philosophy of Science</span>"
    ]
  },
  {
    "objectID": "Week_4.html#deduction-and-induction-in-hypothesis-testing",
    "href": "Week_4.html#deduction-and-induction-in-hypothesis-testing",
    "title": "6  Philosophy of Science",
    "section": "",
    "text": "Premise: All men are mortal\n\n\nPremise: Socrates is a man\n\n\nConclusion: Therefore, Socrates is mortal.\n\n\n\n\n\n\n\nPremise: All swans I have ever seen are white\n\n\nConclusion: Therefore, all swans are white.\n\n\n\n\n\n\nPremise: The sun has risen in the east every morning up until now.\n\n\nConclusion: The sun will also rise in the east tomorrow.\n\n\n\n\n\n\n\nPremise: More time spent studying causes better grades.\n\n\nConclusion: In my dataset, time spent studying should correlate positively with grades.\n\n\n\n\n\n\n\nPremise: I observed a positive correlation between time spent studying and grades in my dataset\n\n\nConclusion: Therefore, time spent studying causes better grades.\n\n\n\n\n\n\nPremise: I observed a positive correlation between time spent studying and grades in my dataset\n\n\nConclusion: Therefore, time spent studying correlates positively with grades in the general population of students.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Philosophy of Science</span>"
    ]
  },
  {
    "objectID": "Week_4.html#falsificationism",
    "href": "Week_4.html#falsificationism",
    "title": "6  Philosophy of Science",
    "section": "\n6.2 Falsificationism",
    "text": "6.2 Falsificationism\nIt follows from the problem of induction that it is impossible to definitively prove a theory to be true. No matter how much evidence I have observed that supports a theory (white swans), all it takes is one refuting observation (black swan) to reject is. Karl Popper sought to avoid the problem of induction by devising a scientific method that relies exclusively on deduction: falsificationism. Popper demarcated the distinction between “pseudo-science” and science by arguing that “[scientific] statements […] must be capable of conflicting with […] observations” (Popper 1962, 39). The core business of science, according to Popper, should be to try to reject theories. Note that - while Popper’s work has been heavily criticized (for good reasons), his work is very influential in social science. Therefore, Popper is a good starting point for our course - even though he probably should not be the endpoint for students with a genuine interest in philosophy of science.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Philosophy of Science</span>"
    ]
  },
  {
    "objectID": "Week_4.html#falsificationism-and-hypothesis-testing",
    "href": "Week_4.html#falsificationism-and-hypothesis-testing",
    "title": "6  Philosophy of Science",
    "section": "\n6.3 Falsificationism and Hypothesis Testing",
    "text": "6.3 Falsificationism and Hypothesis Testing\nThe idea of falsificationism has been very influential in applied statistics in the social sciences, particularly in the practice of “Null-Hypothesis Significance Testing” (NHST). In NHST, researchers proceed as follows:\n\nDevelop a testable proposition about a population parameter; for example:\n\n“On average, my students understand the course material. Their mean grade is \\(\\mu \\geq 6\\)”.\n“On average, there is a positive association between hours studied and grade, \\(\\rho \\geq 0\\)”.\n\n\nDevelop a second hypothesis whose sole purpose is to be rejected, to pay lip service to falsificationism. Call this the “null hypothesis”. The “null hypothesis” is often taken to be the exact opposite of the researcher’s true belief, or “alternative hypothesis”:\n\n“On average, my students DO NOT understand the course material. Their mean grade is \\(\\mu &lt; 6\\)”.\n“On average, there is NO positive association between hours studied and grade, \\(\\rho &lt; 0\\)”.\n\n\nExecute a procedure to make a decision to reject (falsify) or not reject the null hypothesis (next chapters).\nIf the null hypothesis is rejected, act as if this finding supports the alternative hypothesis.\n\nAs argued by Andrew Gelman in this blog post, this approach only pays lip service to falsificationism. A true falsificationist would put their true belief (alternative hypothesis) to the test. Fake falsificationism is creating a meaningless, “straw man” null-hypothesis, whose sole purpose is to be rejected.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Philosophy of Science</span>"
    ]
  },
  {
    "objectID": "Week_4.html#moving-forward",
    "href": "Week_4.html#moving-forward",
    "title": "6  Philosophy of Science",
    "section": "\n6.4 Moving Forward",
    "text": "6.4 Moving Forward\nWhere does this leave us? The most important point is that there are important limitations to commonly used methods, including null-hypothesis significance testing. There is no real satisfying solution. Just keep in mind that no statistical test can give evidence in support of a theory or hypothesis; neither a null nor an alternative hypothesis.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Philosophy of Science</span>"
    ]
  },
  {
    "objectID": "Week_4.html#causality",
    "href": "Week_4.html#causality",
    "title": "6  Philosophy of Science",
    "section": "\n6.5 Causality",
    "text": "6.5 Causality\nAnother crucial philosophical issue relevant for statistics is the question of causality. Scientists are often interested in causal questions. We assume causality, for example, any time we want to act on knowledge derived from scientific research. For example, say that I do find a strong correlation between hours studied and grade obtained. If, based on this finding, you increase your study hours in order to improve your grade - then you are assuming causality. The same applies for governments making evidence-based policy, companies adjusting sales strategies based on customer analytics, or drugs that replenish a particular neurotransmitter that has been found lacking in patients with a specific diagnosis.\nDespite the fact that causality is so important in scientific research, it is rarely defined. Contemporary definitions are typically based on counterfactuals: A is a cause of B if B would not have happened if A had not happened. This definition has important limitations, but it is sufficient for our course (Halpern, 2015).\nMost people have heard the phrase “correlation does not imply causation”. What does this mean? One important misunderstanding is that the correlation coefficient is an inappropriate statistic for investigating causal research questions. This is not the case. This phrase warns us that, just because observe a statistical association between variables X and Y (for example, a correlation of \\(r = .43\\)), that does not mean that X caused Y. Importantly, observing this correlation is consistent with a causal effect of X on Y - but also with other explanations. For example, maybe Y caused X, or maybe a third variable caused both X and Y, and that is why they are correlated.\nThe problem is related to the previous section: observing a pattern in data that is consistent with a causal association between X and Y cannot conclusively prove that X caused Y, no matter what statistic you use to describe the pattern.\nSo where does causality come from? The short answer is: from theory or methodology. Causality can be assumed on theoretical grounds, or established using a randomized controlled experiment. In such an experiment, researchers randomly assign participants to either an experimental condition (e.g., receiving a drug, instruction, treatment, et cetera), or a control condition (e.g., receiving a placebo, no instruction, non-effective treatment, et cetera). The random assignment should, theoretically, result in two groups with no systematic differences that could explain between-group differences in the outcome of interest. Of course, due to pure chance, it could happen that there are systematic differences (more men in one group, taller people in one group, et cetera). But there is no procedure that has a better chance of resulting in comparable groups than random assignment.\nIn the social sciences, experiments are not always feasible or ethical, so researchers often use observational data. Does this preclude all causal claims? It does not. It is perfectly legitimate to present a theory that predicts a causal effect in the Introduction section of your scientific writing, and then present empirical data that show a pattern consistent with that effect. For example, if I assume that hours studied causes improved grades, a correlation of \\(r = .43\\) is consistent with that assumption. An alternative explanation might be that having receiving high grades in the past has motivated some students to study harder. Just make sure not to take the observed data as evidence for a causal effect.\nWhat is required to argue that X has a causal effect on Y? Several philosophers have addressed this issue; most notably Hume and Mill (see Morabia, 2013). The necessary conditions for causality are sometimes summarized as association, temporal precedence, and non-spuriousness. Below, each is supported with quotes from Hume (1902)1:\n\n\nAssociation: Cause and effect must be associated (this could be statistical association)\n\n“When one particular species of event has always […] been conjoined with another, we […] call the one object, Cause; the other, Effect.” (VII, II, 59)\n“familiar objects or events to be constantly conjoined together” (V, I, 35) There must be a “constant union” between cause and effect, and they must be “contiguous in space and time” (Hume 1739,16, pp. 173–175).\n\n\n\nTemporal precedence: The cause must occur before the effect.\n\nobserve a continual succession of objects, and one event following another (V, I, 35)\n“[when] the same object is always followed by the same event; we then begin to entertain the notion of cause and connexion.” (VII, II, 61)\n\n\n\nNon-spuriousness: All alternative explanations of the effect are excluded.\n\n“Their conjunction may be arbitrary and casual. There may be no reason to infer the existence of one from the appearance of the other.” (describing spuriousness; V, I, 35)\n“we may define a cause to be an object, followed by another, and where all the objects similar to the first are followed by objects similar to the second. Or in other words where, if the first object had not been, the second never had existed.” (VII, II, 61)\n\n\n\nThis latter definition resembles the aforementioned counterfactual definition of causality. Note that this definition does not require randomized experimentation, but randomized experiments do help us meet all three criteria. The field of causal inference focuses on developing methods that can estimate causal effects (like you would get from a randomized controlled experiment) from observational data (Pearl, 2009).",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Philosophy of Science</span>"
    ]
  },
  {
    "objectID": "Week_4.html#assignment-1-hypothesis-testing---formulating-hypotheses",
    "href": "Week_4.html#assignment-1-hypothesis-testing---formulating-hypotheses",
    "title": "6  Philosophy of Science",
    "section": "\n9.1 Assignment 1: Hypothesis Testing - Formulating Hypotheses",
    "text": "9.1 Assignment 1: Hypothesis Testing - Formulating Hypotheses\nDiscuss with your portfolio group the logic behind hypothesis testing, and how it relates to your personal (and group’s) research interests.\nConsider the following three research descriptions. Formulate H0 and H1 in words. Discuss your answers with your group members.\nResearchers want to know whether it matters for test performance if an exam is completed on a computer or using paper and pencil. Hence, the research question reads: Is there an effect of the type of administration (computer or paper and pencil) on the test performance?\nWhat would be the H0 and HA for this study?\n\n\nShow answer\n\nThis appears to be an undirected hypothesis about a mean difference for two independent samples, without a clearly specified alternative hypothesis. Thus, we could state:\n\\(H_0: \\mu_{computer} = \\mu_{paper}\\) \\(H_A: \\mu_{computer} \\neq \\mu_{paper}\\)\n\nResearchers want to know whether the alcohol consumption among Dutch students differs from the alcohol consumption in the general Dutch population. Using CBS statistics, they know that in the general population the average alcohol consumption is 5.6 glasses a week. The question is whether the average alcohol consumption among students is different from this national average.\nWhat would be the H0 and H1 for this study?\n\n\nShow answer\n\nThis appears to be an undirected hypothesis about the difference between a mean and a hypothesized value, without a clearly specified alternative hypothesis. Thus, we could state:\n\\(H_0: \\mu = 5.6\\) \\(H_A: \\mu \\neq 5.6\\)\n\nResearchers want to study whether social isolation is associated with income.\nWhat would be the H0 and H1 for this study?\n\n\nShow answer\n\nThis appears to be an undirected hypothesis about an association between two variables, without a clearly specified alternative hypothesis. We could thus state:\n\\(H_0: \\rho = 0\\) \\(H_A: \\rho \\neq 0\\)\n\nFormulating the hypothesis is an important very first step in hypotheses testing. Continue with the next assignment, in which we will go through the steps of a hypothesis test.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Philosophy of Science</span>"
    ]
  },
  {
    "objectID": "Week_4.html#assignment-2-test-statistics-alpha-and-significance",
    "href": "Week_4.html#assignment-2-test-statistics-alpha-and-significance",
    "title": "6  Philosophy of Science",
    "section": "\n9.2 Assignment 2: Test Statistics, Alpha and Significance",
    "text": "9.2 Assignment 2: Test Statistics, Alpha and Significance\nIn this assignment we will go through the steps of a hypothesis test.\nWhile going through the steps we will come across the most important concepts related to hypothesis testing.\nFor the next steps, we consider the following situation:\nSuppose we are interested in the personality profile of musicians; that is, we want to know whether, on average, personality characteristics of musicians differ from those of the general population. For now, we’ll only focus on Openness. We pretend that we have collected data among 25 musicians using a validated scale for which previous research has shown that in the general population the scores are normally distributed with mean 50 and SD 15. It is our task to test whether the mean of Openness for musicians differs from the mean in the general population. To keep things simple, we assume that in the population of musicians the SD is the same as in the general population; that is, we assume that LaTeX: \\(\\sigma = 15\\).\nLet openness be the variable of interest. Let \\(\\mu_{musicians}\\) represent the mean openness in the population of musicians. The hypothesis test amounts to testing:\n\\(H0: \\mu_{musicians} = 50\\)\n\\(H1: \\mu_{musicians} \\neq 50\\)\nNow, when we do the hypothesis test, we seek for evidence against the null hypothesis. More specifically, our testing procedure starts with the assumption that H0 represents the truth and as long as we don’t have convincing evidence that our assumption is false we stick to that assumption.\nThe question is, however, when do we have convincing evidence against H0?\nFinding evidence against H0 works as follows:\nIf H0 is true, we expect mean values close to H0. And, if we observe a mean value that is much different from the value under H0, we have convincing evidence against H0. If this happens, we reject H0 as representing the truth and accept the alternative hypothesis, H1.\nHypothesis testing fits Popper’s philosophy of falsification. He introduced this well-known analogy to explain the logic of falsificationism:\n\nSuppose we assume that all Swans are white, \\(H_0: Swans = white\\)\n\nWe would then not expect to observe black ones.\nIf we do observe black swans, our initial hypothesis is called into question.\nThe number of white swans we see (= observations consistent with the hypothesis) does not provide evidence for \\(H_0\\), because there could always be a black swan out there we haven’t observed yet.\n\nSo, the next questions are:\nWhat are the sample values we can expect under H0? When is evidence “convincing” enough? To answer the first question we have to go back to sampling distributions!\nFor the second question, we need a criterion. We have to realize that even if H0 is true, sample values can be far off just by sampling fluctuations (i.e., by chance). The common criterion is: if the observed value is among the 5% most unlikely samples under H0 (i.e. if H0 is true), we reject the null hypothesis.\nLet’s go back to our example about musicians.\nLet X be openness. Under H0 we assume that X is normally distributed with mean 50 and SD equal to 15.\nWhat are the mean and standard deviation of the sampling distribution of the mean under H0 given that the sample size is 25? And what do we call the standard deviation of the sampling distribution?\n(Use what you have learned in the previous lectures. Hint: first make a drawing of the situation, then do the computations).\n\n\nExplanation\n\nSampling distribution:\n\nMean: \\(\\mu = 50\\)\n\nStandard error ( =SD of sampling distribution!): \\(\\sigma_{\\bar{X}} = \\frac{15}{\\sqrt{25}}= 3\\)\n\n\n\nSuppose we want to indicate sample means that are unlikely if H0 would be true. In particular, we want to know how far the sample mean must be from the hypothesized mean to be among the 5% of all possible samples under H0 that are furthest away from the hypothesized means.\nWhat should the value of the sample mean be to fall within the 5% most deviant samples if the sample size is 25?\n\n\nExplanation\n\nWe are talking about the distribution of the mean; so we need to work with the sampling distribution. We want to know the cut offs that mark the 2.5% highest and 2.5% lowest means. We first have to find the Z-values: they are 1.96 for the highest 2.5%, and (by symmetry) -1.96 marks the 2.5% lowest.\nHence, to be among the 5% of all possible sample means that are most unlikely under H0, the sample mean should be:\nlarger than 50+1.96 x 3 = 55.88 or smaller than 50-1.96 x 3 = 44.12\n\nLet’s do some more exercises on the Z-test.\nSuppose the mean for Openness we found in our sample was 59.\nIf we use a significance level of 5%, would we reject the null hypothesis? \nYes\nNo\nIn the previous step we used cut offs for the sample means to decide about significance. The cut off scores were obtained via the Z-distribution. However, doing all these computations is not necessary (there’s a shortcut!!). In fact, if we know the Z-value for the sample, we can easily find out if the sample is among the 5% of the most unlikely sample means. We only have to compare the value with 1.96 and -1.96 to see whether that is the case.\nIn this course, we will use Z-values for different purposes. In these specific calculations, Z is used as a Test Statistic. A test statistic quantifies evidence against the null hypothesis. In this case, the Z test statistic expresses how far away from the mean under the null hypothesis the observed mean is, in terms of the number of standard errors.\nThe Z test-statistic follows the standard normal distribution. The values 1.96 and -1.96 are called the critical values and they mark the 5% most unlikely sample means under H0. In other words, the critical values mark the reject region for H0.\nSo, if we compute the Z-value for the sample mean, and if that sample value of Z falls in the rejection region, we reject H0 (we found something that is unlikely enough to no longer believe H0 is true). If H0 is rejected we speak of a significant result. See the graph below:\n\nFollowing these steps to test a mean is one example of performing a “Z-test”!\nWe can use the Z-test to test hypotheses about the population mean if we know the population \\(\\sigma\\).\nThe test statistic for the Z-test is:\n\\(z  = \\frac{\\bar{X}-\\mu_{H_0}}{\\sigma_{\\bar{X}}}\\)\nThis statistic is computed using the mean from the sample, the hypothesized mean under H0 and \\(\\sigma\\).\nH0 is rejected at the 5% significance level if z is either larger than 1.96 or smaller than -1.96.\nSo far, we rejected the null hypothesis if the sample is among the 5% most unlikely sample means under H0. This 5% was called the significance level, and is denoted as \\(\\alpha = .05\\). However, we could just as well choose 1% or .5%.\nWhat would be the critical values for the Z-test if one tests at \\(\\alpha = .01\\)? \nWhat would be the critical values for the Z-test if one tests at \\(\\alpha = .005\\%\\)? \nFor historical reasons, social scientists tend to use \\(\\alpha = 0.05\\) as a default. So in this course, if alpha is not explicitly stated, assume \\(\\alpha = 0.05\\).\nWhen we test hypotheses we reject H0 if the sample we find is unlikely if H0 is true. However, the flip side is that, even though H0 is true, we may find a sample that is much different by chance, and erroneously reject H0. Or, in other words, we could make an error. Rejecting H0 while it is true in reality is called a Type I error!\nConsider the following:\n\nIf H0 is true, and you test at \\(\\alpha = 0.05\\), what is the probability of committing a Type I error?\nWhat is the link between the \\(\\alpha\\)-level and type I error rate?\n\n\n\nExplanation\n\n\nIf H0 is really true (i.e., H0 should not be rejected), then the probability that the sample mean is among the 5% most unlikely is equal to 5%.\nThe alpha level specifies the risk of a Type I error. So if one tests at an alpha level of .05, it means that one accepts a risk of 5% to commit a Type I error.\n\n\nProperties of the Z-test:\nUsed to test hypotheses about the mean in a population, assuming \\(\\sigma\\) known.\nThe test-statistic equals \\(z = \\frac{\\bar{X}-\\mu}{\\sigma_{\\bar{X}}}\\)\nThe test statistic is normally distributed.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Philosophy of Science</span>"
    ]
  },
  {
    "objectID": "Week_4.html#assignment-3-z-test",
    "href": "Week_4.html#assignment-3-z-test",
    "title": "6  Philosophy of Science",
    "section": "\n9.3 Assignment 3: Z-test",
    "text": "9.3 Assignment 3: Z-test\nIn this assignment we will apply the Z-test.\nThis assignment first presents an example, followed by two practice questions.\nA researcher wants to test \\(H_0: \\mu = 50\\) against \\(H_1: \\mu \\neq 50\\)\nData are available from a random sample of 26 respondents. The mean was 53.7. The researcher assumes the SD in the population is 8.5. Perform all steps of the Z-test.\n\n\nExplanation\n\nStep 1: Formulate hypotheses\n\\(H_0: \\mu = 50\\) \\(H_1: \\mu \\neq 50\\)\nStep 2: Compute test statistic\nStandard error: \\(\\frac{8.5}{\\sqrt{26}}=1.667\\)\nTest statistic: \\(z = \\frac{53.7-50}{1.667}=2.212\\)\nStep 3: Decide about significance\n\\(\\alpha = .05\\), so critical values +/- 1.96.\nOur test statistic exceeds this critical value.\nThe sample mean thus falls in the rejection region, and we should conclude that the test is significant so \\(H_0\\) s rejected.\nStep 4: Draw conclusion\nWe have convincing evidence that the population mean differs from 50.\n\nA researcher wants to test whether the population mean is equal to 80. Data are available from a random sample of 60 respondents. The mean was 74. The researchers assume the SD in the population is 40. Perform and report all steps of the Z-test. What is the resulting p-value? \nA researcher wants to test whether the population mean is equal to 500. Data are available from a random sample of 75 respondents. The mean was 546. The researchers assume that the SD in the population is 200. Perform all steps of the Z-test. Use \\(\\alpha = .01\\). Perform and report all steps.\n\n\nShow answer\n\nStep 1: Hypotheses: \\(H_0: \\mu=500\\), \\(H_1: \\mu \\neq 500\\)\nstep 2: Compute Statistic:\n\nstandard error: \\(\\frac{200}{\\sqrt{75}} = 23.094\\)\n\ntest statistic: \\(z  = \\frac{546-500}{23.094}=1.992\\)\n\n\nStep 3: Decide about significance.\nZ does not exceed +/- 2.576. This means that Z does not fall in the reject region when tested at the 1% significance level. The test is not significant.\nStep 4: Draw conclusion\n\\(H_0\\) is not rejected.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Philosophy of Science</span>"
    ]
  },
  {
    "objectID": "Week_4.html#quiz",
    "href": "Week_4.html#quiz",
    "title": "6  Philosophy of Science",
    "section": "\n9.4 Quiz",
    "text": "9.4 Quiz\n\n“The null and alternative hypothesis are deduced from the data.” \nTRUE\nFALSE\n“When performing a hypothesis test, we start by assuming \\(H_0\\) is true.” \nTRUE\nFALSE\n“If we reject \\(H_0\\) with \\(\\alpha=0.05\\), then we will also reject it at \\(\\alpha=0.10\\), assuming all other quantities are held constant.” \nTRUE\nFALSE\n\n\nExplanation\n\nThe critical values of \\(\\alpha =0.05\\) are +/- 1.96. Hence, if \\(H_0\\) is rejected it means that z in the sample is larger than 1.96 or smaller than -1.96.”\nThe critical values of \\(\\alpha =0.1\\) are +/- 1.645. This means that for rejecting \\(H_0\\) at this alpha level, that z should be larger than 1.645 or smaller than -1.645. That is implied by the fact that it exceeds +/- 1.96.\n\n“If we reject \\(H_0\\), then \\(H_0\\) is surely wrong.” \nTRUE\nFALSE\n\n\nExplanation\n\nWe should always be aware of the possibility of making a Type I error. The probability of making a Type I error is equal to \\(\\alpha\\).\n\n“Increasing the sample size n (and holding all the rest constant) decreases the probability of a Type I error.” \nTRUE\nFALSE\n\n\nExplanation\n\nIncreasing the sample size n (and holding all the rest constant) does not decrease the probability of a Type I error.\nThe Type I error is determined by the alpha level.\nIf our sample is among the 5% most unlikely sample means of all possible sample means with the same size under \\(H_0\\), whatever that sample size N may be.\nIncreasing the sample size n (and holding all the rest constant) does not decrease the probability of a Type I error.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Philosophy of Science</span>"
    ]
  },
  {
    "objectID": "Week_4.html#assignment-4-z-test-and-alpha-levels",
    "href": "Week_4.html#assignment-4-z-test-and-alpha-levels",
    "title": "6  Philosophy of Science",
    "section": "\n9.5 Assignment 4: Z-test and Alpha-levels",
    "text": "9.5 Assignment 4: Z-test and Alpha-levels\nIn this assignment we will practice some more with the Z-test, meanwhile we will review important concepts of hypothesis testing. In particular, we will look at significance levels.\nTo test hypotheses, we need to specify the “significance level”, usually denoted by \\(\\alpha\\). The significance level is our decision criterion to reject H0.\nThe most common choice is .05. But what does this criterion exactly entail?\nDiscuss with your group what an \\(\\alpha\\) level entails.\n\n\nExplanation\n\nIf we test at an \\(\\alpha\\) of .05 it means that we are willing to reject H0 in favor of H1 if our sample mean belongs to the 5% most extreme scores (2.5% in each tail) under the null hypothesis.\nIf indeed the sample mean is among this 5%, it means that we have observed a sample in a range that is quite unlikely if the null hypothesis would be true and, therefore, justifies rejection of the null hypothesis.\n\nIn the previous assignments you already used the critical values for the Z-test for specific alpha levels.\nFor two-tailed tests, it holds that if the absolute value of Z exceeds the critical value, we may reject \\(H_0\\).\nLet \\(Z_\\text{crit}\\) be the critical value. For the Z-test it holds that:\n\n\n\\(Z_\\text{crit} = 1.65\\), if \\(\\alpha = 0.10\\) (two-tailed)\n\n\\(Z_\\text{crit} = 1.96\\), if \\(\\alpha = 0.05\\) (two-tailed)\n\n\\(Z_\\text{crit} = 2.58\\), if \\(\\alpha = 0.01\\) (two-tailed)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Philosophy of Science</span>"
    ]
  },
  {
    "objectID": "Week_4.html#quiz-1",
    "href": "Week_4.html#quiz-1",
    "title": "6  Philosophy of Science",
    "section": "\n9.6 Quiz",
    "text": "9.6 Quiz\n\nResearchers want to test whether \\(\\mu=70\\). They assume that \\(\\sigma = 10\\). Researchers found a mean of 72 in a random sample of 40 persons.\nTrue or false:\n\\(H_0\\) can be rejected at one of the three levels discussed above (\\(\\alpha = .10, .05, .01\\). \nTRUE\nFALSE\n“If the two-tailed test is significant at the 5% level, it will also be significant at the 1% level (keeping everything else fixed).” \nTRUE\nFALSE\n“If the two-tailed test is not significant at the 10% level, it won’t be significant at the 5% level either (keeping everything else fixed).” \nTRUE\nFALSE\n“If the two-tailed test is not significant at the 5% level, it could still be significant at the 10% level (keeping everything else fixed).” \nTRUE\nFALSE\n“If the two-tailed test is significant at the 1% level, it might not be significant at the 5% level (keeping everything else fixed).” \nTRUE\nFALSE",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Philosophy of Science</span>"
    ]
  },
  {
    "objectID": "Week_4.html#assignment-5-p-values",
    "href": "Week_4.html#assignment-5-p-values",
    "title": "6  Philosophy of Science",
    "section": "\n9.7 Assignment 5: P-values",
    "text": "9.7 Assignment 5: P-values\nWe will now focus on the interpretation of the p-values and how to use the p-values to decide about significance.\nConsider the following situation:\nScores on a test measuring confidence in police are normally distributed in the general population, with \\(\\mu = 500\\) and an \\(\\sigma = 50\\). Researchers want to know if the average confidence level is different for those who have been a victim of crime. They collect data for 60 victims. They find a sample mean of 511. They test \\(H_0: \\mu = 500\\) against \\(H_1: \\mu \\neq 500\\), while assuming that the population variance is \\(\\sigma = 50\\).\nCompute the p-value. Draw a graph for the two-tailed p-value. Write down in your own words and as precise as possible the interpretation of the p-value in the answer box below. Then, discuss your response with your group.\n\n\nExplanation\n\n\nThe p-value represents the proportion of all possible sample means that are further away from our hypothesized mean than the observed sample mean is.\nWe have the sampling distribution with \\(\\mu = 500\\) and \\(\\sigma_{\\bar{X}} = \\frac{50}{\\sqrt{60}} = 6.455\\).\nFirst, we compute the right-tail area: \\(P(\\bar{X} &gt; 511) = P(Z &gt; 1.70) = 0.0446\\).\nHence, 4.66% of all possible samples is further away from \\(H_0\\) on the right side.\nSecond, we compute the left-tail area. These are the sample means that are more than 11 points from the hypothesized mean to the left \\(P(\\bar{X} &lt; 489) = P(Z &lt; -1.70) = 0.0446\\).\nHence, the two-tailed p-value is 0.0892.\n\n\nIs the test significant at the 5% level? \nTRUE\nFALSE\nIs it significant at the 1% level? \nTRUE\nFALSE\nResearchers test whether \\(\\mu = 90\\). They assume that \\(\\sigma=21\\). The sample mean was 85. Sample size was 50.\nWhat is the two-tailed p-value? \nWhat is the highest level at which the test is significant? \n0.01\n0.1\n0.005\n0.05\nResearchers test whether \\(\\mu = 35\\). They assume \\(\\sigma =16\\). The sample mean was 38. Sample size was 64.\nCompute the two-tailed p-value and indicate which of the following statements is true.\n\nThe test is not significant at 10%, not significant at 5% and not significant at 1%.The test is significant at the 10% level, but not at 5% or 1% level.The test is significant at the 10% and 5% level, but not at the 1% level.The test is significant at the 10%, 5% level, and 1% level.\n\nConsider these true- or false statements:\nIf a two-tailed p-value is .0567 then the test is significant at the 10% level but not at the 5% level. \nTRUE\nFALSE\nIf a two-tailed test is significant at the 5% level but not at the 1% level, then the two-tailed p-value will be less than 0.01. \nTRUE\nFALSE\nA two-tailed p-value of 0.060 indicates that we have 6% chance that the null hypothesis is true. \nTRUE\nFALSE\n\n\n\n\nHalpern, J. Y. (2015, May 1). A Modification of the Halpern-Pearl Definition of Causality. https://doi.org/10.48550/arXiv.1505.00162\n\n\nMorabia, A. (2013). Hume, Mill, Hill, and the Sui Generis Epidemiologic Approach to Causal Inference. American Journal of Epidemiology, 178(10), 1526–1532. https://doi.org/10.1093/aje/kwt223\n\n\nPearl, J. (2009). Causal inference in statistics: An overview. Statistics Surveys, 3, 96–146. https://doi.org/10.1214/09-SS057",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Philosophy of Science</span>"
    ]
  },
  {
    "objectID": "Week_4.html#footnotes",
    "href": "Week_4.html#footnotes",
    "title": "6  Philosophy of Science",
    "section": "",
    "text": "With thanks to Aaron Peikert for identifying these quotes.↩︎",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Philosophy of Science</span>"
    ]
  },
  {
    "objectID": "testing.html",
    "href": "testing.html",
    "title": "7  Hypothesis Testing",
    "section": "",
    "text": "8 Lecture",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Hypothesis Testing</span>"
    ]
  },
  {
    "objectID": "testing.html#hypothesis-testing-type-i-and-type-ii-errors",
    "href": "testing.html#hypothesis-testing-type-i-and-type-ii-errors",
    "title": "7  Hypothesis Testing",
    "section": "\n9.1 Hypothesis Testing: Type I and Type II Errors",
    "text": "9.1 Hypothesis Testing: Type I and Type II Errors\nWhen we conduct a null-hypothesis significance test, we select the significance level \\(\\alpha\\). Alpha is the probability of committing a Type I error (drawing a false-positive conclusion). Since we select the alpha level, it is known. If we use \\(\\alpha = .05\\), that means that - by definition - we accept a 5% risk of committing a Type I error.\nThere is also the probability of committing a Type II error. This is called \\(\\beta\\). We don’t know the value of \\(\\beta\\) beforehand, but we can calculate it if we make some assumptions. The probability of committing a Type II error (drawing a false-negative conclusion) depends on a few factors:\n\n9.1.1 How big the effect is\nBig effects are harder to miss; imagine trying to detect a difference between two groups. If the mean of both groups is really close together, it will be harder to detect a difference (see below):\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 9.1: Effect of Effect Size\n\n\n\n9.1.2 How big the sample is\nLarge samples make it easier to detect smaller effects; imagine that the two distributions below are sampling distributions for two groups with very small sample sizes (left) and very large sample sizes (right):\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 9.2: Effect of Sample Size\n\n\n\n9.1.3 How ‘noisy’ the data are\nThe standard deviation is a measure of how “noisy” the data are. If observations are very spread out (high standard deviation), it will be harder to detect small differences. Consider that a small difference between two groups would be hard to detect if the two groups overlapped very much (= high standard deviation). Look at the same picture from the previous point (sample size); it illustrates this principle. The reason that both sample size and “noise in the data” have an impact on the probability of committing a Type II error is because they are used to calculate the standard error:\n\\[\nSE_M = \\frac{SD}{\\sqrt{n}}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Hypothesis Testing</span>"
    ]
  },
  {
    "objectID": "testing.html#power-of-a-test",
    "href": "testing.html#power-of-a-test",
    "title": "7  Hypothesis Testing",
    "section": "\n9.2 Power of a Test",
    "text": "9.2 Power of a Test\nThe “power” of a test is the probability that it will correctly detect a true effect of a specific size. Since \\(\\beta\\) is the probability of missing a true effect, it follows that \\(1-\\beta\\) must be the probability of detecting a true effect, or the power.\nAs explained in the previous paragraph, we must know a few pieces of information to be able to calculate \\(\\beta\\):\n\nEffect size\nSample size\nStandard deviation\n\nWhen we conduct a study, we often know the sample size and standard deviation. The effect size is unknown, but we can assume a specific effect size. Think of this as an “informative” alternative hypothesis. The standard alternative hypothesis in null-hypothesis significance testing is just “anything that’s not the null hypothesis”. So if \\(H_0: \\mu = 0\\), then \\(H_a: \\mu \\neq 0\\). Now, we must specify an exact value. For example, we could choose the smallest effect size of interest as the alternative hypothesis: Let’s say we’d be interested in a mean value of \\(\\mu = 0.2\\). Then we could set our informative alternative hypothesis as \\(H_i: \\mu = 0.2\\).\nNow we have all the information needed to calculate the power of the test. To do so, we draw two sampling distributions (see illustration below): One (in red) centered around the null hypothesis, \\(H_0: \\mu = 0\\), and one centered around the informative alternative hypothesis, \\(H_i: \\mu = 0.2\\). We find the critical value in the red distribution around the null hypothesis; remember that \\(\\alpha\\) is the 5% of probability in the right tail of the red distribution. But we can now also calculate \\(\\beta\\), the unknown probability in the tail of the blue distribution to the left of the critical value. If the informative alternative hypothesis is true, then this is the probability of failing to detect that true effect. Although this example has no numeric values, we see that the blue shaded area representing \\(\\beta\\) is slightly smaller than the red shaded area representing \\(\\alpha\\), so the probability of committing a Type II error must be less than .05, and therefore the power \\(1-\\beta\\) must be greater than 95%! If our assumptions are correct, we’d be really well able to detect a true effect of the size specified under \\(H_i\\).",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Hypothesis Testing</span>"
    ]
  },
  {
    "objectID": "testing.html#try-it-yourself",
    "href": "testing.html#try-it-yourself",
    "title": "7  Hypothesis Testing",
    "section": "\n9.3 Try it Yourself",
    "text": "9.3 Try it Yourself\nNow, let’s calculate this by hand. Imagine that last year’s average grade was \\(M = 5\\), with a standard deviation of \\(SD = 1.5\\). This year, we have 73 students. We’ve made some changes to the teaching material, and we hope to reach an average grade of \\(M = 6\\).\nAssume that the standard deviation this year will be the same as last year, and calculate the power of being able to detect a mean grade of \\(H_i: \\mu = 6\\) when the null hypothesis is that the mean grade is the same as last year, \\(H_0: \\mu = 5\\).\nStep 1: Calculate the SE\nWe calculate the SE as \\(SE = \\frac{SD}{\\sqrt{n}} = \\frac{1.5}{\\sqrt{73}} = 0.18\\)\nStep 2: Calculate Critical Value\nThe critical value is the boundary that corresponds to \\(\\alpha = .05\\) in the distribution centered around \\(H_0\\). Looking at the t- or Z-table (because sample size is &gt;&gt;30), we see that this corresponds to a Z-value of about 1.64.\n\nConverting this back to a score on the grades scale, we get:\n\\[\n\\text{Grade}_{\\text{critical}} = (Z_{\\text{critical}} * SE) + \\mu_{H_0} = (1.64 * 0.18) + 5 = 5.3\n\\]\nStep 3: Get Left-Tail Probability for That Value\nNow, we just need to get the left-tail probability for that critical value, in the blue distribution. Convert that critical value back to a Z-value, but now in the blue distribution which is centered around \\(\\mu_{H_i} = 6\\):\n\\[\nZ = \\frac{\\text{Grade}_{\\text{critical}}-\\mu_{H_i}}{SE} = \\frac{5.3 - 6}{0.18}  = -3.89\n\\]\nThis is an extremely large (negative) Z-value; it’s not even in our table. Thus, the left-tail probability \\(\\beta\\) will be tiny - \\(\\beta &lt; .01\\).\nThat means that our power to detect a true effect of 6 would be very high - \\(1-\\beta = 1-.01 = .99\\), 99%!",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Hypothesis Testing</span>"
    ]
  },
  {
    "objectID": "testing.html#assignment-1-hypothesis-testing---formulating-hypotheses",
    "href": "testing.html#assignment-1-hypothesis-testing---formulating-hypotheses",
    "title": "7  Hypothesis Testing",
    "section": "\n11.1 Assignment 1: Hypothesis Testing - Formulating Hypotheses",
    "text": "11.1 Assignment 1: Hypothesis Testing - Formulating Hypotheses\nDiscuss with your portfolio group the logic behind hypothesis testing, and how it relates to your personal (and group’s) research interests.\nConsider the following three research descriptions. Formulate H0 and H1 in words. Discuss your answers with your group members.\nResearchers want to know whether it matters for test performance if an exam is completed on a computer or using paper and pencil. Hence, the research question reads: Is there an effect of the type of administration (computer or paper and pencil) on the test performance?\nWhat would be the H0 and HA for this study?\n\n\nShow answer\n\nThis appears to be an undirected hypothesis about a mean difference for two independent samples, without a clearly specified alternative hypothesis. Thus, we could state:\n\\(H_0: \\mu_{computer} = \\mu_{paper}\\) \\(H_A: \\mu_{computer} \\neq \\mu_{paper}\\)\n\nResearchers want to know whether the alcohol consumption among Dutch students differs from the alcohol consumption in the general Dutch population. Using CBS statistics, they know that in the general population the average alcohol consumption is 5.6 glasses a week. The question is whether the average alcohol consumption among students is different from this national average.\nWhat would be the H0 and H1 for this study?\n\n\nShow answer\n\nThis appears to be an undirected hypothesis about the difference between a mean and a hypothesized value, without a clearly specified alternative hypothesis. Thus, we could state:\n\\(H_0: \\mu = 5.6\\) \\(H_A: \\mu \\neq 5.6\\)\n\nResearchers want to study whether social isolation is associated with income.\nWhat would be the H0 and H1 for this study?\n\n\nShow answer\n\nThis appears to be an undirected hypothesis about an association between two variables, without a clearly specified alternative hypothesis. We could thus state:\n\\(H_0: \\rho = 0\\) \\(H_A: \\rho \\neq 0\\)\n\nFormulating the hypothesis is an important very first step in hypotheses testing. Continue with the next assignment, in which we will go through the steps of a hypothesis test.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Hypothesis Testing</span>"
    ]
  },
  {
    "objectID": "testing.html#assignment-2-test-statistics-alpha-and-significance",
    "href": "testing.html#assignment-2-test-statistics-alpha-and-significance",
    "title": "7  Hypothesis Testing",
    "section": "\n11.2 Assignment 2: Test Statistics, Alpha and Significance",
    "text": "11.2 Assignment 2: Test Statistics, Alpha and Significance\nIn this assignment we will go through the steps of a hypothesis test.\nWhile going through the steps we will come across the most important concepts related to hypothesis testing.\nFor the next steps, we consider the following situation:\nSuppose we are interested in the personality profile of musicians; that is, we want to know whether, on average, personality characteristics of musicians differ from those of the general population. For now, we’ll only focus on Openness. We pretend that we have collected data among 25 musicians using a validated scale for which previous research has shown that in the general population the scores are normally distributed with mean 50 and SD 15. It is our task to test whether the mean of Openness for musicians differs from the mean in the general population. To keep things simple, we assume that in the population of musicians the SD is the same as in the general population; that is, we assume that LaTeX: \\(\\sigma = 15\\).\nLet openness be the variable of interest. Let \\(\\mu_{musicians}\\) represent the mean openness in the population of musicians. The hypothesis test amounts to testing:\n\\(H0: \\mu_{musicians} = 50\\)\n\\(H1: \\mu_{musicians} \\neq 50\\)\nNow, when we do the hypothesis test, we seek for evidence against the null hypothesis. More specifically, our testing procedure starts with the assumption that H0 represents the truth and as long as we don’t have convincing evidence that our assumption is false we stick to that assumption.\nThe question is, however, when do we have convincing evidence against H0?\nFinding evidence against H0 works as follows:\nIf H0 is true, we expect mean values close to H0. And, if we observe a mean value that is much different from the value under H0, we have convincing evidence against H0. If this happens, we reject H0 as representing the truth and accept the alternative hypothesis, H1.\nHypothesis testing fits Popper’s philosophy of falsification. He introduced this well-known analogy to explain the logic of falsificationism:\n\nSuppose we assume that all Swans are white, \\(H_0: Swans = white\\)\n\nWe would then not expect to observe black ones.\nIf we do observe black swans, our initial hypothesis is called into question.\nThe number of white swans we see (= observations consistent with the hypothesis) does not provide evidence for \\(H_0\\), because there could always be a black swan out there we haven’t observed yet.\n\nSo, the next questions are:\nWhat are the sample values we can expect under H0? When is evidence “convincing” enough? To answer the first question we have to go back to sampling distributions!\nFor the second question, we need a criterion. We have to realize that even if H0 is true, sample values can be far off just by sampling fluctuations (i.e., by chance). The common criterion is: if the observed value is among the 5% most unlikely samples under H0 (i.e. if H0 is true), we reject the null hypothesis.\nLet’s go back to our example about musicians.\nLet X be openness. Under H0 we assume that X is normally distributed with mean 50 and SD equal to 15.\nWhat are the mean and standard deviation of the sampling distribution of the mean under H0 given that the sample size is 25? And what do we call the standard deviation of the sampling distribution?\n(Use what you have learned in the previous lectures. Hint: first make a drawing of the situation, then do the computations).\n\n\nExplanation\n\nSampling distribution:\n\nMean: \\(\\mu = 50\\)\n\nStandard error ( =SD of sampling distribution!): \\(\\sigma_{\\bar{X}} = \\frac{15}{\\sqrt{25}}= 3\\)\n\n\n\nSuppose we want to indicate sample means that are unlikely if H0 would be true. In particular, we want to know how far the sample mean must be from the hypothesized mean to be among the 5% of all possible samples under H0 that are furthest away from the hypothesized means.\nWhat should the value of the sample mean be to fall within the 5% most deviant samples if the sample size is 25?\n\n\nExplanation\n\nWe are talking about the distribution of the mean; so we need to work with the sampling distribution. We want to know the cut offs that mark the 2.5% highest and 2.5% lowest means. We first have to find the Z-values: they are 1.96 for the highest 2.5%, and (by symmetry) -1.96 marks the 2.5% lowest.\nHence, to be among the 5% of all possible sample means that are most unlikely under H0, the sample mean should be:\nlarger than 50+1.96 x 3 = 55.88 or smaller than 50-1.96 x 3 = 44.12\n\nLet’s do some more exercises on the Z-test.\nSuppose the mean for Openness we found in our sample was 59.\nIf we use a significance level of 5%, would we reject the null hypothesis? \nYes\nNo\nIn the previous step we used cut offs for the sample means to decide about significance. The cut off scores were obtained via the Z-distribution. However, doing all these computations is not necessary (there’s a shortcut!!). In fact, if we know the Z-value for the sample, we can easily find out if the sample is among the 5% of the most unlikely sample means. We only have to compare the value with 1.96 and -1.96 to see whether that is the case.\nIn this course, we will use Z-values for different purposes. In these specific calculations, Z is used as a Test Statistic. A test statistic quantifies evidence against the null hypothesis. In this case, the Z test statistic expresses how far away from the mean under the null hypothesis the observed mean is, in terms of the number of standard errors.\nThe Z test-statistic follows the standard normal distribution. The values 1.96 and -1.96 are called the critical values and they mark the 5% most unlikely sample means under H0. In other words, the critical values mark the reject region for H0.\nSo, if we compute the Z-value for the sample mean, and if that sample value of Z falls in the rejection region, we reject H0 (we found something that is unlikely enough to no longer believe H0 is true). If H0 is rejected we speak of a significant result. See the graph below:\n\nFollowing these steps to test a mean is one example of performing a “Z-test”!\nWe can use the Z-test to test hypotheses about the population mean if we know the population \\(\\sigma\\).\nThe test statistic for the Z-test is:\n\\(z  = \\frac{\\bar{X}-\\mu_{H_0}}{\\sigma_{\\bar{X}}}\\)\nThis statistic is computed using the mean from the sample, the hypothesized mean under H0 and \\(\\sigma\\).\nH0 is rejected at the 5% significance level if z is either larger than 1.96 or smaller than -1.96.\nSo far, we rejected the null hypothesis if the sample is among the 5% most unlikely sample means under H0. This 5% was called the significance level, and is denoted as \\(\\alpha = .05\\). However, we could just as well choose 1% or .5%.\nWhat would be the critical values for the Z-test if one tests at \\(\\alpha = .01\\)? \nWhat would be the critical values for the Z-test if one tests at \\(\\alpha = .005\\%\\)? \nFor historical reasons, social scientists tend to use \\(\\alpha = 0.05\\) as a default. So in this course, if alpha is not explicitly stated, assume \\(\\alpha = 0.05\\).\nWhen we test hypotheses we reject H0 if the sample we find is unlikely if H0 is true. However, the flip side is that, even though H0 is true, we may find a sample that is much different by chance, and erroneously reject H0. Or, in other words, we could make an error. Rejecting H0 while it is true in reality is called a Type I error!\nConsider the following:\n\nIf H0 is true, and you test at \\(\\alpha = 0.05\\), what is the probability of committing a Type I error?\nWhat is the link between the \\(\\alpha\\)-level and type I error rate?\n\n\n\nExplanation\n\n\nIf H0 is really true (i.e., H0 should not be rejected), then the probability that the sample mean is among the 5% most unlikely is equal to 5%.\nThe alpha level specifies the risk of a Type I error. So if one tests at an alpha level of .05, it means that one accepts a risk of 5% to commit a Type I error.\n\n\nProperties of the Z-test:\nUsed to test hypotheses about the mean in a population, assuming \\(\\sigma\\) known.\nThe test-statistic equals \\(z = \\frac{\\bar{X}-\\mu}{\\sigma_{\\bar{X}}}\\)\nThe test statistic is normally distributed.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Hypothesis Testing</span>"
    ]
  },
  {
    "objectID": "testing.html#assignment-3-z-test",
    "href": "testing.html#assignment-3-z-test",
    "title": "7  Hypothesis Testing",
    "section": "\n11.3 Assignment 3: Z-test",
    "text": "11.3 Assignment 3: Z-test\nIn this assignment we will apply the Z-test.\nThis assignment first presents an example, followed by two practice questions.\nA researcher wants to test \\(H_0: \\mu = 50\\) against \\(H_1: \\mu \\neq 50\\)\nData are available from a random sample of 26 respondents. The mean was 53.7. The researcher assumes the SD in the population is 8.5. Perform all steps of the Z-test.\n\n\nExplanation\n\nStep 1: Formulate hypotheses\n\\(H_0: \\mu = 50\\) \\(H_1: \\mu \\neq 50\\)\nStep 2: Compute test statistic\nStandard error: \\(\\frac{8.5}{\\sqrt{26}}=1.667\\)\nTest statistic: \\(z = \\frac{53.7-50}{1.667}=2.212\\)\nStep 3: Decide about significance\n\\(\\alpha = .05\\), so critical values +/- 1.96.\nOur test statistic exceeds this critical value.\nThe sample mean thus falls in the rejection region, and we should conclude that the test is significant so \\(H_0\\) s rejected.\nStep 4: Draw conclusion\nWe have convincing evidence that the population mean differs from 50.\n\nA researcher wants to test whether the population mean is equal to 80. Data are available from a random sample of 60 respondents. The mean was 74. The researchers assume the SD in the population is 40. Perform and report all steps of the Z-test. What is the resulting p-value? \nA researcher wants to test whether the population mean is equal to 500. Data are available from a random sample of 75 respondents. The mean was 546. The researchers assume that the SD in the population is 200. Perform all steps of the Z-test. Use \\(\\alpha = .01\\). Perform and report all steps.\n\n\nShow answer\n\nStep 1: Hypotheses: \\(H_0: \\mu=500\\), \\(H_1: \\mu \\neq 500\\)\nstep 2: Compute Statistic:\n\nstandard error: \\(\\frac{200}{\\sqrt{75}} = 23.094\\)\n\ntest statistic: \\(z  = \\frac{546-500}{23.094}=1.992\\)\n\n\nStep 3: Decide about significance.\nZ does not exceed +/- 2.576. This means that Z does not fall in the reject region when tested at the 1% significance level. The test is not significant.\nStep 4: Draw conclusion\n\\(H_0\\) is not rejected.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Hypothesis Testing</span>"
    ]
  },
  {
    "objectID": "testing.html#quiz",
    "href": "testing.html#quiz",
    "title": "7  Hypothesis Testing",
    "section": "\n11.4 Quiz",
    "text": "11.4 Quiz\n\n“The null and alternative hypothesis are deduced from the data.” \nTRUE\nFALSE\n“When performing a hypothesis test, we start by assuming \\(H_0\\) is true.” \nTRUE\nFALSE\n“If we reject \\(H_0\\) with \\(\\alpha=0.05\\), then we will also reject it at \\(\\alpha=0.10\\), assuming all other quantities are held constant.” \nTRUE\nFALSE\n\n\nExplanation\n\nThe critical values of \\(\\alpha =0.05\\) are +/- 1.96. Hence, if \\(H_0\\) is rejected it means that z in the sample is larger than 1.96 or smaller than -1.96.”\nThe critical values of \\(\\alpha =0.1\\) are +/- 1.645. This means that for rejecting \\(H_0\\) at this alpha level, that z should be larger than 1.645 or smaller than -1.645. That is implied by the fact that it exceeds +/- 1.96.\n\n“If we reject \\(H_0\\), then \\(H_0\\) is surely wrong.” \nTRUE\nFALSE\n\n\nExplanation\n\nWe should always be aware of the possibility of making a Type I error. The probability of making a Type I error is equal to \\(\\alpha\\).\n\n“Increasing the sample size n (and holding all the rest constant) decreases the probability of a Type I error.” \nTRUE\nFALSE\n\n\nExplanation\n\nIncreasing the sample size n (and holding all the rest constant) does not decrease the probability of a Type I error.\nThe Type I error is determined by the alpha level.\nIf our sample is among the 5% most unlikely sample means of all possible sample means with the same size under \\(H_0\\), whatever that sample size N may be.\nIncreasing the sample size n (and holding all the rest constant) does not decrease the probability of a Type I error.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Hypothesis Testing</span>"
    ]
  },
  {
    "objectID": "testing.html#assignment-4-z-test-and-alpha-levels",
    "href": "testing.html#assignment-4-z-test-and-alpha-levels",
    "title": "7  Hypothesis Testing",
    "section": "\n11.5 Assignment 4: Z-test and Alpha-levels",
    "text": "11.5 Assignment 4: Z-test and Alpha-levels\nIn this assignment we will practice some more with the Z-test, meanwhile we will review important concepts of hypothesis testing. In particular, we will look at significance levels.\nTo test hypotheses, we need to specify the “significance level”, usually denoted by \\(\\alpha\\). The significance level is our decision criterion to reject H0.\nThe most common choice is .05. But what does this criterion exactly entail?\nDiscuss with your group what an \\(\\alpha\\) level entails.\n\n\nExplanation\n\nIf we test at an \\(\\alpha\\) of .05 it means that we are willing to reject H0 in favor of H1 if our sample mean belongs to the 5% most extreme scores (2.5% in each tail) under the null hypothesis.\nIf indeed the sample mean is among this 5%, it means that we have observed a sample in a range that is quite unlikely if the null hypothesis would be true and, therefore, justifies rejection of the null hypothesis.\n\nIn the previous assignments you already used the critical values for the Z-test for specific alpha levels.\nFor two-tailed tests, it holds that if the absolute value of Z exceeds the critical value, we may reject \\(H_0\\).\nLet \\(Z_\\text{crit}\\) be the critical value. For the Z-test it holds that:\n\n\n\\(Z_\\text{crit} = 1.65\\), if \\(\\alpha = 0.10\\) (two-tailed)\n\n\\(Z_\\text{crit} = 1.96\\), if \\(\\alpha = 0.05\\) (two-tailed)\n\n\\(Z_\\text{crit} = 2.58\\), if \\(\\alpha = 0.01\\) (two-tailed)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Hypothesis Testing</span>"
    ]
  },
  {
    "objectID": "testing.html#quiz-1",
    "href": "testing.html#quiz-1",
    "title": "7  Hypothesis Testing",
    "section": "\n11.6 Quiz",
    "text": "11.6 Quiz\n\nResearchers want to test whether \\(\\mu=70\\). They assume that \\(\\sigma = 10\\). Researchers found a mean of 72 in a random sample of 40 persons.\nTrue or false:\n\\(H_0\\) can be rejected at one of the three levels discussed above (\\(\\alpha = .10, .05, .01\\). \nTRUE\nFALSE\n“If the two-tailed test is significant at the 5% level, it will also be significant at the 1% level (keeping everything else fixed).” \nTRUE\nFALSE\n“If the two-tailed test is not significant at the 10% level, it won’t be significant at the 5% level either (keeping everything else fixed).” \nTRUE\nFALSE\n“If the two-tailed test is not significant at the 5% level, it could still be significant at the 10% level (keeping everything else fixed).” \nTRUE\nFALSE\n“If the two-tailed test is significant at the 1% level, it might not be significant at the 5% level (keeping everything else fixed).” \nTRUE\nFALSE",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Hypothesis Testing</span>"
    ]
  },
  {
    "objectID": "testing.html#assignment-5-p-values",
    "href": "testing.html#assignment-5-p-values",
    "title": "7  Hypothesis Testing",
    "section": "\n11.7 Assignment 5: P-values",
    "text": "11.7 Assignment 5: P-values\nWe will now focus on the interpretation of the p-values and how to use the p-values to decide about significance.\nConsider the following situation:\nScores on a test measuring confidence in police are normally distributed in the general population, with \\(\\mu = 500\\) and an \\(\\sigma = 50\\). Researchers want to know if the average confidence level is different for those who have been a victim of crime. They collect data for 60 victims. They find a sample mean of 511. They test \\(H_0: \\mu = 500\\) against \\(H_1: \\mu \\neq 500\\), while assuming that the population variance is \\(\\sigma = 50\\).\nCompute the p-value. Draw a graph for the two-tailed p-value. Write down in your own words and as precise as possible the interpretation of the p-value in the answer box below. Then, discuss your response with your group.\n\n\nExplanation\n\n\nThe p-value represents the proportion of all possible sample means that are further away from our hypothesized mean than the observed sample mean is.\nWe have the sampling distribution with \\(\\mu = 500\\) and \\(\\sigma_{\\bar{X}} = \\frac{50}{\\sqrt{60}} = 6.455\\).\nFirst, we compute the right-tail area: \\(P(\\bar{X} &gt; 511) = P(Z &gt; 1.70) = 0.0446\\).\nHence, 4.66% of all possible samples is further away from \\(H_0\\) on the right side.\nSecond, we compute the left-tail area. These are the sample means that are more than 11 points from the hypothesized mean to the left \\(P(\\bar{X} &lt; 489) = P(Z &lt; -1.70) = 0.0446\\).\nHence, the two-tailed p-value is 0.0892.\n\n\nIs the test significant at the 5% level? \nTRUE\nFALSE\nIs it significant at the 1% level? \nTRUE\nFALSE\nResearchers test whether \\(\\mu = 90\\). They assume that \\(\\sigma=21\\). The sample mean was 85. Sample size was 50.\nWhat is the two-tailed p-value? \nWhat is the highest level at which the test is significant? \n0.005\n0.1\n0.05\n0.01\nResearchers test whether \\(\\mu = 35\\). They assume \\(\\sigma =16\\). The sample mean was 38. Sample size was 64.\nCompute the two-tailed p-value and indicate which of the following statements is true.\n\nThe test is significant at the 10% level, but not at 5% or 1% level.The test is not significant at 10%, not significant at 5% and not significant at 1%.The test is significant at the 10%, 5% level, and 1% level.The test is significant at the 10% and 5% level, but not at the 1% level.\n\nConsider these true- or false statements:\nIf a two-tailed p-value is .0567 then the test is significant at the 10% level but not at the 5% level. \nTRUE\nFALSE\nIf a two-tailed test is significant at the 5% level but not at the 1% level, then the two-tailed p-value will be less than 0.01. \nTRUE\nFALSE\nA two-tailed p-value of 0.060 indicates that we have 6% chance that the null hypothesis is true. \nTRUE\nFALSE",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Hypothesis Testing</span>"
    ]
  },
  {
    "objectID": "glm1_regression.html",
    "href": "glm1_regression.html",
    "title": "8  GLM-I: Linear Regression",
    "section": "",
    "text": "9 Lecture",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>GLM-I: Linear Regression</span>"
    ]
  },
  {
    "objectID": "glm1_regression.html#linear-regression",
    "href": "glm1_regression.html#linear-regression",
    "title": "8  GLM-I: Linear Regression",
    "section": "\n11.1 Linear Regression",
    "text": "11.1 Linear Regression",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>GLM-I: Linear Regression</span>"
    ]
  },
  {
    "objectID": "glm1_regression.html#regression-analysis",
    "href": "glm1_regression.html#regression-analysis",
    "title": "8  GLM-I: Linear Regression",
    "section": "\n12.1 Regression Analysis",
    "text": "12.1 Regression Analysis\nIn this assignment we will make a start with regression analysis.\nWe will go through the different steps of running and interpreting a regression analysis.\nOpen the file Work.sav to get started.\nConsider the following research question: “Does variety at work predict pleasure at work?”\nWhat is the dependent variable in this case? \nPleasure\nVariety\nTo answer the research question, we will run a linear regression analysis.\nSelect the following menu item: Analyze &gt; Regression &gt; Linear\nChoose the dependent variable (scpleasure) and independent variable (scvariety). Paste and run the syntax.\nIf you look in the output, you will see that SPSS shows four tables in the output file.\nIn the table labeled “Model Summary” we can find the R2 value. R2 indicates the total proportion of explained variance in the dependent variable in the model; this is the focus of next week’s class.\nWhat proportion of the variance Emotional pressure (scpleasure) is explained by our single predictor Variety at work (scvariety)? \nConsider the unstandardized Coefficients in the table labeled “Coefficients”.\nWhat is the value of the intercept (b0) for the regression line? \nHow should we interpret the intercept (or “constant”) within the context of this analysis?\n\nSomeone who reports zero Variety at work (meaning a score of 0 on scvariety) has an expected value of this many points on Pleasure.The sample average of Pleasure is this many pointsEveryone who reports zero Variety at work (meaning a score of 0 on scvariety) has a value of this many points on Pleasure.For every point in Variety at work, we expect an increase of this many points in Pleasure.\n\nConsider the unstandardized regression coefficients again.\nWhat is the value of the regression coefficient of scpleasure on scemoti (b1)? \nHow should we interpret the regression coefficient of scvariety within the context of this analysis?\n\nIf someone’s score on Variety at work increases with 1 SD, their score on Pleasure increases by this many SDs.This is the sample average of PleasureIf someone’s score on Variety at work increases with 1 point, their score on Pleasure increases by this many points.This is the sample average score of Variety at work.\n\nThe “Coefficients” table also shows whether or not the effect of scvariety on scpleasure is significant.\nWhat is the p-value for the regression coefficient for scvariety? \nCan we conclude that the effect of scvariety on scpleasure is significant? (use \\(\\alpha\\) = .05). \nYes\nNo",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>GLM-I: Linear Regression</span>"
    ]
  },
  {
    "objectID": "glm1_regression.html#assumptions",
    "href": "glm1_regression.html#assumptions",
    "title": "8  GLM-I: Linear Regression",
    "section": "\n12.2 Assumptions",
    "text": "12.2 Assumptions\nRecall that regression assumes linearity, normality of residuals, homoscedasticity (equal variance of residuals), and independence of observations. We will check each of these assumptions in turn, except for independence of observations because this is a property of our sampling method and cannot be checked statistically.\n\n12.2.1 Scatterplot\nA scatter plot can provide some insight into linearity.\nTo make a scatter plot: Graphs &gt; Legacy Dialogs &gt; Scatter/Dot &gt; Simple Scatter\nPlace variety at work on the X axis and emotional pressure on the Y axis.\nIs the assumption of linearity met in this case? \nYes\nNo\n\n12.2.2 Regression Diagnostics\nAside from the scatterplot, we can check the assumptions of regression by requesting additional options in the analysis.\nGo back to the analysis dialog via Analyze –&gt; Regression –&gt; Linear. Verify that you still have the correct predictor and outcome.\nThen, click the Plots button. You want a plot of the predicted values against the residual values, so put ZPRED in the X box and ZRESID in the Y box.\nAlso check the boxes for a Histogram and normal probability plot, then hit continue.\nNow paste and run the syntax. You should see the following added to your previous regression syntax:\n  /SCATTERPLOT=(*ZRESID ,*ZPRED)\n  /RESIDUALS HISTOGRAM(ZRESID) NORMPROB(ZRESID)\n\n12.2.3 Linearity\nHow can we test linearity using this additional output?\nFirst, we can use the “Normal P-P plot”. If the relationship is perfectly linear, all dots should be on the diagonal line. If the points are deviating from the line, the relationship is not perfectly linear. Small deviations are OK; for example, the plot below shows a linear association:\n\nDoes the P-P plot for your regression give cause for concern for violation of the assumption of linearity? \nYes\nNo\nUnclear\n\n12.2.4 Normality\nOne way to check normality is by examining the histogram of residuals. This histogram displays a normal curve by default. If the observed residuals deviate strongly from this histogram, there may be a problem.\nThe plot below shows a residual histogram with some minor deviations from normality (too few scores near the mean). This is probably still fine:\n\nDoes the residual histogram for your regression give cause for concern for violation of the assumption of normal residuals? \nYes\nNo\nUnclear\n\n12.2.5 Homoscedasticity\nWe examine homoscedasticity using a plot of standardized predicted values against standardized residuals. We want residuals to be identically distributed on the Y-axis for all values on the X-axs. In other words, this scatterplot should look like a dot cloud (no pattern) around the zero line (left picture below), and not like a pattern (right picture below).\n\nDoes the scatterplot for standardized predicted values against residual values for your regression give cause for concern for violation of the assumption of homoscedasticity? \nYes\nNo\nUnclear\nWrite up a discussion of potential violations of the assumptions for your regression, then check your answer.\n\n\nExplanation\n\nWe observed that the observed scores deviated from the P-P plot in an S-shaped pattern. We further observed that, in a histogram of standardized residuals, the observed residuals were right-skewed. Finally, we observed less variance around the regression line for low scores and more variance around the regression line for high scores.\nThese findings give cause for concern of violations of the assumptions of regression. One potential explanation is that the effect might be quadratic instead of linear. (Optional)",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>GLM-I: Linear Regression</span>"
    ]
  },
  {
    "objectID": "glm2_sum_squares.html",
    "href": "glm2_sum_squares.html",
    "title": "9  GLM-II: Sums of Squares",
    "section": "",
    "text": "10 Lecture",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>GLM-II: Sums of Squares</span>"
    ]
  },
  {
    "objectID": "glm2_sum_squares.html#correlation-analysis",
    "href": "glm2_sum_squares.html#correlation-analysis",
    "title": "9  GLM-II: Sums of Squares",
    "section": "\n12.1 Correlation Analysis",
    "text": "12.1 Correlation Analysis",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>GLM-II: Sums of Squares</span>"
    ]
  },
  {
    "objectID": "glm2_sum_squares.html#bivariate-regression",
    "href": "glm2_sum_squares.html#bivariate-regression",
    "title": "9  GLM-II: Sums of Squares",
    "section": "\n13.1 Bivariate Regression",
    "text": "13.1 Bivariate Regression\nSocial science students were asked about their opinion towards Tilburg’s nightlife, number of Facebook friends, and some other characteristics. The data are in the SocScSurvey.sav file.\nDownload the file to your computer and open it in SPSS.\nSuppose researchers are interested in the relationship between personality and social media use. In particular, they want to know if extraversion explains the number of Facebook friends.\nWhat is the independent variable here? \nExtraversion\nFacebook friends\nRemember that the independent variable is the variable that predicts the other variable (which we call the dependent variable). The dependent variable is influenced by the independent variable (its value depends on the independent variable).\nRun a regression analysis in which you regress Facebook friends on extraversion (via analyze &gt; regression &gt; linear).\nKeep in mind that we “regress the dependent variable Y on the independent variables (X)”.\nConsult the output.\nWrite down the estimated unstandardized regression equation.\n\n\nAnswer\n\n\\(\\text{Friends}_i = -62.377 + 26.788*\\text{Extraversion}_i + e_i\\)\n\nWhich of the following statements is true?\n\nIf Extraversion increases with one unit, the number of facebook friends increases with 26.788 unitsIf Facebook friends increases with one unit, extraversion increases with 26.788 unitsIf Extraversion increases with 26.788 units, the number of facebook friends increases with 1 unit\n\nRemember that the general form of interpretation of the unstandardized effect is: “If X increases with 1 unit, Y increases/decreases with ‘unstandardized regression coefficient’ units”.\nWhat is the value of the standardized regression coefficient? \nYou can find the standardized regression coefficients in the column called ‘Standardized Coefficients Beta’.\nWhich of the following statements about the standardized regression coefficients is correct?\n\nIf extraversion increases with one SD, the number of facebook friends increases with 0.438 SDsIf extraversion increases with one unit, the number of facebook friends increases with 0.438 SDsIf extraversion increases with one SD, the number of facebook friends increases with 0.438 units\n\nRemember that standardized regression coefficients are interpreted in a similar way as unstandardized regression coefficients are, with the one difference being they are interpreted in terms of standard deviations.\nConsider the first person in the data file. The person had an extraversion score of 9.\nWhat is the predicted number of Facebook friends for this person? \nConsider the first person again.\nGiven the predicted number of Facebook friends for this person, what is the prediction error (rounded to the nearest integer)? \nPrediction error = yobserved - ypredicted\nConsider two people, one with an extraversion score of 10 and the other with an extraversion score of 15.\nWhat is the difference in the predicted number of Facebook friends between the two persons? (report the absolute value) \nConsult the output of the regression analysis.\nWhat percentage of the total variance in number of Facebook friends can be explained by extraversion? \nConsult the ANOVA table.\nThe table shows the results of an F-test.\nWhat is the default null hypothesis and alternative hypothesis for the reported test?\n\n\nAnswer\n\n\\(H_0: \\rho^2 = 0\\), \\(H_A: \\rho^2 &gt; 0\\)\n\nSuppose three researchers test the significance of the R-square.\nResearcher I tests at the 10% level, researcher II tests at the 5% level, and researcher III at the 1% level.\nWhich researcher will reject the null hypothesis? \nOnly researcher II\nOnly researcher III\nOnly researcher I\nAll three researchers\nWhen reporting the F-test for the model, you would report \\(R^2\\), the F-test statistic, its degrees of freedom, and the p-value.\nThe F-test has two distinct degrees of freedom. The first refers to the degrees of freedom for the regression equation, and the second to the degrees of freedom for the residuals. The degrees of freedom are given in brackets. For example, if regression has 2 degrees of freedom and the residuals 100, we write the F-value as F(2,100) = ….\nWhich of the following F value and corresponding degrees of freedom should be reported? \nF(1,132) = 0.000\nF(1,132) = 31.283\nF(1,133) = 31.283",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>GLM-II: Sums of Squares</span>"
    ]
  },
  {
    "objectID": "glm2_sum_squares.html#correlation",
    "href": "glm2_sum_squares.html#correlation",
    "title": "9  GLM-II: Sums of Squares",
    "section": "\n13.2 Correlation",
    "text": "13.2 Correlation\nCorrelations and regression analyses can both be used to study the relationship between variables, but there is an important difference.\nDiscuss with your group mates what the similarities and differences between the two methods are.\n\n\nAnswer\n\nA correlation is a symmetric measure of association, meaning we are agnostic about which is the predictor and which is the outcome (or neither are predictor/outcome). The correlation between X and Y is the same as the one between Y and X.\nIn regression analysis, we do define an independent and dependent variable. The goal is to predict the outcome using the predictor. Most of the time, this implies an assumption of causality - but not necessarily.\nFor example, we can use regression to predict sales based on customer characteristics without assuming that those characteristics CAUSE sales. But if we want to cause an increase in sales, and we look at the regression coefficients to decide where to intervene - then it suddenly matters a lot whether the predictors are causes of sales or not.\nYou see this a lot with online marketing when you are receiving a lot of adds for a product that you recently bought. Their regression model knows that looking at the product page is a great predictor of intention to buy it - but they don’t know that the reason you were looking at that page is because you were already buying it.\n\nNow, let’s have a look at the correlation between these two variables.\nAnalyze &gt; correlate &gt; bivariate.\nChoose as variables: Facebook Friends and Extraversion, and click OK.\nWhat is the correlation between Extraversion and number of Facebook friends? \nSuppose three researchers test the significance of the correlation between Extraversion and Facebook friends. Researcher I tests at the 10% level, researcher II tests at the 5% level, and researcher III at the 1% level.\nWhich researcher will reject the null hypothesis? \nOnly researcher III\nAll three researchers\nOnly researcher I\nOnly researcher II\nWhich of the following interpretations is true?\n\nIt would be very unlikely to observe a sample correlation of .44 by chance if the population correlation would be zero.We don't have convincing evidence that Facebook friends and extraversion are associated in the population.We have convincing evidence that Facebook friends and extraversion are associated in the population.\n\nCompare the correlation coefficient to the standardized regression coefficient from the bivariate regression you conducted previously.\nThen, compare it to the value labeled “R” in the “Model Summary” table from the regression.\nSquare the correlation, and compare it to the value labeled “R Square”.\nWhat do you observe?\n\n\nAnswer\n\nIf you did everything correctly, you should observe that the bivariate correlation is identical to the standardized regression coefficient. This is only the case with bivariate regression.\nFurthermore, the bivariate correlation should be identical to the R reported in the Model Summary table, because they are both just the correlation coefficient. R squared is the squared correlation coefficient, and we interpret it as the “proportion of variance in the outcome explained by the predictor”. Only in bivariate regression is this identical to the squared correlation coefficient.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>GLM-II: Sums of Squares</span>"
    ]
  },
  {
    "objectID": "glm2_sum_squares.html#r-squared",
    "href": "glm2_sum_squares.html#r-squared",
    "title": "9  GLM-II: Sums of Squares",
    "section": "\n13.3 R squared",
    "text": "13.3 R squared\nThe R squared expresses how well the predictors explain variance in the outcome of a regression. In the next few steps we will look in more detail at this concept.\nConsider the results of the regression model again.\nWrite down the (unstandardized) regression equation based on your previous results, and use the raw data in the Data View to answer the following question.\n\n\nAnswer\n\n\\(\\text{pressure}_i = 37.863 -.320 * \\text{variety}_i + e_i\\)\n\nWhat is the predicted value (Y’) for emotional pressure at work for the first person in the data file (i.e., the person with respondent number 1)? \nWhat is the prediction error (a.k.a. the residual) for the first person? \nRemember Residual = Yobserved - Ypredicted\nWe’ve just computed the predicted value and error by hand. It would be very tedious if we would have to do that for all respondents. Fortunately, SPSS offers the option to compute predicted values and errors for all cases for us!\nNavigate to Analyze &gt; Regression &gt; Linear\nClick on the ‘Save’ button. SPSS opens a new window.\nAsk for the Unstandardized predicted values and the unstandardized residuals. Paste and run the syntax.\nLet’s inspect the Data View in SPSS again and verify that SPSS added two columns in the data file. One column is labeled PRE_1 and the other RES_1. These columns show the predicted values and residuals for each person, respectively.\nYou may verify this for the first person (i.e., the values should be the same as you computed in the previous steps).\nNow we will look at the variance of the observed values of Pleasure at work, the variance of the predicted values of pleasure at work, and variance of the residuals.\nCompute the variances of Emotional pressure, as well as for the predicted values of Emotional pressure, and for the residuals.\nNavigate to Analyze &gt; Descriptive statistics &gt; Descriptives Select scemoti, PRE_1, and RES_1. Click on ‘options’ and ask for the Variance. Paste and run the syntax.\nHow large is the variance of the observed scores for Emotional pressure? \nHow large is the variance of predicted values of Work pleasure? \nHow large is the variance of the residuals? \nIn the previous questions, we looked at three variance components.\nDiscuss with your group what the three variances represent.\n\n\nAnswer\n\nThe variance in observed values of Emotional pressure is the total variance in Y (i.e., the dependent variable). The variance in the predicted values of Emotional pressure reflects “differences in emotional pressure that can be explained because some persons have a job with a lot of variety and some have a monotonous job”. This variance component is also known as the explained variance. The variance of the residuals, also known as the residual variance, represents differences in emotional pressure that cannot be attributed to differences in variety at work. Hence, the residual describes differences that are unrelated to variety at work.\n\nIn the previous step, we looked at the variances itself, but the numbers are not very informative. A more convenient way to look at the explained variance is proportion wise.\nSo, let’s use the variances we just generated to calculate the proportion of variance in Emotional pressure that can be explained by Variety at work.\nWhat percentage of the total variance in emotional pressure can be explained by variety at work? \nConsult the output of the regression analysis again, particularly the table Model Summary.\nVerify that the R-square that is reported in the table is the same as the proportion of explained variance that you have calculated yourself.\nFinally, independently go through all the steps of a simple regression analysis using the data file LAS_SS_Work.sav.\nYour theory suggests that independence at work predicts emotional pressure.\n\nConstruct an appropriate research question and hypotheses.\nConduct the analysis\nDescribe the relationship (i.e., regression coefficient)?\nDiscuss the effect size in terms of R2.\nPerform a significance test and report your results\n\nFinally, compare the standardized regression coefficient to the R coefficient in the Model Summary table, and optionally to a correlation computed via the Correlation interface. Verify that these are all identical.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>GLM-II: Sums of Squares</span>"
    ]
  },
  {
    "objectID": "glm3binary.html",
    "href": "glm3binary.html",
    "title": "10  GLM-III: Binary Predictors",
    "section": "",
    "text": "11 Lecture",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>GLM-III: Binary Predictors</span>"
    ]
  },
  {
    "objectID": "glm3binary.html#independent-samples-t-test",
    "href": "glm3binary.html#independent-samples-t-test",
    "title": "10  GLM-III: Binary Predictors",
    "section": "\n13.1 Independent Samples t-test",
    "text": "13.1 Independent Samples t-test\nAs a t-test and as regression with a dummy predictor:",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>GLM-III: Binary Predictors</span>"
    ]
  },
  {
    "objectID": "glm3binary.html#independent-samples-t-test-1",
    "href": "glm3binary.html#independent-samples-t-test-1",
    "title": "10  GLM-III: Binary Predictors",
    "section": "\n14.1 Independent Samples T-Test",
    "text": "14.1 Independent Samples T-Test\nIn this assignment we will use the data file 5groups.sav Download 5groups.sav. Download the file and open it in SPSS.\nThis time, we will compare the means of the variable y of two specific groups: group 1 and group 4. To test the difference between two sample means, we will use the t-test for independent samples.\nWhat is the null hypothesis of this test? And what is the alternative hypothesis?\n\n\nAnswer\n\n\\(H_0: \\mu_1=\\mu_4\\), against \\(H_1: \\mu_1\\neq \\mu_4\\)\n\nCreate the necessary syntax for the t-test that compares the means of group 1 and group 4.\nYou can find the dialog for the two-sample t-test under Analyze &gt; Compare Means &gt; Independent Samples T Test\nIn the SPSS dialog you have to specify which two groups you want to compare. In our case, it’s group 1 and group 4. After placing the variable in the box named “Grouping Variable”, click the button named “Define Groups” to define the groups.\nCompare your syntax to the correct syntax:\n\n\nAnswer\n\nT-TEST GROUPS=group(1 4) /MISSING=ANALYSIS /VARIABLES=y /CRITERIA=CI(.95).\n\nOne of the assumptions of the independent samples t-test is homoscedasticity (equal variances for all levels of the predictor). We can compare the sizes of the variances of the two groups with a simple F-test, which we call Levene’s test.\nHave a look at Levene’s test and try to interpret it. Discuss with your group what null-hypothesis is being tested here.\nWhat is the p-value of the Levene’s test? \nWhat do you conclude from this? What’s the practical use of the outcome of this test?\n\n\nExplanation\n\nLevene’s test is not significant. Remember that the null hypothesis of Levene’s test is that the population variances of the group are equal. As the p-value is not significant, we cannot reject the null hypothesis. Consequently, there is no evidence that the population variances of two groups are unequal. Thus, there is no reason to question the assumption.\n\nNow you will have to decide on the outcome of the actual t-test. SPSS reports two versions: one that assumes equal variances (top row) and one that relaxes this assumption (bottom row).\nYou should pick one of these. In principle, you should decide which one you will use before seeing the results - although if there is clear evidence of violation of assumptions, you might want to discuss in your report whether the results change if you use the robust version (bottom row).\nFor now remember: we assume equal variances.\nWhat is the two-sided p-value? \nDo you reject the null hypothesis of this t-test at alpha 0.05? \nYes\nNo",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>GLM-III: Binary Predictors</span>"
    ]
  },
  {
    "objectID": "glm3binary.html#regression-with-dummies",
    "href": "glm3binary.html#regression-with-dummies",
    "title": "10  GLM-III: Binary Predictors",
    "section": "\n14.2 Regression with dummies",
    "text": "14.2 Regression with dummies\nWe will now perform the exact same analysis, but with regression and dummies.\nTo test the difference between group 1 and group 4, we first create a dummy variable to distinguish these two groups. Use group 1 as reference category. You can use either Transform -&gt; Recode into different variables, or syntax:\nRECODE group (1=0) (4=1) INTO dgroup4.\nEXECUTE.\nNote that all other groups are coded as missing on this variable, which is exactly what we want!\nWe will use regression to perform our t-test. The hypothesis is the same as in the previous assignment, but you could also rewrite it in terms of regression coefficient(s). What is the null hypothesis of this test in terms of regression coefficient(s)? And what is the alternative hypothesis?\n\n\nAnswer\n\n\\(H_0: \\beta_{group1 vs group2}=0\\) which is the same as \\(H_0: \\mu_{group1} = \\mu_{group2}\\), versus \\(H_1: \\beta_{group1 vs group2} \\neq 0\\) which is the same as \\(H_0: \\mu_{group1} \\ne \\mu_{group2}\\)\n\nCreate the necessary syntax for a regression with the dummy variable that compares the means of group 1 and group 4.\nYou can find the dialog under Analyze &gt; Regression &gt; Linear\nIn the SPSS dialog you have to specify the Dependent and Independent variable. In our case, the independent variable is the dummy we created.\nCompare your syntax to the correct syntax:\nREGRESSION\n  /MISSING LISTWISE\n  /STATISTICS COEFF OUTS R ANOVA\n  /CRITERIA=PIN(.05) POUT(.10)\n  /NOORIGIN \n  /DEPENDENT y\n  /METHOD=ENTER dgroup4.\nNote that, unlike the t-test interface, the regression interface does not provide a Levene’s test. This is one reason you might want to use the t-test interface. The regression interface provides a more generic way to test the assumption of homoscedasticity: a residual plot.\nGo back through the regression interface, but this time click the Plots button and plot the predicted value (X = ZPRED) against the residual value (Y = ZRESID).\nYour syntax will now say:\nREGRESSION\n  /MISSING LISTWISE\n  /STATISTICS COEFF OUTS R ANOVA\n  /CRITERIA=PIN(.05) POUT(.10)\n  /NOORIGIN \n  /DEPENDENT y\n  /METHOD=ENTER dgroup4\n  /SCATTERPLOT=(*ZRESID ,*ZPRED)\nIf the assumption of homoscedasticity is met, we should see that the dots in this plot are equally distributed around the zero line for all values on the X-axis. In this case, we see much narrower spread on the right side than on the left side.\nWhat can you conclude from this, and does it match your conclusion from Levene’s test?\nNow you will have to decide on the outcome of the actual t-test.\nRemember that the t-test of the dummy variable should be the same as the t-test we conducted before. Verify that this is true.\nWhat is the two-sided p-value? \nWe see one more t-test: for the “(Constant)” or intercept. How do we interpret this?\n\nThe mean value across both Groups is 7, and this differs significantly from zero.The mean value in Group 4 is 7, and this differs significantly from zero.The mean value in Group 1 is 7, and this differs significantly from zero.The mean difference between both Groups is 7, and this differs significantly from zero.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>GLM-III: Binary Predictors</span>"
    ]
  },
  {
    "objectID": "glm4anova.html",
    "href": "glm4anova.html",
    "title": "11  GLM-IV: ANOVA",
    "section": "",
    "text": "12 Lecture",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>GLM-IV: ANOVA</span>"
    ]
  },
  {
    "objectID": "glm4anova.html#anova",
    "href": "glm4anova.html#anova",
    "title": "11  GLM-IV: ANOVA",
    "section": "\n14.1 ANOVA",
    "text": "14.1 ANOVA\nUsing the ANOVA interface and the regression interface:",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>GLM-IV: ANOVA</span>"
    ]
  },
  {
    "objectID": "glm4anova.html#anova-1",
    "href": "glm4anova.html#anova-1",
    "title": "11  GLM-IV: ANOVA",
    "section": "\n15.1 ANOVA",
    "text": "15.1 ANOVA\nFor this assignment, we will use the data file 5groups.sav Download 5groups.sav. Please open it in SPSS.\nAs you have seen in the previous assignments, this file contains the measurements of the y variable for 5 different groups. So far, we have - at most - compared two groups at once. This time, we will compare the means of all 5 groups simultaneously using an Analysis of Variance (ANOVA).\nANOVA is often used to examine the results of experimental research where different groups receive different manipulations of an independent variable, and a continuous dependent variable is measured. In that case, rejecting the null hypothesis indicates a causal effect of the manipulated independent variable on the dependent variable.\nLet’s say the 5 groups in our data file have received 5 different types of training, and the dependent variable y measures the effect of the training.\nWe will now perform an ANOVA to see if these trainings have an equal effectiveness.\nThe null hypothesis of the ANOVA with 5 groups is as follows:\n\\(H_0: \\mu_1 = \\mu_2 = \\mu_3 = \\mu_4 = \\mu_5\\)\nThat is, the null hypothesis states that the population means of all five groups are the same. Rejecting the null hypothesis implies that at least one one of these means is different from the rest.\nLet’s run the analysis!\nNavigate to Analyze &gt; General Linear Model &gt; Univariate. Choose y as the dependent variable. Choose group as the fixed factor. Now click on the “Options” button and check the two boxes named “Descriptive statistics” and “Homogeneity tests”. Finally, click “Paste” to paste the syntax into the syntax editor, and run it from there.\nYou should end up with the following syntax:\n    UNIANOVA y BY group\n      /METHOD=SSTYPE(3)\n      /INTERCEPT=INCLUDE\n      /PRINT=HOMOGENEITY DESCRIPTIVE\n      /CRITERIA=ALPHA(.05)\n      /DESIGN=group.\nThe first table in the output we will inspect is the “Descriptive Statistics” table. This table displays the means and standard deviations of the variable y for each of the five groups.\nDo you think the population standard deviations are different for each group? If they are, why could that pose a problem for our analysis?\nOne of the assumptions of ANOVA is homoscedasticity. In this case, that means that the population of each group has the same variance (and hence, the same standard deviation). This assumption is also called “homogeneity of variance” (= translation of homoscedasticity). Of course the variance in each sample will differ somewhat. If these differences are significant, there is evidence to doubt our assumption. That’s why we asked SPSS to perform “Homogeneity tests”.\nNote that the SD’s of groups 1 and 2 are quite different from the SD’s of groups 3, 4, 5.\nThe next table shows the output of Levene’s test. You might remember using Levene’s test for comparing the variances of two groups in the context of the independent samples t-test. This time, it tests whether the variance of all 5 groups should be considered equal.\nIs there a reason to doubt the assumption of homoscedasticity based on Levene’s test? Note: Use the Levene’s test “Based on mean”. mcq(c(answer = \"Yes\", \"No\"))\nIf Levene’s test is significant, there is evidence that the population variances of at least 2 of the groups differ. This is evidence against our assumption. This could pose a problem for our analysis. We may choose to use a version of the analysis that is robust to violations of this assumption instead, but that makes our analysis dependent on the data (= no longer confirmatory). Instead, we could discuss the violation, and compare results with and without a robust test.\nFor now, we continue with interpreting the output of the final table. There’s a lot of information, but for now we are only interested in the Sig. value of the “Corrected Model” in the first row. This is the two-sided p-value we can use to test our null hypothesis.\nWhat is the two-sided p-value? Do you reject the null hypothesis? What does that mean?\n\n\nAnswer\n\nThe p-value is &lt;.001. This is smaller than 0.05. Therefore, we reject the null hypothesis, which was: \\(H_0: \\mu1=\\mu2=\\mu3=\\mu4=\\mu5\\)\nThis means that the means of at least two groups are different. Note that we do not yet know for which groups the means differ!\n\nFinally, there’s an interesting nugget of information below the final table. It’s called R Squared. This shows the total amount of variance in y that is explained by group membership.\nWhat is the value of R Squared? \nBy rule of thumb, what is the magnitude of this value (small, medium, or large)?\nCohen (1988) proposed the following guidelines for interpreting the magnitude of R2:\n\n\nSize\nR2\n\n\n\nSmall\n0.01\n\n\nMedium\n0.06\n\n\nLarge\n0.138",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>GLM-IV: ANOVA</span>"
    ]
  },
  {
    "objectID": "glm4anova.html#anova-using-regression",
    "href": "glm4anova.html#anova-using-regression",
    "title": "11  GLM-IV: ANOVA",
    "section": "\n15.2 ANOVA using regression",
    "text": "15.2 ANOVA using regression\nThis time, we will conduct the ANOVA using the regression interface.\nWhen we conduct ANOVA using regression, we still test the null hypothesis mentioned before:\n\\(H_0: \\mu_1 = \\mu_2 = \\mu_3 = \\mu_4 = \\mu_5\\)\nA different way to phrase this when using regression is to state that all regression coefficients will be zero:\n\\(H_0: \\beta_0 =\\beta_1 = \\beta_2 = \\beta_3 = \\beta_4\\)\nOr to say that the explained variance will be zero:\n\\(H_0: \\rho^2 =0\\)\nAll of these hypotheses are interchangeable and imply that the means of all five groups are the same. If this is not the case, each of these null-hypotheses would be rejected. Rejecting these null hypothesis implies that at least one one of these means is different from the rest.\nTo test the differences between groups, we first create dummy variables. Let’s make them for all categories, but we will mostly use group 1 as reference category. When making dummies, it’s most convenient to use syntax:\nRECODE group (1=1) (2=0) (3=0) (4=0) (5=0) INTO dgroup1.\nRECODE group (1=0) (2=1) (3=0) (4=0) (5=0) INTO dgroup2.\nRECODE group (1=0) (2=0) (3=1) (4=0) (5=0) INTO dgroup3.\nRECODE group (1=0) (2=0) (3=0) (4=1) (5=0) INTO dgroup4.\nRECODE group (1=0) (2=0) (3=0) (4=0) (5=1) INTO dgroup5.\nEXECUTE.\nCreate the necessary syntax for a regression with the dummy variable that compares the means of group 1 against all other groups.\nYou can find the dialog for the regression under Analyze &gt; Regression &gt; Linear\nIn the SPSS dialog you have to specify the Dependent and Independent variable. In our case, the independent variables are all dummies we created, except for the reference category! Use category 1 as reference category.\nCompare your syntax to the correct syntax:\nREGRESSION\n  /MISSING LISTWISE\n  /STATISTICS COEFF OUTS R ANOVA\n  /CRITERIA=PIN(.05) POUT(.10)\n  /NOORIGIN \n  /DEPENDENT y\n  /METHOD=ENTER dgroup2 dgroup3 dgroup4 dgroup5.\nAlso compare this syntax to the one we used for t-test using regression. What is the only difference?\nWhich test statistic do you use to determine the significance of your ANOVA? \nAll of the ts\nR2\nF\nt for the Constant\nWhat is the value of the test statistic? \nCompare this output to the output of your previous ANOVA!\nWhich parts are the same? Which parts are different?\n\n\nAnswer\n\nThe F-test is identical to the one from the ANOVA. What’s different is that the regression also gives us t-tests for the difference between each group and the reference group. By changing the reference group, we can make all possible comparisons.\n\nNote that, unlike the t-test interface, the regression interface does not provide a Levene’s test. This is one reason you might want to use the t-test interface. The regression interface provides a more generic way to test the assumption of homoscedasticity: a residual plot.\nGo back through the regression interface, but this time click the Plots button and plot the predicted value (X = ZPRED) against the residual value (Y = ZRESID).\nAlternatively, just add this line to your syntax (make sure to remove the period . from what was previously the last line):\n  /SCATTERPLOT=(*ZRESID ,*ZPRED).\nIf the assumption of homoscedasticity is met, we should see that the dots in this plot are equally distributed around the zero line for all values on the X-axis. In this case, we see some differences that could lead us to question the assumption. However, we don’t get an actual test, which is a pity. Thus, you could use the ANOVA interface if you want this test.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>GLM-IV: ANOVA</span>"
    ]
  },
  {
    "objectID": "glm4anova.html#one-way-anova",
    "href": "glm4anova.html#one-way-anova",
    "title": "11  GLM-IV: ANOVA",
    "section": "\n15.3 One-Way ANOVA",
    "text": "15.3 One-Way ANOVA\nWe have prepared the following data file for this assignment: hiking.sav Download hiking.sav. Please download it and open it in SPSS.\nThe data file describes the result of a fictitious experiment in which a hiking guide has displayed five different types of behavior towards different groups of hikers. The treatment that each person received from the guide is recorded in the variable behavior.\nThe dependent variable of this experiment is feeling. Higher scores on this variable indicate a more positive attitude of a participant towards the guide. In this assignment, we will use ANOVA to determine whether the mean score on the dependent variable differs between the five experimental conditions.\nWhat type of design do we use for this experiment? \nWithin-subjects design\nBetween-subjects design\nCombination of the two\nAs you will have noticed, the data file contains a third variable named weather, which can be either good or bad. For now, we will only look at the results obtained during good weather. Hence, we will use “Select cases” to select only those participants with a value of 1 on the weather variable.\nClick Data &gt; Select Cases and select “If condition is satisfied” and click the “If”-button. Now enter the following condition into the equation box:\nweather = 1\nNow click “Continue” and “Paste” to paste the resulting syntax into the syntax editor. Select Run &gt; All to run it.\nVerify that half of the participants have been crossed out in the Data View.\nWe are now ready to perform an ANOVA with the 50 remaining participants.\nTo run an ANOVA in SPSS there are multiple options. We will use the module “General Linear Model”, which encompasses ANOVA and all of its extensions which we will discuss later on (factorial ANOVA, ANCOVA, and repeated measurements).\nAnyway, let’s first create the basic syntax.\nAnalyze &gt; General Linear Model &gt; Univariate Choose feeling as the dependent variable and behavior as the fixed factor Click on the “Options” button and check the two boxes named “Descriptive” and “Homogeneity tests”. After clicking “Paste” you should get the following syntax:\nUNIANOVA feeling BY behavior    \n    /METHOD=SSTYPE(3)   \n    /INTERCEPT=INCLUDE   \n    /PRINT=DESCRIPTIVE HOMOGENEITY    \n    /CRITERIA=ALPHA(.05)   \n    /DESIGN=behavior.   \nWhat is the p-value of the Levene’s test? Use the Levene’s test “Based on mean” again. \nDo we have reason to question the assumption of equal population variances? \nYes\nNo\nIn ANOVA, we distinguish between three sources of variation: the Sums of Squares total (SSt), the Sums of Squares between (SSb, or SSR) and the Sums of Squares within (SSw, or SSE).\nWhat does the Sum of squares total mean (phrase your answer in your own words)? Look up the value of the SSt in the ANOVA output and write it down as well.\nWhat does the Sum of squares between entail (phrase your answer in your own words)? Look up the value of the SSb in the ANOVA output, and write it down as well.\nWhat does the Sums of squares within entail (phrase your answer in your own words)? Look up the value of the SSw in the ANOVA output, and write it down as well.\n\n\nAnswer\n\nThe Between Groups Sum of squares or SSb is equal to 18.330 and simply give the squared distance of individual scores to the mean, summed together. In other words, it shows how much variability there is in the group means. If all group means would be equal to each other, the SSb equals 0.\nThe SSw here is 38.405. It tells us how much the individual scores within a group deviate from the group mean. In other words, it shows how much variability there is within the groups. The is the variation that is independent from the experimental effect (because variation within groups cannot be caused by differences in experimental conditions).\nThe SSt tells us how much the invidual scores deviate from the grand mean. In other words, it shows how much variability there is in the dependent variable in total.\nRecall that SSB is the same as SSR; it can be found in the row “Corrected Model”, column Type III Sums of Squares.\nRecall that the SSW is the same as SSE; it islabeled “Error” in the column Type III Sums of Squares.\n\nHow do we use the different types of Sum of Squares to calculate the F statistic?\n\n(SSB/dfb)/(SSW/dfw)(SSW/dfw)/(SSB/dfb)(SSW)/(SSB)(SSB)/(SSW)\n\n\n\nAnswer\n\nWe can calculate F using the following formula:\n\\(F = \\frac{MSb}{MSw}\\)\nThe MSb and MSw give the between group variance and within group variance, respectively. They can be calculated using the following formula’s:\n\\(MSb = \\frac{SSb}{k-1}\\), \\(MSw = \\frac{SSw}{N-k}\\)\n\nAgain, consider the table Tests of Between Subjects, which represents the results of ANOVA.\nWhat is the F-value of the ANOVA? \nThe degrees of freedom between (dfb) are  and the degrees of freedom within (dfw) are .\ndfb = k-1\ndfw = N-k\nAgain consider the table Tests of Between Subjects\nWhat is the p-value of the ANOVA? \nYou can find the p-value of the ANOVA in the table named “Tests of Between-Subjects Effects”. The p-value is equal to the Sig.-value in the first row of this table.\nWhat can you conclude from this?\nWrite down a statistical conclusion and a conclusion within the context of this research example.\n\n\nAnswer\n\nThe p-value is smaller than our alpha level (0.05). Therefore, we can conclude that there was a statistically significant difference in positive attitude between the groups, based on the behaviour the guide displayed towards them, (F(4,45) = 5.369, p = .001).\n\nWhat is the proportion of variance explained by behavior? \nHow would you describe this number in words? So what does it mean?\nRemark: Cohen formulated some rules of thumb for interpreting the \\(R^2\\) How would you qualify the strength of the effect based on Cohen’s rules of thumb? And why should we not take the rules of thumb too seriously?\nCohen (1988) proposed the following guidelines for interpreting the magnitude of \\(R^2\\)\n\n\nSize\n\\(R^2\\)\n\n\n\nSmall\n0.01\n\n\nMedium\n0.06\n\n\nLarge\n0.14\n\n\n\nNote that, in ANOVA, \\(R^2\\) is also called \\(\\eta^2\\) (eta squared) is a measure of effect size, it indicates the amount of variance in thedependen t variable that is explained by the independent variable(s). In our case, 32.3% of the variance in feeling is explained by behaviour. According to Cohen’s guidelines this is a large effect size (see slide 28). However, these guidelines are rather arbitrary, which Cohen himself also stresses.\nThe correct conclusion so far is that the five groups differ significantly on the dependent variable feeling. However, we do not yet know which groups differ.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>GLM-IV: ANOVA</span>"
    ]
  },
  {
    "objectID": "glm4anova.html#one-way-anova-using-regression",
    "href": "glm4anova.html#one-way-anova-using-regression",
    "title": "11  GLM-IV: ANOVA",
    "section": "\n15.4 One-Way ANOVA using regression",
    "text": "15.4 One-Way ANOVA using regression\nIn this assignment, we will conduct the same ANOVA using the regression interface.\nTo test the differences between groups, we first create dummy variables. Let’s make them for all categories, but we will mostly use group 1 as reference category. When making dummies, it’s most convenient to use syntax. Let’s give the dummies informative names this time:\nRECODE behavior (1=1) (2=0) (3=0) (4=0) (5=0) INTO rushing.\nRECODE behavior (1=0) (2=1) (3=0) (4=0) (5=0) INTO stories.\nRECODE behavior (1=0) (2=0) (3=1) (4=0) (5=0) INTO insulting.\nRECODE behavior (1=0) (2=0) (3=0) (4=1) (5=0) INTO jokes.\nRECODE behavior (1=0) (2=0) (3=0) (4=0) (5=1) INTO singing.\nEXECUTE.\nCreate the necessary syntax for a regression with the dummy variable that compares the means of the rushing group against all other groups.\nYou can find the dialog for the regression under Analyze &gt; Regression &gt; Linear\nIn the SPSS dialog you have to specify the Dependent and Independent variable. In our case, the independent variables are all dummies we created, except for the reference category! Use category 1 as reference category.\nCompare your syntax to the correct syntax:\nREGRESSION\n  /MISSING LISTWISE\n  /STATISTICS COEFF OUTS R ANOVA\n  /CRITERIA=PIN(.05) POUT(.10)\n  /NOORIGIN \n  /DEPENDENT feeling\n  /METHOD=ENTER stories insulting jokes singing.\nCan you find all three of the aforementioned sources of variation in the output? The Sums of Squares total (SSt), the Sums of Squares between (SSb, or SSR) and the Sums of Squares within (SSw, or SSE).\nCompare the results to those of the One-Way ANOVA interface.\n\n\nAnswer\n\nIn the ANOVA table, the Regression Sum of Squares is identical to the “Between Groups Sum of Squares” from the One-Way ANOVA interface. The Residual Sum of Squares is identical to the “Within Groups Sum of Squares” from the One-Way ANOVA interface. And the Total Sums of Squares are also the same.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>GLM-IV: ANOVA</span>"
    ]
  },
  {
    "objectID": "glm5multiple.html",
    "href": "glm5multiple.html",
    "title": "12  GLM-V: Multiple regression",
    "section": "",
    "text": "12.1 Multiple regression\nMultiple regression is a statistical technique that allows us to examine the relationship between one outcome and multiple predictors. It extends the concept of bivariate linear regression, where we model the relationship between two variables, to include more predictors. In the context of social science research, multiple regression helps us answer the question: What is the unique effect of one predictor, while controlling for the effects of all other predictors?\nAs a matter of fact, last week’s analyses for categorical variables with more than two categories were already an example of multiple regression. We included two dummy variables to represent a categorical variable with three categories. All that’s new today is that we also consider the case where the multiple predictors are continuous variables. An important realization is that a regression model can be expanded to include as many predictors as needed. The general formula for multiple regression is \\(\\hat{Y} = a + b_1X_1 + b_2X_2 + \\ldots + b_KX_K\\), where \\(\\hat{Y}\\) represents the predicted value of the dependent variable Y, \\(a\\) is the intercept, and \\(b_{1 \\ldots K}\\) are the slopes for each predictor.\nWhen interpreting the regression coefficients, the intercept (a) represents the expected value of the dependent variable when all predictors are equal to 0. For dummy variables, this is the mean value of the reference category, while for continuous predictors, it represents the expected value for someone who scores 0 on all predictors. The regression coefficients (b1, b2, …, bK) indicate how many units the dependent variable Y is expected to change when the corresponding predictor X increases by 1 unit, while holding all other predictors constant.\nCentering predictors can be useful in multiple regression. By centering, we shift the zero-point of the predictor to a meaningful value, such as the mean value on that predictor. This helps in interpretation, because the intercept now gives us the mean value on the outcome for someone who has an average score on all predictors.\nAs previously explained, standardized regression coefficients drop the units of the predictor and outcome variable. They are calculated by transforming the predictors and outcome variable into z-scores with a mean of 0 and a standard deviation of 1, and performing the (multiple) regression analysis on those z-scores. Because the units of the variables are dropped, standardized coefficients make the effects of predictors comparable across different studies or variables with different measurement units. They represent the change in the dependent variable in terms of standard deviations when the corresponding predictor increases by 1 standard deviation.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>GLM-V: Multiple regression</span>"
    ]
  },
  {
    "objectID": "glm5multiple.html#causality",
    "href": "glm5multiple.html#causality",
    "title": "12  GLM-V: Multiple regression",
    "section": "\n12.2 Causality",
    "text": "12.2 Causality\nA statistical association between variables does not necessarily imply a causal relationship. Instead, causality is either assumed on theoretical grounds, or established using the experimental method. In an experiment, researchers manipulate an independent variable and observe its effects on the dependent variable. However, in many social science studies, experiments are not feasible or ethical, so researchers rely on observational data. In these cases, establishing causal relationships relies on theory and careful statistical analysis.\nOne important concept in causal inference is the direction of effects. While statistical methods can identify associations between variables, determining the direction of causality is a causal assumption that cannot be estimated using statistics alone. The assumed direction of effects is often based on theory and prior knowledge of the subject matter. Researchers make informed assumptions about which variable is likely to have a causal effect on the other based on theoretical reasoning and empirical evidence.\nIn the process of analyzing causal relationships, it is essential to consider the presence of confounders, mediators, and colliders. Confounders are variables that are associated with both the independent and dependent variables and can create a spurious association or distort the true causal relationship. Identifying and controlling for confounders is crucial to ensure accurate causal inference.\nMediators, on the other hand, are variables that explain the relationship between the independent and dependent variables. They act as intermediate steps or process variables in the causal pathway. Understanding and analyzing mediation effects help us understand the underlying mechanisms through which the independent variable affects the dependent variable.\nColliders are variables that are caused by both the independent and dependent variables. Controlling for colliders can lead to spurious statistical relationships between unrelated variables. It is essential to be cautious when including variables in the analysis and consider the causal structure of the variables involved.\nOne important take-home message is that, in multiple regression, the distinction between confounders and colliders is crucial. Including confounders as control variables in multiple regression improves our inferences - but accidentally including a collider as control variable (severely) biases our inferences. You therefore have to carefully reason about each variable’s role in relation to the other variables in the model.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>GLM-V: Multiple regression</span>"
    ]
  },
  {
    "objectID": "glm5multiple.html#multiple-regression-1",
    "href": "glm5multiple.html#multiple-regression-1",
    "title": "12  GLM-V: Multiple regression",
    "section": "\n15.1 Multiple Regression",
    "text": "15.1 Multiple Regression",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>GLM-V: Multiple regression</span>"
    ]
  },
  {
    "objectID": "glm5multiple.html#multiple-regression-2",
    "href": "glm5multiple.html#multiple-regression-2",
    "title": "12  GLM-V: Multiple regression",
    "section": "\n16.1 Multiple Regression",
    "text": "16.1 Multiple Regression\nSocial science students were asked about their opinion towards Tilburg’s nightlife, number of Facebook friends, and some other characteristics. The data are in the SocScSurvey.sav file.\nIn a previous assignment we predicted Facebook friends by extraversion.\nIn this question we will add another predictor, peer pressure.\nThe variable peer pressure refers to the tendency to be influenced by close friends. Higher scores reflect higher sensitivity to peer pressure.\nBefore we proceed with the regression analysis, we will first look at the correlations between the variables.\nAnalyze &gt; correlate &gt; bivariate.\nNow choose as variables: Facebook Friends, Extraversion and Peer Pressure, and click OK.\nWhat is the correlation between peer pressure and number of Facebook friends? \nSuppose three researchers test the significance of the correlation between peer pressure and Facebook friends. Researcher I tests at the 10% level, researcher II tests at the 5% level, and researcher III at the 1% level.\nWhich researcher will reject the null hypothesis? \nOnly researcher III\nAll three researchers\nOnly researcher II\nOnly researcher I\nNow, run the regression analysis in which the number of Facebook friends is regressed on extraversion and peer pressure.\nProceed as follows: via analyze &gt; regression &gt; linear. Choose Facebook friends as dependent and extraversion and peer pressure as independents.\nConsult the output and write down the regression equation.\n\n\nAnswer\n\n\\(\\text{Friends}_i = -158.012 + 26.560*\\text{Extraversion}_i + 12.056*\\text{Peer}_i + e_i\\)\n\nConsider the second person in the sample. The person had an extraversion score of 11 and a score of 9 on peer pressure.\nWhat is the predicted number of Facebook friends for this person? \nConsult the output.\nResearchers conclude that – in the sample – as peer pressure increases with one unit, the predicted number of Facebook friends increases with 12.056 units.\nIs this a valid conclusion? \nYes\nNo\nIn multiple regression, the regression coefficients show us the expected changes in the dependent variable, while keeping the other independent variables constant.\nWith this in mind, what is the correct conclusion?\n\nAs peer pressure increases with one unit the predicted number of Facebook friends increases with 12.056 units.As peer pressure increases with one unit the predicted number of Facebook friends increases with 12.056 units, while extraversion changes with 26.56 units.As peer pressure increases with one unit the predicted number of Facebook friends increases with 12.056 units, while keeping extraversion constant.As peer pressure increases with one unit the predicted number of Facebook friends increases with 12.056 units. This is added to the constant of -158.01.\n\nConsult the table Coefficients. The table shows the results of t-tests.\nWhat are the null hypotheses and alternative hypotheses that are tested here?\n\n\nAnswer\n\nThe t-tests test significance of the individual regression coefficients. In particular, for each coefficient we can use the t-tests to test the following hypotheses:\n\\(H_0: \\beta = 0\\), \\(H_1: \\beta \\ne 0\\)\n\nWhat is the value of the test-statistic for the significance test for extraversion? \nConsider the t-tests for the regression coefficients again.\nHow many degrees of freedom do the t-tests have? \n\n\nExplanation\n\nNote that:\nDegrees of freedom = N - p N = number of participants; p = number of parameters in the model (intercept + two regression slopes)\n\nSuppose three researchers test the significance of peer pressure as a predictor of Facebook friends, while controlling for extraversion. Researcher I tests at the 10% level, researcher II tests at the 5% level, and researcher III at the 1% level.\nWhich researcher(s) will reject the null hypothesis? \nOnly researcher II\nOnly researcher I\nAll three researchers\nOnly researcher III\nWhat percentage of the total variance in Facebook friends can be explained by both extraversion and peer pressure? \nCompare the \\(R^2\\) of the regression model with both predictors with the \\(R^2\\) of a model with only extraversion as the predictor.\nWhat is the difference? \nIn the previous step we compared the \\(R^2\\) of two so called nested models.\nTwo models are nested if the larger model (i.e., the model with the most predictors) contains all predictors of the smaller model.\nIn the next lecture we will learn more about nested models, model comparisons, and how useful they are for researchers!",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>GLM-V: Multiple regression</span>"
    ]
  },
  {
    "objectID": "glm5multiple.html#multiple-regression-ii",
    "href": "glm5multiple.html#multiple-regression-ii",
    "title": "12  GLM-V: Multiple regression",
    "section": "\n16.2 Multiple Regression II",
    "text": "16.2 Multiple Regression II\nFor this assignment we need the file HealthyFood.sav.\nThis file contains hypothetical data on three variables:\nEating healthy food (the higher the score, the healthier a person’s diet) Knowledge about food (the higher the score, the more a person knows about healthy food and risks of unhealthy food) Income (higher scores = more income).\nLet’s first look at the associations (correlations) between the three variables.\nCompute the correlations and summarize the relationships between all pairs of variables. Include in your answer the strength of the relationship (i.e., weak, moderate, or strong), the direction of the relationship (i.e., positive or negative), and generalizability to the population (i.e., is the correlation significant at the 5% level).\nCohen’s rules of thumb:\n\nr = 0.00-0.30 (none to weak)\nr = 0.30-0.50 (weak to moderate)\nr = 0.50-0.70 (moderate to strong)\nr = 0.70-0.90 (strong to very strong)\nr = 0.90-1.00 (very strong)\n\n\n\nAnswer\n\n\nIncome and eating have a weak positive correlation, which is significant at the 5% level.\nIncome and knowledge have a weak to moderate positive correlation, which is significant at the 5% level.\nKnowledge and eating have a moderate to strong positive correlation, which is significant at the 5% level.\n\n\nResearchers may be interested in explaining differences in eating healthy food: in other words, they want to know why some people eat very healthy, while others tend to eat unhealthy.\nOne of the hypotheses is that healthy food is on average more expensive than unhealthy food, so one of the explanatory variables may be income.\nRun a regression analysis using eating as the dependent variable and income as the independent variable.\nConsult the output.\nWhich of the following conclusions is correct?\n\nThe effect of Income on eating healthy food is positive and significantly different from zero.The effect of Income on eating healthy food is positive but not significantly different from zero.\n\nSimple regression analysis suggests a positive relationship between income and healthy food.\nHowever, other researchers (say Team B) came up with an alternative explanation. They hypothesized that the relationship between income and healthy food can be explained by a confounder; knowledge. People with more knowledge will have better jobs (on average), and, as a result more, income. As the result of their knowledge they also prefer to eat healthy food. I.e., Team B thinks knowledge is a common cause of income and eating healthy food.\nIn other words, the researchers of Team B hypothesize that the relationship between income and eating healthy food is \nIndirect\nSpurious\nDraw (on a piece of paper) the conceptual model that reflects the hypotheses of the researchers.\n\n\nAnswer\n\n\n\nNow let’s see if the data support the hypotheses of the researchers.\nRun a multiple regression analysis using eating healthy food as the dependent variable and income and knowledge as independent variables.\nConsult the output. Look at the effect of income, controlled for knowledge (both the coefficient and the significance test).\n\nWhat happened with the effect of income if you control for knowledge?\nDoes knowledge predict eating healthy food (controlled for income)?\nDo the data support the hypothesis that the relationship between income and healthy food is confounded by knowledge?\n\nWhat is the p-value of Income when you control for Knowledge? \nWhat is the p-value of Knowledge, controlling for Income? \nDo the data support the hypothesis that the relationship between income and healthy food is confounded by knowledge? \nYes\nNo\nFinally, interpret the output. Write down the answers to the following questions:\n\nHow well can we predict the variance in healthy eating with the predictors income and knowledge? Interpret R2, report the appropriate test and its significance\nInterpret the regression coefficients (size, direction, significance)\nWhich predictor is the most important predictor of healthy eating behavior? Inspect the standardized regression coefficients\n\n\n\nAnswer\n\nIncome and Knowledge together predict 44.9% of the variance in Eating healthy food, which is significantly different from zero, \\(R^2 = .45, F(2, 347) = 141.179, p &lt;.001\\).\nControlling for Knowledge, Income has a positive, but non-significant effect on Eating healthy food, t(347) = .283, p = .778.\nControlling for Income, Knowledge has a positive, significant effect on Eating healthy food, t(347) = 15.287, p &lt;.001.\nKnowledge is the most important predictor (\\(\\beta\\) = .665) (compare it with \\(\\beta\\) = .012 of Income).",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>GLM-V: Multiple regression</span>"
    ]
  },
  {
    "objectID": "glm6nested.html",
    "href": "glm6nested.html",
    "title": "13  GLM-VI: Nested models",
    "section": "",
    "text": "14 Lecture",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>GLM-VI: Nested models</span>"
    ]
  },
  {
    "objectID": "glm6nested.html#multiple-regression",
    "href": "glm6nested.html#multiple-regression",
    "title": "13  GLM-VI: Nested models",
    "section": "\n16.1 Multiple Regression",
    "text": "16.1 Multiple Regression",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>GLM-VI: Nested models</span>"
    ]
  },
  {
    "objectID": "glm6nested.html#multiple-regression-1",
    "href": "glm6nested.html#multiple-regression-1",
    "title": "13  GLM-VI: Nested models",
    "section": "\n17.1 Multiple Regression",
    "text": "17.1 Multiple Regression\nThis assignment revolves around multiple regression with more than two predictors.\nUse the data file called Work.sav. These data were about work characteristics.\nOpen the date file in SPSS to get started!\nConsider the following research question(s):\n“To what extent do variety at work, learning possibilities, and independence at work explain pleasure at work, and which of these explanatory characteristics is most important?”\nWhat are the independent variables in this research question?\n\nvarietypleasurevariety, learning possibilities, independencevariety, learning possibilities, independence, pleasure\n\nLet’s now run a multiple regression analysis to get the output we need to answer our research question.\nNavigate to Analyze &gt; Regression &gt; Linear. Enter the dependent variable (pleasure at work). Enter the independent variables (variety at work, learning possibilities, independence at work). Paste and run the syntax.\nIn the next steps we will go over the output from this analysis.\nWhat percentage of the total variance in work pleasure is explained by variety at work, learning possibilities, and independence at work altogether? \nWhich of the following statements correctly summarizes the F-test for the R2 in this analysis?\n\nR-square is not significant, F(3, 118) = 14.455, p &lt; .001R-square is significant, F(3, 118) = 14.455, p &lt; .001R-square is not significant, F(3, 121) = 14.455, p &lt; .001R-square is significant, F(3, 121) = 14.455, p &lt; .001\n\nConsider the “Coefficients” table.\nWhat is the unstandardized regression coefficient for the effect of variety at work on work pleasure? \nDescribe the effect of variety at work on work pleasure as precise as possible.\nIn other words, how should we interpret the unstandardized regression coefficient for variety at work?\n\n\nAnswer\n\nWhen variety at work increases with one unit and the other two variables stay constant, pleasure at work increases with .272 units.\n\nNow, consider the effect of independence at work on work pleasure.\nWhat is the standardized regression coefficient of the effect of independence at work on work pleasure? \nDescribe the effect the effect of independence at work on work pleasure as precise as possible using the standardized regression coefficient.\nIn other words, how should we interpret the standardized coefficient for this predictor?\n\n\nAnswer\n\nWhen independence at work increases with one SD and the other two variables stay constant, pleasure at work increases with .107 SDs.\n\nWhich of the predictors has a significant partial effect on pleasure at work when using \\(\\alpha\\) =.10? \nVariety at work and Learning possibilities\nVariety at work\nNone\nIndependence at work\nLearning possibilities\nIn the final couple of steps we went through the output displayed in the “Coefficients” table. Before you proceed with the next assignment, please review the following aspects in the answers your gave:\n\nWhen you wrote down the effect of variety at work on pleasure at work in unstandardized form, did you include that it is the effect of the IV on the DV controlled for the other two variables? If not, please keep in mind that this is very important! In multiple regression, all effects are partial (unique) effects, controlling for the other predictors.\nWhen you wrote down the effect of independence at work on pleasure at work in standardized form, did you indicate that it is the effect in standard deviations, and, again, did you include that it is the effect of IV on the DV controlled for the other two variables (i.e., 1 SD change in independent variable independence at work leads to a .107 SDs change in the predicted score for pleasure at work, controlled for the other variables)?",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>GLM-VI: Nested models</span>"
    ]
  },
  {
    "objectID": "glm6nested.html#unique-contributions",
    "href": "glm6nested.html#unique-contributions",
    "title": "13  GLM-VI: Nested models",
    "section": "\n17.2 Unique Contributions",
    "text": "17.2 Unique Contributions\nUse the data file called Work.sav. These data were about work characteristics.\nIn this assignment, we will look more closely at how to evaluate the “added value” of one predictor in addition to the other predictors in an analysis explaining the dependent variable. Or, put the other way around, how much we lose if we would remove a certain predictor from the model.\nWe will again consider the analysis in which we predicted pleasure at work by the three predictors learning possibilities, independence at work, and variety at work.\nWe want to know how much the variable variety at work adds to predicting work pleasure.\nRun the two analyses specified below:\nRun the regression analysis using all three predictors.\nRun the regression analysis analysis with only learning possibilities and independence at work as predictors.\nInspect the R2 of both regression analyses.\nWhat happened with the R2 when variety was removed?\n\n\nAnswer\n\nWith all three predictors included, R-square equals .269 (see slide 3) With Variety at Work removed, R-square equals .248. So, R-square decreased with .021, indicating that Variety at Work uniquely explains 2.1% of the total variance in Pleasure at Work.\n\nLet’s do the same for the other two predictors; that is, check how much the R2 changes if you would remove the predictor from the model.\nWrite down the changes below.\n\n\nAnswer\n\nWith Learning Possibilities removed, R square equals .211. R-square decreased with .058, which means that Learning Possibilities uniquely explains 5.8% of the total variance in Pleasure at Work. With Independence at Work removed, R square equals .260. R-square decreased with .009, which means that Independence at Work uniquely explains 0.9% of the total variance in Pleasure at Work.\n\nWhich predictor explained the least unique variance, controlling for the other two? \nVariety at work\nIndependence at work\nLearning possibilities",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>GLM-VI: Nested models</span>"
    ]
  },
  {
    "objectID": "glm6nested.html#hierarchical-regression-analysis",
    "href": "glm6nested.html#hierarchical-regression-analysis",
    "title": "13  GLM-VI: Nested models",
    "section": "\n17.3 Hierarchical Regression Analysis",
    "text": "17.3 Hierarchical Regression Analysis\nIn this assignment we will carry out a hierarchical regression analysis, which is a structured way to compare nested models in linear regression analysis.\nWith hierarchical regression analysis we are able to compare two (or more) nested models. Consider the model below:\n\\(Y′ = b0 + b1X1 + b2X2 + b4X4 + b5X5 + b7X7\\)\nWhich of the following models is/are nested within the larger model presented above?\n\n\\(Y′=b0+b1X1+b2X2+b4X4\\)\\(Y′=b0+b1X1+b3X3+b4X4\\)\\(Y′=b0+b1X1+b2X2+b6X6\\)\n\nWe will now get back to our data on work characteristics using the data file Work.sav.\nConsider the following situation in which researchers are interested in clusters of variables:\nResearchers are interested in the effect of “Health” (i.e., mental pressure, physical demands, and emotional pressure) and “Social Environment” (i.e., relationship with coworkers, and relationship with supervisors) on the Need for recovery.\nWe will address this research question in a number of steps.\nFirst, we will look at the full model (i.e., the model that has all health and social environment predictors).\nRun the regression analysis in which you regress Need for recovery on the three health variables (i.e., mental pressure, physical demands, and emotional pressure) and the two social environment variables (i.e., relationship with coworkers, and relationship with supervisors).\nWhat is the R2 of the full model? \nNow we want to test the significance of the clusters of variables. We will first look at the Health variables (emotional pressure, physical demands, & mental pressure). We want to test whether Health has a direct effect on Need for recovery controlled for the social environment predictors.\nTo accomplish this, we have to do a hierarchical regression analysis, in which we compare two nested models: a small one, and a larger one.\nWrite down what these two models look like.\nHow many predictors does the smaller model contain? \nHow many predictors does the larger model contain? \n\n\nAnswer\n\n\nSmall model: \\(Recover_i = b0 + b1 * sccowork_i + b2 * scsuperv_i + e_i\\)\n\nLarge model: \\(Recover_i = b0 + b1 * sccowork_i + b2 * scsuperv_i + b3 *scmental_i + b4* scphys_i + b5* scemoti_i + e_i\\)\n\n\nThe small model has 2 predictors and the large model has 5 predictors. The large model has three predictors more than the small model.\n\nNow run the hierarchical regression analysis in SPSS!\nNavigate to Analyze &gt; Regression &gt; Linear\nClick on “Reset” to start from scratch.\nSelect Need for Recovery as the dependent variable.\nSelect only the Social Environment variables (i.e., Relationship with coworkers and Relationship with supervisors) as the independent variables (this is the small model). This is block 1 of 1.\nClick on “Next”. Select the three Health variables (i.e., emotional pressure, physical demands, and mental pressure) and add those to this second block.\nImportant: Now click on the button “Statistics” to request the R2 change.\nPaste and run the syntax. Note the following new elements:\n  /STATISTICS COEFF OUTS R ANOVA CHANGE\n  /METHOD=ENTER sccowork scsuperv\n  /METHOD=ENTER scmental scphys scemoti.\nThe CHANGE command asks for \\(R^2\\) change statistics, and the two rows of /METHOD=ENTER sequentially add blocks of predictors to the model (enter them into the model).\nLet’s inspect the table labeled “Model Summary” first.\nWhat percentage of the total variance in Need for recovery is explained by the small model? \nHow much of the total variance in Need for recovery is explained by the large model? \nWhat is the R2-change from Model 1 to Model 2? \nThe Model Summary table also reports the results of the F-tests, which tests whether the change in R2 is significant.\nWrite down the null and alternative hypothesis that are evaluated by these F-tests, then check your answer?\n\n\nAnswer\n\n\\(H_0: \\Delta R^2 = 0\\)\n\\(H_0: \\Delta R^2 \\ne 0\\)\n\nSuppose three researchers use the output to see whether the R2-change is significant. Researcher I tests at the 10% level, Researcher II tests at the 5% level, and Researcher III tests at the 1% level.\nWhich of the researchers will conclude that there is a significant result? \nOnly researcher I\nAll three researchers\nOnly researcher II\nOnly researcher III\nSuppose the researchers summarized the result as follows:\n“Health variables explain 11.3% of the variance in need for recovery.” \nYes\nNo\n\n\nExplanation\n\nThe correct interpretation is:\n“The health variables explain an additional 11.3% of the total variance in Need to recover, on top of what is already explained by the social environment variables.”\nAlternatively, you may summarize the result as:\n“The health variables uniquely explain 11.3% of the total variance in Need to recover, while controlling for the social environment variables.”\nSince the R2-change was significant, we have evidence that “Health” had a direct effect on the Need to recover.\n\nNow test whether the social environment variables have an effect on need to recover (while controlling for the health variables). Summarize the results (include all relevant statistics: test statistics, degrees of freedom, p-values).\nInclude in your answer:\nThe R2 of the Small and Full model.\nThe R2-change and whether or not it is significant (use a significance level of .05).\nA substantive interpretation of the R2-change (within the context of this assignment).\nThe first step is to run the hierarchical regression analysis, with the health variables in Block 1 and the social environment variables in Block 2.\n\n\nAnswer\n\nThe model with social environment variables explains 14.2% of the total variance in Need for Recovery. Health variables explain an additional 7.8% of variance in Need for Recovery, and this difference significantly differs from zero, \\(\\Delta R^2 = .08, F(2,116) = 5.800, p = .004\\). This means that the social environment variables uniquely explain 7.8% of the total variance in Need for Recovery, while controlling for the health variables. The total explained variance in Need for Recovery is 22.0%, which is significantly different from zero, \\(F(5, 116) = 6.536, p &lt; .001\\).",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>GLM-VI: Nested models</span>"
    ]
  },
  {
    "objectID": "glm6nested.html#dummies-and-continuous-predictors",
    "href": "glm6nested.html#dummies-and-continuous-predictors",
    "title": "13  GLM-VI: Nested models",
    "section": "\n17.4 Dummies and Continuous Predictors",
    "text": "17.4 Dummies and Continuous Predictors\nIn this assignment we will predict a continuous outcome variable from a dichotomous predictor (i.e. gender).\nThe data file that we will use is PublicParticipation.sav.\nThis data file contains data on the following variables:\n\nincome (higher score = higher income)\npublic participation (i.e. being a member of school boards, municipal councilor, etc.)\neducation\nage\ngender (0 = females; 1 = males)\n\nWe want to test the following research question:\n“Are there gender differences in Public Participation?”\nTo answer this research questions, we can use an independent samples t-test.\nRun an independent samples t-test to answer the research question (consult the information button in case you forgot how to run an independent samples t-test.)\nConsult the output to answer the questions in the next steps.\nAnalyze &gt; Compare means &gt; Independent samples t-test.\nChoose Public Participation as the dependent variable.\nThe grouping variable is Gender. Define the groups: group 1 = 0 (i.e., women) and group 2 = 1 (i.e., men).\nPaste and run the syntax.\nWhat is the mean difference between men and women? \n\nConsult the table Group Statistics.\n“In the sample, men score on average  points higher on public participation than women.”\nWhich of the following statements correctly summarizes the results of Levene’s test (use \\(\\alpha\\)=.05)?\n\nLevene's test is not significant, no evidence against the assumption of homoscedasticityLevene's test is significant, evidence against assumption of homoscedasticity.\n\nThe researchers conclude:\n“We have convincing evidence that the population means of public participation differs between males and females.”\nIs this a valid conclusion? \nYes\nNo\nReport the test results, then check your answer.\n\n\nExplanation\n\nThe mean level of public participation differs between males (\\(M = 16.54\\)) and females (\\(M = 9.95\\)), \\(t(41) = -4.942, p &lt;.001\\).\n\nWhat is the (absolute) value of the t-statistic? \nFrom the results of the t-test the researchers would conclude that males on average have higher levels of public participation than females.\nBut, of course, we don’t know for sure, because we did not test the entire population. Which error type could the researchers have made? \nType I error \nType II error\nType I or Type II error \n\n17.4.1 Examining Income\nIn the previous steps, we used the independent sample’s t-test to test for mean differences in public participation and found a significant result. Results suggested that males show higher levels of public participation. However, males and females may differ not only in gender, but also in other characteristics that explain differences in public participation. In particular, the researchers hypothesize that income differences may play a role as well. Research has shown that income is positively associated with public participation. So if males and females differ in income (on average), the gender differences in public participation may be partly due to income differences.\nIn other words, according to the researchers income may be a \nconfounder\npredictor\nmoderator\ncollider of the effect of gender.\nBefore we proceed, let’s first check whether the groups differ on income. Request the means for the variable income for both males and females separately.\nDo the males and females in the sample differ in average income?\nTake your existing syntax for gender differences in Participation, and change it to test for income differences instead:\nT-TEST GROUPS=Gender(0 1)\n  /MISSING=ANALYSIS\n  /VARIABLES=Income\n  /ES DISPLAY(TRUE)\n  /CRITERIA=CI(.95).\nIs there a difference in income? \nYes\nNo\nThe next step is to study gender differences controlled for income differences. This is not possible via the independent samples t-test interface, but it is possible when specifying our model using regression analyses. Regression analysis allows us to study gender differences controlling for other variables.\n\n17.4.2 Add continuous predictor\nBefore we proceed with the regression analysis including income (we will do this in the next assignment), we will first see what the regression model looks like if we would only use gender as the only predictor in the model.\nRun a regression analysis using Public Participation as the dependent variable, and gender as the independent variable (Analyze &gt; regression &gt; linear). Note that the variable gender is already dummy coded.\nInspect the table with Coefficients.\nWhat is the regression slope of gender? \nCompare the value to the mean difference from ; what do you see?\nRecall that the independent samples t-test is the exact same test as the t-test for the regression slope of a dummy variable.\nCompare the value of the t-statistic in the regression with the value of t-statistic in the independent samples t-test (you may ignore the minus signs). What do you see?\nThe regression coefficient of gender is 6.502. This is the same as the difference in means of Public Participation between males and females. The t-statistic of the regression coefficient is 4.942. The t-statistic in the independent samples t-test was -4.942. As we can ignore the minus sign (just make sure to check which group is higher than the other), we can conclude they are equal.\nWhat percentage of the total variance in public participation is explained by gender? \nRecall that the independent samples t-test and regression analysis with a dummy variable predictor are completely equivalent; SPSS just offers different interfaces to the same linear model.\nWe need to use the regression interface when we want to add other predictors (e.g., income) to see if the gender differences are confounded by other characteristics, and we can calculate the R2 value to evaluate the size of the effect of gender.\nNext, we want to know whether there are differences in public participation between men and women with the same income level.\nIn other words: let’s look at gender differences in public participation controlled for income.\nRun a regression analysis of public participation on income and gender (analyze -&gt; regression -&gt; linear). Consult the output and answer the following questions:\nGender and income jointly explain % of the variance in public participation.\nWhich of the following alternatives correctly report the F-statistic testing the significance of the R2? \nF(2,40)=26.845, p &lt; 0.001\nF(2,42)=26.845, p &lt; 0.001\nThe researchers conclude:\n“On average, women score 4.818 points higher on public participation than men.”\nIs this a valid conclusion? \nNo\nYes\n\n\nExplanation\n\nI hope you concluded that the researchers’ conclusion is incorrect.\nThey should have said:\n“On average, women score 4.818 points less on public participation than men of an equal income level”\nSo, if we take two groups of men and women with the same income (= “controlling for income”), then we expect a mean difference of 4.818 in public participation.\n\nIs there evidence of gender differences, while controlling for income differences when testing at \\(\\alpha = .01\\)? \nYes\nNo\nWrite down the complete regression equation, then check your answer below.\n\n\nAnswer\n\nThe regression equation is as follows:\n\\(\\text{Participation}_i = 5.762 + 3.475*\\text{Income}_i+ 4.818 * \\text{Gender}_i+e_i\\)\n\nSuppose we have a man with an income of 3.0 and a woman with an income of 2.0, what is the predicted difference in public participation? \n\n\nExplanation\n\nMan with an income of 3 has a predicted score of:\nPublic Participation′=5.762+3.475∗3+4.818 ∗1\nPublic Participation′=21.005\nWoman with an income of 2 has a predicted score of:\nPublic Participation′=5.762+3.475∗2+4.818 ∗ 0\nPublic Participation′=12.712\nDifference = 21,005 – 12,712\nDifference = 8.293\n\nWe previously computed the mean difference in public participation for men and women, which was 6.50.\nWhy is this previous mean difference not the same as the effect of gender that we find in this most recent regression analysis?\n\n\nAnswer\n\nThe mean difference as observed in the sample is the mean difference without controlling for income differences.\nHowever, as we have seen, men and women also differ in the average income, and income differences between males and females may also explain differences in public participation. In the regression analyses, we controlled for income differences, which means that we “filtered out” the effect of income (the correct way to say it: we partialed out income effects). After controlling for income the effect of gender is somewhat smaller. Hence, the difference in public participation in the sample means is partly due to income differences.\n\nOne researcher argues that there are gender differences in public participation, and gender differences in income, and that income additionally has an effect on public participation.\nIn this theoretical model, income is a \nConfounder\nCommon cause\nMediator\nModerator",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>GLM-VI: Nested models</span>"
    ]
  },
  {
    "objectID": "glm6nested.html#nested-models",
    "href": "glm6nested.html#nested-models",
    "title": "13  GLM-VI: Nested models",
    "section": "\n17.5 Nested Models",
    "text": "17.5 Nested Models\nFinally, we might want to know how much unique variance is explained by gender, after controlling for income. To this end, we would perform a nested model test.\nConduct this test as you have done before, using the graphical interface or syntax. Remember: Enter Income first, then Gender - and ask for the \\(R^2\\) change statistics.\nLet’s inspect the Model Summary table.\nWhat percentage of the total variance in Participation is explained by Income (only)? \nHow much of the total variance in Participation is explained by both Income and Gender? \nWhat is the R2-change (in percentage) from Model 1 to Model 2? \nThe Model Summary table also reports the results of the F-tests, which tests whether the change in R2 is significant.\nSuppose three researchers use the output to see whether the R2-change is significant. Researcher I tests at the 10% level, Researcher II tests at the 5% level, and Researcher III tests at the 1% level.\nWhich of the researchers will conclude that there is a significant result? \nAll three researchers\nOnly researcher III\nOnly researcher I\nOnly researcher II\nReport the results of your analysis (include all relevant statistics: test statistics, degrees of freedom, p-values).\nInclude in your answer:\n\nThe R2 of the Small and Full model.\nThe R2-change and whether or not it is significant (use a significance level of .05).\nA substantive interpretation of the R2-change (within the context of this assignment).\n\n\n\nAnswer\n\nIncome explains 39.1% of variance in Participation, which is significantly greater than zero, \\(F(1,41) = 26.32, p &lt; .001\\). Gender explains an additional 18.2% of variance in Participation, and this difference significantly differs from zero, \\(\\Delta R^2 = .18, F(1,40) = 17.06, p &lt; .001\\). The total explained variance in Participation by Income and Gender is 55.2%, which is significantly different from zero, \\(F(2, 40) = 26.85, p &lt; .001\\).",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>GLM-VI: Nested models</span>"
    ]
  },
  {
    "objectID": "glm6nested.html#one-more-categorical-variable",
    "href": "glm6nested.html#one-more-categorical-variable",
    "title": "13  GLM-VI: Nested models",
    "section": "\n17.6 One more Categorical Variable",
    "text": "17.6 One more Categorical Variable\nLet’s finish this assignment by adding one more categorical variable, and seeing whether it has a significant unique effect after controlling for Income and Gender. We will use Education level, which has three categories. We thus have to create two dummy variables to account for this variable.\nFirst, make the dummy variables, using low Education status as reference category.\nRemember that these dummies together code for one variable, so you must add them to the model in the same step together.\nWhat is the F test statistic for the \\(\\Delta R^2\\) test for adding Education to a model that already contains Income and Gender? \nWhat is the difference in expected Participation between someone with Low education status and High education status?",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>GLM-VI: Nested models</span>"
    ]
  },
  {
    "objectID": "glm7interaction.html",
    "href": "glm7interaction.html",
    "title": "14  GLM-VII: Interaction",
    "section": "",
    "text": "14.1 Introducing Interactions\nNow, let’s take our regression analysis to the next level by introducing the concept of interactions. An interaction implies that the effect of one predictor variable depends on the level of another predictor variable.\nTo incorporate interactions, we add a special building block to our regression equation:\n\\(Y = a + b_1X_1 + b_2X_2 + b_3(X_1 \\times X_2)\\)\nTo include an interaction term in your regression model:\nIn summary, interactions add a new layer of complexity to regression analysis by acknowledging that the relationships between variables can be contingent on other factors. By incorporating interactions, we can gain deeper insights into the nuanced dynamics between predictors and outcomes in our statistical models.",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>GLM-VII: Interaction</span>"
    ]
  },
  {
    "objectID": "glm7interaction.html#introducing-interactions",
    "href": "glm7interaction.html#introducing-interactions",
    "title": "14  GLM-VII: Interaction",
    "section": "",
    "text": "Calculate a new variable as the product of the two interacting variables.\nAdd this interaction term to the regression equation along with the original variables. Note: You should never include an interaction term in the model without including its constituent terms!",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>GLM-VII: Interaction</span>"
    ]
  },
  {
    "objectID": "glm7interaction.html#interaction-between-one-continuous-and-one-binary-predictor",
    "href": "glm7interaction.html#interaction-between-one-continuous-and-one-binary-predictor",
    "title": "14  GLM-VII: Interaction",
    "section": "\n14.2 Interaction between one Continuous and one Binary Predictor",
    "text": "14.2 Interaction between one Continuous and one Binary Predictor\nInteraction is easiest to explain using one binary predictor, coded as 0 and 1, and one continuous predictor.\nRecall that using this type of “dummy coding” allows us to represent different intercepts for the two groups in our regression model. The intercept of the regression equation applies to the group coded 0 (the reference group), and the intercept of the group coded 1 is equal to the overall intercept plus the effect of the dummy variable. In formulas this is represented as:\n\\[\\begin{align}\nY &= a + bD \\text{, where D} \\in(0,1)\\\\\nY_{D=0} &= a + b*0 = a\\\\\nY_{D=1} &= a + b*1 = a + b\n\\end{align}\\]\nAn interaction implies that not only the intercept but also the regression slope differs between two groups. Imagine we add continuous predictor \\(X\\) to the model, as well as the interaction term \\(D*X\\):\n\\[\\begin{align}\nY &= a + b_1D + b_2X +b_3 (D*X)\n\\end{align}\\]\nIn some cases, we might want to estimate not only distinct intercepts but also distinct slopes for different groups. For instance, we might be interested in understanding how the effect of gender role attitudes on involvement differs for men and women.\nThe complete formula for the regression line varies based the value of dummy variable \\(D\\):\n\\[\\begin{align}\nY_{D=0} &= a + b_1*0 + b_2X +b_3 (0*X) = a + b_2X\\\\\nY_{D=1} &= a + b_1*1 + b_2X +b_3 (1*X) = (a + b_1) + (b_2 + b_3)X\n\\end{align}\\]\nNote that both groups’ regression equations can be simplified into a basic linear formula of the form \\(a + bX\\), except that they each have a unique value for the intercept and regression slope! This is how interaction terms allow you to make the effect of one variable contingent on the value of another.\nIf the interaction term is significant (i.e., the slope for the product of the interacting variables), we conclude that there is significant interaction and the slope of the effect of one interacting variable depends on the value of the other interacting variable.",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>GLM-VII: Interaction</span>"
    ]
  },
  {
    "objectID": "glm7interaction.html#simple-effects",
    "href": "glm7interaction.html#simple-effects",
    "title": "14  GLM-VII: Interaction",
    "section": "\n14.3 Simple Effects",
    "text": "14.3 Simple Effects\nWhen the interaction between a binary moderator and a continuous predictor is significant, we often want to know how big the regression effect of the continuous predictor is in each group of the binary predictor. This is called simple effects analysis.\nOne straightforward way to perform simple effects analysis involves creating dummy variables for both categories of the binary moderator and computing interaction terms with these dummies. Then, specifying two regression models with different reference categories. This gives the effect of the continuous moderator for each group, along with a significance test.",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>GLM-VII: Interaction</span>"
    ]
  },
  {
    "objectID": "glm7interaction.html#interaction-with-two-continuous-predictors",
    "href": "glm7interaction.html#interaction-with-two-continuous-predictors",
    "title": "14  GLM-VII: Interaction",
    "section": "\n14.4 Interaction with Two Continuous Predictors",
    "text": "14.4 Interaction with Two Continuous Predictors\nWhen we previously discussed interaction effects involving one binary and one continuous predictor, we discovered that such interactions result in distinct regression lines for each unique value of the binary predictor. Now, consider an interaction between two continuous predictors. In this scenario, each variable can theoretically take infinite possible values. Therefore, we can no longer think of this as a distinct regression line for each value of the moderator. Instead, we can imagine how an increase in the value of one interacting variable leads to an adjustment of the effect of the other interacting variable.\nTo grasp the concept of interaction effects with two continuous predictors, let’s dive into a concrete example. Imagine we’re investigating the relationship between outcome Y, and continuous predictors X1 and X2. We’ve determined the coefficients for our regression model:\n\\(Y = 12.50 + 1.50 \\cdot X_{1} - 0.20 \\cdot X_{2} + 0.07 \\cdot (X_{1} \\times X_{2})\\)\nLet’s do the same we did for understanding the regression equation with a binary moderator, and simplify it by plugging in a specific value for one of the interacting variables. Suppose we want to know the effect of X1 for someone who scores 0 on the continuous variable X2:\n\\(Y = 12.50 + 1.50 \\cdot X_{1} - 0.20 \\cdot 0 + 0.07 \\cdot (X_{1} \\times 0) = 12.50 + \\textbf{1.50} \\cdot X_{1}\\)\nThe effect for such a person is 1.50. Now, let’s compare this to a person who scores 1 on the continuous variable X2:\n\\(Y = 12.50 + 1.50 \\cdot X_{1} - 0.20 \\cdot 1 + 0.07 \\cdot (X_{1} \\times 1) = (12.50-0.20) + (1.50 + 0.07) \\cdot X_1 = 12.30 + \\textbf{1.57} \\cdot X_1\\)\nNow, the effect of \\(X_1\\) has increased by 0.07 - which was exactly the size of the regression slope for the interaction term.",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>GLM-VII: Interaction</span>"
    ]
  },
  {
    "objectID": "glm7interaction.html#centering-for-interpretability",
    "href": "glm7interaction.html#centering-for-interpretability",
    "title": "14  GLM-VII: Interaction",
    "section": "\n14.5 Centering for Interpretability",
    "text": "14.5 Centering for Interpretability\nWhen working with interactions between two continuous predictors, it’s essential to center the variables. Centering aids interpretability - the effect of one predictor is now given for the average value of the other predictors. Moreover, centering avoids artificial multicollinearity between the two interacting variables and their interaction term.\n\n14.5.1 Simple Slopes\nIf the interaction effect between two continuous predictors is significant, we might want to understand how the effect of one of the interacting predictors varies across levels of the other interacting predictor. This is similar to the simple effects approach from before, except now it’s called simple slopes.\nInstead of computing the effect of one variable for all unique values of a binary moderator, we pick specific values of the continuous moderator - typically +/- 1SD - and calculate the effect of the other predictor at those specific values.\nBy centering the interacting predictors at their mean value +/- 1SD and re-computing the interaction term using those transformed predictors, we obtain simple slopes at different levels of the moderator. Note that centering at \\(M + 1SD\\) gives us the effect for people who score 1SD below the mean (you’re sliding the distribution to the right on the number line, until people who used to score -1SD are centered at 0).",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>GLM-VII: Interaction</span>"
    ]
  },
  {
    "objectID": "glm7interaction.html#multiple-regression",
    "href": "glm7interaction.html#multiple-regression",
    "title": "14  GLM-VII: Interaction",
    "section": "\n17.1 Multiple Regression",
    "text": "17.1 Multiple Regression",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>GLM-VII: Interaction</span>"
    ]
  },
  {
    "objectID": "glm7interaction.html#interaction",
    "href": "glm7interaction.html#interaction",
    "title": "14  GLM-VII: Interaction",
    "section": "\n18.1 Interaction",
    "text": "18.1 Interaction\nIn this assignment we work with the PublicParticipation.sav data. It contains (fictional) data on the following variables: income (higher scores, more income), public participation, education, age, and gender (0 = females; 1 = males). Public participation involves being member of school boards, municipal councillor, etc.\nIn this assignment we will see how we can model interaction between a continuous predictor and a dichotomous predictor.\nSuppose we are interested in relationship between age and public participation, and we want to know if the relationship is moderated by gender. An interaction model is conceptually represented as follows (these two diagrams are interchangeable):\n\n\n\n\n\n\n\n\n\n\n\n\n\nModeling Interactions\nThe regression model for testing the interaction is:\n\\(Y' = b_{0} + b_{1}X + b_{2}D_{g} + b_{3}XD_{g}\\)\nwhere X = age, and D_g = gender (0 = women; 1 = men). Notice that women are our reference group.\nTo model interaction we need to create a new variable, which is the product of the dummy variable (gender in our case) and (age in our case).\nThis is best done via syntax, but to use the graphical interface proceed as follows:\nvia Transform &gt; compute variable\nGive the new variable a name (i.e., the target variable), say GenderTAge.\nThen specify the product at the right (see more information button). Click on Paste, select and run the code. Check in Data View whether the product term was added correctly.\nAlternatively, the syntax is:\nCOMPUTE GenderTAge = Gender * Age.\nEXECUTE.\nNow run the regression analysis that includes the interaction effect.\nImportant: Just like with dummies you must include all dummies that belong to the same variable in the model together, with an interaction term, you must always include its constituent variables as well. This is because the interaction term only modifies the effect of its constituent variables; the effect of those constituent variables must thus also be in the model.\nSo, if you add variable intXTZ into the model, you must also include X and Z.\nVia analyze &gt; regression &gt; linear; choose age, gender and GenderTAge as the independent variables, and public participation as the dependent variable.\nConsult the table Regression coefficients. Write down the general estimated model.\nFinish the following equation, then check your answer.\n\\(\\text{Public Participation' = .....}\\)\n\n\nAnswer\n\n\\(\\text{Public Participation}′ = 3.252 + 0.137*\\text{Age} + 12.439*\\text{Gender} − 0.116*\\text{Gender}*\\text{Age}\\)\n\nNow write down the estimated models down for women and men separately. Hint: fill in 0 and 1 in the general estimated model mentioned in the previous step, then simplify the formula.\nComplete the equations for women (W) and men (M):\n\\(\\text{PP}_W'=\\) \\(+\\) \\(*\\text{Age}\\)\n\\(\\text{PP}_M'=\\) \\(+\\) \\(*\\text{Age}\\)\nNow draw (on a piece of paper) a graph of the results. That is, put age on the x-axis, the predicted public participation on the y-axis, and draw separate regression lines for males and females.\nTrue or false\nIn the sample, age has a positive effect on public participation for women but a negative effect for men? \nTRUE\nFALSE\nThe researchers tested at the 5% level and concluded:\n“We have convincing evidence that the population effect of age on public participation is different for men and women.” \nTRUE\nFALSE\nThe estimated regression model was:\n\\(Y'= 3.252 + 0.137Age + 12.439D_g - 0.116(Age \\times D_g)\\)\nWhat would the regression equation look like if we would have used the men as the reference group? Use logic to answer this question, instead of re-running the analysis.\n\\(Y'=\\) \\(+\\) \\(*\\text{Age}+\\) \\(*D_g+\\) \\(*(\\text{Age} \\times D_g)\\)\n\nTo verify our answer to the previous question, we will recode the variable Gender such that males are scored 0 (= reference group) and females are scored 1.\nProceed as follows:\n\nvia Transform &gt; Recode into different variables\nSelect Gender.\nGive a name to the new output variable (say GenderFem), give a label (say: “Gender (ref=males)” click on change.\nSpecify old and new values: old value 0 becomes 1 and old value 1 becomes 0 (don’t forget to click on add in between).\nClick OK. Verify that SPSS added a new column with a dummy variable where males are the reference group.\nCompute the product variable for the interaction between age and gender but now use the dummy having males as reference group.\nRerun the regression analysis, but now using the new gender variable and interaction term. If you’re answer in the previous step is correct you should find the values back in the table Regression Coefficients.",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>GLM-VII: Interaction</span>"
    ]
  },
  {
    "objectID": "glm7interaction.html#categorical-predictors-with-three-or-more-categories",
    "href": "glm7interaction.html#categorical-predictors-with-three-or-more-categories",
    "title": "14  GLM-VII: Interaction",
    "section": "\n18.2 Categorical Predictors with Three or more Categories",
    "text": "18.2 Categorical Predictors with Three or more Categories\nThe categorical predictor Education has three levels (low, middle, high). If we want to include such a variable we need to use dummies.\nCode the dummy variables as follows:\n\n\nValue\nD1\nD2\n\n\n\nLow\n0\n0\n\n\nMiddle\n1\n0\n\n\nHigh\n0\n1\n\n\n\nWhich group is the reference group according to this coding? \nLow\nMiddle\nHigh\nUse syntax to create the dummies.\nWe are now ready for the regression analysis.\nRun a hierarchical regression analysis with public participation as dependent variable. Model 1 only includes age. Model 2 includes age and the dummies. So we have the following nested models:\nThis model does not include the interaction effects yet! This means that we assume that the regression lines are parallel to one another. In the next assignment we check whether this assumption is reasonable.\nProceed as follows:\n\nvia analyze &gt; regression &gt; linear.\nSelect public participation as the dependent variable and only age as the independent variable. Click on next.\nNow select the two dummies we have created in the previous step. The two dummies together represent education. Always enter dummies into the model together!\nVia Statistics ask for the R-change statistics.\n\nConsult the output and answer the questions in the next few steps.\nEducation and age together explain  % of the total variance.\nWhat is the value of the test statistic that tests the unique effect of education, controlled for age? \nReport the results for the unique effect of education, then check your answer.\n\n\nAnswer\n\nEducation does not have a significant unique effect on public participation after controlling for age, \\(\\Delta R^2 = .04, F(2,38) = 0.895, p = .417\\).\n\nConsult the table with the regression coefficients.\nWrite down the estimated regression equation of Model 2.\n\n\nAnswer\n\n\\(PublicParticipation'\\:=\\:10.478\\:+\\:.097\\:\\cdot \\:Age\\:-\\:2.042\\:\\cdot \\:D1\\:-\\:3.071\\:\\cdot \\:D2\\)\n\nWrite down the estimated model for each of the three groups.\nThen make a graph of the regression equations. Put age on the x-axis, the predicted public participation on the y-axis, and draw the lines for each education group.\n\n\nAnswer\n\nThe models were:\n\\(PP'_l = 10.478 + .097Age\\)\n\\(PP'_m = (10.478-2.042) + .097Age = 8.436 + .097Age\\)\n\\(PP'_h = (10.478-3.071) + .097Age = 7.407 + .097Age\\)\nDid you get it right?\n\nSuppose we have two persons, both are 40 years old, but one had middle level education and the other had high-level education.\nWhat is the expected (absolute) difference in public participation between these two persons? \nThe researchers conclude:\n“Controlled for age, low educated people in the sample show highest level of public participation”.\nIs this a valid conclusion? \nTRUE\nFALSE",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>GLM-VII: Interaction</span>"
    ]
  },
  {
    "objectID": "glm7interaction.html#interaction-with-more-than-two-categories",
    "href": "glm7interaction.html#interaction-with-more-than-two-categories",
    "title": "14  GLM-VII: Interaction",
    "section": "\n18.3 Interaction with more than Two Categories",
    "text": "18.3 Interaction with more than Two Categories\nIn the previous assignment, we assumed that the effect of Age on Public participation was equal for each of the education level groups. However, we do not know whether this assumption is reasonable. In this assignment, we will check whether the interaction effect between Age and Education level is statistically significant or not.\nCreate the two interaction terms using syntax, with the Compute variable command. Note that we need two interaction terms: D1Tage and D2Tage.\nWe are now ready for the regression analysis.\nRun a hierarchical regression analysis. Model 1 only includes age and the two dummy variables. Model 2 additionally includes the interaction terms.\nWrite down the formulas for the two nested models, then check your answer.\n\n\nAnswer\n\n\nModel 1: \\(Y'= b_0 + b_1Age + b_2D_1 + b_3 D_2\\)\n\nModel 2: \\(Y'= b_0 + b_1Age + b_2D_1 + b_3 D_2 + b_4D_1Age + b_5 D_2Age\\)\n\n\n\nProceed as follows (or, preferably, use syntax):\n\nvia analyze &gt; regression &gt; linear.\nSelect public participation as the dependent and age, D1 and D2 as the independent variables. Click on next.\nNow select the two interaction terms we have created in the previous step. The two interaction terms together represent the interaction effect between education and age.\nVia Statistics ask for the R-change statistics.\n\nConsult the output and answer the questions in the next few steps.\nBefore we carry out any of the significance tests, let’s take a look at the coefficients table. Look at the unstandardized coefficients in Model2. First, write down the entire estimated model.\nComplete the following equation:\n\\(Y'=\\) \\(+\\) \\(*Age+\\) \\(*D_{middle}+\\) \\(*D_{high}+\\) \\(*(D_{middle}*Age)+\\) \\(*(D_{high}*Age)\\)\nNext, write down the estimated model for each of the three education groups.\nRemember, fill in 0 and 1 for the dummy variables, then simplify:\n\\(Y_{low}'=\\) \\(+\\) \\(*Age\\)\n\\(Y_{middle}'=\\) \\(+\\) \\(*Age\\)\n\\(Y_{high}'=\\) \\(+\\) \\(*Age\\)\nNow, answer the following questions.\nTrue or False?\nThe effect of Age on Publication Participation in the sample is positive for all education groups. \nTRUE\nFALSE\nFor which group is the effect of Age on publication participation the strongest? \nLow\nMiddle\nHigh\nWe inspected the estimated model. But is there a significant interaction effect to begin with? To answer that question we inspect the Model Summary Table.\nFirst of all, write down the \\(R^2\\) for the model without- and with interactions. What do these numbers mean?\nWithout interactions:  With interactions: \nFinish the following sentence:\nModel 2 with the interaction effects explains an additional  % of the variance in Public Participation compared to Model 1 (on top of what was already explained by the main effects of Age and Education).\nWe will now carry out the F-change test. Write down the null hypothesis and alternative hypothesis that we test with this F-change test.\n\n\nAnswer\n\n\\(H_0:\\:R^2\\:=\\:0\\)\n\\(H_1:\\:R^2 \\ne 0\\)\n\nWrite down the F-value, the df and the p-value.\n\nF-value: \n\ndf: ( ,  )\np-value: \n\n\nTrue or false: there is a significant interaction effect: \nTRUE\nFALSE\nTrue or False: As a follow-up analysis, we should perform a simple effects analysis. \nTRUE\nFALSE\nInterpret the results of Model 1 (without interaction) and report your results.\n\n\nAnswer\n\nThere is no evidence for a significant effect of Age and Education on Participation, \\(R^2 = .10, F(3, 38) = 1.36, p = .27\\).",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>GLM-VII: Interaction</span>"
    ]
  },
  {
    "objectID": "glm7interaction.html#interaction-effects",
    "href": "glm7interaction.html#interaction-effects",
    "title": "14  GLM-VII: Interaction",
    "section": "\n18.4 Interaction Effects",
    "text": "18.4 Interaction Effects\nIn this assignment, you will examine whether the effect of relationship with coworkers (sccowork; higher score = better relationship) on the emotional pressure at work (scemoti) has an interation effect with gender (0 = male, 1 = female).\nIf there is an interaction effect, the effect of sccowork on scemoti depends on the value of the variable gender.\nOpen Work.sav.\nTo be able to examine the interaction effect, you should first create a product variable.\n\nGo to Transform &gt; Compute Variable\nGive a name to the new product variable in Target Variable (GenderTRelco for example).\nIn Nummeric Expression you need to specify how the new variable should be computed. You have to enter gender * sccowork to compute the product of gender and sccowork.\nPaste and run the syntax, and check whether the product variable was added\n\nConduct a multiple regression analysis (using Analyze &gt; Regression &gt; Linear) with scemoti as dependent variable. The independent variables are the main effects (gender and sccowork) and the interaction effect (genderTsccowork).\nWhat is the p-value of the interaction effect? \nTrue or false: The interaction effect is significant at \\(\\alpha = .10\\) \nTRUE\nFALSE\nThe regression equation for the entire sample is:\n\\(\\text{scemoti}'=\\) \\(+\\) \\(*\\text{Gender}+\\) \\(*\\text{Relationship}+\\) \\(*(\\text{Gender}*\\text{Relationship})\\)\nFor males, the value of Gender is 0. That means that GenderTRelco is also 0. The regression equation for males then becomes:\n\\(\\text{scemoti}'=\\) \\(*\\text{Relationship}\\)\nFor females, the value of Gender is 1. What is the regression equation for females?\n\\(\\text{scemoti}'=\\) \\(+\\) \\(*\\text{Relationship}\\)\nDraw (on paper, not in SPSS) a schematic graph of the interaction effect. Put relationship with coworkers on the X-axis, and emotional pressure on the Y-axis. Draw a schematic regression line for each group.\nIn what group is the effect of relationship with coworkers on emotional pressure the strongest: males or females? \nMales\nFemales\nIn practice, you’d often want to know whether the effects within the groups are significant.\nCan you use the output of this regression analysis to draw conclusions about the significance of the effect within each group? \nNo\nYes, but only for the group of males\nYes, but only for the group of females\nYes, for both groups\nAt this moment, we don’t have enough information in the output yet to test the effect within the female group. But we can test the effect within the male group!\nWhat is the p-value of the effect of sccowork on scemoti within the male group? \nTo test the significance within the the group of females, we can simply switch the reference groups.\n\nMake a new dummy variable called male, on which males score 1, and females 0\nCompute a new product variable: COMPUTE maleTsccowork = male * sccowork.\n\n\nPerform a new regression analysis with these predictors. This is exactly the same analysis, but now with women as reference group instead of men.\nLook at the table with the estimated coefficients. What is the p-value of the effect of sccowork on scemoti within the female group?",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>GLM-VII: Interaction</span>"
    ]
  },
  {
    "objectID": "logistic.html",
    "href": "logistic.html",
    "title": "15  GLM VIII - Logistic Regression",
    "section": "",
    "text": "15.1 Introducing the logit\nLogistic regression predicts the logit function of the individual probabilities of observing the outcome, pi. The logit of the probability (pi) is given by log(pi/(1-pi)), ensuring that the predicted values remain within the valid probability range. The outcome, Yi, is assumed to follow a Bernoulli distribution with an individual probability of success, pi. The logit of this success probability is modeled as a linear function of the predictors, allowing us to use the familiar linear regression model to predict the logit of pi.\nUnderstanding the distinction between probability, odds, and the logit is crucial in logistic regression. Probability is defined as the long-run proportion of outcomes of a random experiment in which a particular outcome is observed. Odds describe the ratio of the probability of an event occurring relative to the probability of it not occurring. Finally, the logit transforms odds into a linear function, enabling us to use the regression model. The transformations from probability to odds and logit, and back, are given by:",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>GLM VIII - Logistic Regression</span>"
    ]
  },
  {
    "objectID": "logistic.html#introducing-the-logit",
    "href": "logistic.html#introducing-the-logit",
    "title": "15  GLM VIII - Logistic Regression",
    "section": "",
    "text": "Operation\nFormula\n\n\n\nProbability to odds\n\\(\\text{odds}= \\frac{P}{1-P}\\)\n\n\nOdds to probability\n\\(P = \\frac{\\text{odds}}{1+\\text{odds}}\\)\n\n\nOdds to logit\n\\(\\text{logit} = \\ln(odds)\\)\n\n\nLogit to odds\n\\(\\text{odds} = e^{\\text{logit}}\\)\n\n\nProbability to logit\n\\(\\text{logit} = \\ln(\\frac{p}{1-p})\\)\n\n\nLogit to probability\n\\(p = \\frac{e^{logit}}{1+e^{logit}}\\)",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>GLM VIII - Logistic Regression</span>"
    ]
  },
  {
    "objectID": "logistic.html#maximum-likelihood-estimation-mle",
    "href": "logistic.html#maximum-likelihood-estimation-mle",
    "title": "15  GLM VIII - Logistic Regression",
    "section": "\n15.2 Maximum Likelihood Estimation (MLE)",
    "text": "15.2 Maximum Likelihood Estimation (MLE)\nIn traditional linear regression, we use “ordinary least squares” (OLS) estimation to obtain the model parameters. This method involves simple matrix algebra and always yields a unique solution. However, for logistic regression, there is no OLS solution due to the binary nature of the dependent variable. Instead, we turn to Maximum Likelihood Estimation (MLE). A complete explanation is beyond the scope of this course, but here is a basic intuitive explanation of the procedure:\n\nStart with random values for the coefficients (a and b)\nUsing those parameter values, calculate the individual probabilities predicted by the logistic regression formula\nFor each individual, calculate the likelihood of observing their true outcome in a Bernoulli distribution with model-implied probability pi\nMultiply these probabilities across all individuals to get the overall likelihood of observing these data, given the chosen coefficient values\nAdjust the values of a and b a little bit\nCheck if the likelihood has become larger\nRepeat steps 2-6 until until we find the coefficient values that maximize the likelihood and no further improvement can be found.\n\nIn other words, we look for the values of a and b that maximize the likelihood of observing the observed outcome values.",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>GLM VIII - Logistic Regression</span>"
    ]
  },
  {
    "objectID": "logistic.html#interpreting-coefficients",
    "href": "logistic.html#interpreting-coefficients",
    "title": "15  GLM VIII - Logistic Regression",
    "section": "\n15.3 Interpreting Coefficients",
    "text": "15.3 Interpreting Coefficients\nThe intercept (a) represents the log odds of the outcome (Y) for someone who scores 0 on all predictors. We can convert this log odds to the probability of the outcome for an individual who scores 0 on all predictors using the formula P = e^(a) / (1 + e^(a)). We can also solve for the inflection point at which the model stops predicting 0 and starts predicting 1, or vice versa, using \\(X_{p = .5} = \\frac{-a}{b}\\).\nThe slope (b) of the logistic regression equation determines how steeply the logistic function switches from predicting 0 to predicting 1 as the predictor variable (Xi) increases. Larger absolute values of b indicate a steeper transition between the two outcomes. If the slope is positive, the function ascends (starts at 0 and goes to 1), resulting in an S-shaped curve. Conversely, if the slope is negative, the function descends (starts at 1 and goes to 0), resulting in a Z-shaped curve.",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>GLM VIII - Logistic Regression</span>"
    ]
  },
  {
    "objectID": "logistic.html#odds-ratio",
    "href": "logistic.html#odds-ratio",
    "title": "15  GLM VIII - Logistic Regression",
    "section": "\n15.4 Odds Ratio",
    "text": "15.4 Odds Ratio\nThe odds ratio is another important concept when interpreting logistic regression coefficients. It represents the odds of the outcome occurring given a one-unit increase in the predictor variable (Xi), relative to the odds of the outcome occurring when Xi remains unchanged. For binary predictors (e.g., conditions), the odds ratio provides a sensible effect size. For continuous predictors, the odds ratio is a multiplyer by which the odds increase when the predictor increases by one unit.\nTo calculate the odds ratio for a logistic regression coefficient (b), we use the formula OR = e^(b). A value greater than 1 indicates that the predictor is associated with higher odds of the outcome, while a value less than 1 indicates lower odds of the outcome. For example, if the odds ratio for the test score coefficient (b = 2.12) is 8.35, it means that for each unit increase in the test score, the odds of the outcome are multiplied by 8.35.",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>GLM VIII - Logistic Regression</span>"
    ]
  },
  {
    "objectID": "logistic.html#model-fit",
    "href": "logistic.html#model-fit",
    "title": "15  GLM VIII - Logistic Regression",
    "section": "\n15.5 Model Fit",
    "text": "15.5 Model Fit\nTo assess how well the logistic regression model fits the data, we can use the likelihood obtained from maximum likelihood estimation (MLE). By multiplying the log likelihood by -2, we obtain the \\(-2LL\\), which is a chi-square distributed test statistic. Performing a chi-square test allows us to determine if the overall model is significant. The null hypothesis is that the model does not significantly differ from a model with no predictors. If the chi-square test is significant, it indicates that the model provides a better fit than a null model.",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>GLM VIII - Logistic Regression</span>"
    ]
  },
  {
    "objectID": "logistic.html#likelihood-ratio-test",
    "href": "logistic.html#likelihood-ratio-test",
    "title": "15  GLM VIII - Logistic Regression",
    "section": "\n15.6 Likelihood Ratio Test",
    "text": "15.6 Likelihood Ratio Test\nIn logistic regression, we can also conduct a Likelihood Ratio (LR) test, which is a chi-square test for the difference in log likelihood between two nested models, \\(-2LL_0 - -2LL_1\\). The first model is the restricted model with fewer parameters, and the second is the full model with more parameters. The LR test helps us compare the two models and determine if the additional predictors in the full model significantly improve its fit. The degrees of freedom for the LR test are equal to the difference in the number of parameters between the two models.",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>GLM VIII - Logistic Regression</span>"
    ]
  },
  {
    "objectID": "logistic.html#pseudo-r2",
    "href": "logistic.html#pseudo-r2",
    "title": "15  GLM VIII - Logistic Regression",
    "section": "\n15.7 Pseudo R2",
    "text": "15.7 Pseudo R2\nUnlike linear regression, logistic regression doesn’t have a traditional R-squared to measure explained variance. However, researchers have proposed several Pseudo R2 statistics to approximate the concept of explained variance in logistic regression. These Pseudo R2 statistics rescale the -2 log likelihood of the model. Two common Pseudo R2 statistics are Cox & Snell and Nagelkerke.\nCox & Snell is a generalization of the “normal” R2, which provides the same value for ordinary least squares regression. For logistic regression, however, its value can never reach 1; it will be somewhere between 0 and &lt; 1. Nagelkerke aims to “fix” this property by rescaling Cox & Snell to a range of [0, 1], by dividing it by its maximum possible value. While these statistics can provide a measure of relative model fit and help compare models on the same dataset, they do not represent absolute model fit or effect size.",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>GLM VIII - Logistic Regression</span>"
    ]
  },
  {
    "objectID": "logistic.html#classification-accuracy",
    "href": "logistic.html#classification-accuracy",
    "title": "15  GLM VIII - Logistic Regression",
    "section": "\n15.8 Classification Accuracy",
    "text": "15.8 Classification Accuracy\nOne way to evaluate the model’s predictive performance is by using a classification table. The classification table compares the predicted outcomes with the actual outcomes to determine how well the model predicts true positives and true negatives. The table is constructed by calculating the predicted probability for each individual and then dichotomizing these probabilities using a specific cutoff, typically 0.5. Individuals with predicted probabilities above the cutoff are classified as “1,” and those below as “0.” The observed outcomes are then cross-tabulated against the dichotomized predictions.\nBy examining the classification table, we can assess the accuracy of the model’s predictions and identify areas of improvement. Researchers could choose a different cutoff to optimize the trade-off between false positives and false negatives, depending on the specific goals of the analysis.\nIn summary, evaluating logistic regression models involves assessing model fit through chi-square tests, using Pseudo R2 statistics for relative fit comparison, and examining classification accuracy to understand the model’s predictive performance.",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>GLM VIII - Logistic Regression</span>"
    ]
  },
  {
    "objectID": "logistic.html#probability-odds-and-logits",
    "href": "logistic.html#probability-odds-and-logits",
    "title": "15  GLM VIII - Logistic Regression",
    "section": "\n18.1 Probability, Odds, and Logits",
    "text": "18.1 Probability, Odds, and Logits\nWe will start this session on logistic regression with some theoretical exercises. This way, you will learn how to work with probability, odds, and logits.\nThe given probability is P = 0.36.\nWhat are the corresponding odds? \nPlease find the formula’s below:\n\n\nGoal\nFunction\n\n\n\nProbability -&gt; Odds\n\\(odds = P/(1-P)\\)\n\n\nOdds -&gt; Probability\n\\(P = odds/(1+Odds)\\)\n\n\nOdds -&gt; Logit\n\\(logit = \\ln(odds)\\)\n\n\nLogit -&gt; Odds\n\\(odds = e^{logit}\\)\n\n\n\nAgain, the given probability is P = 0.36.\nWhat is the corresponding logit? \nThe given logit is – 2.7.\nWhat are the corresponding odds? \nAgain, the given logit is – 2.7. \nDiscuss with your group mates when and why we should carry out logistic regression analysis.\n\n\nExplanation\n\nWe carry out logistic regression analysis when we want to carry out regression analysis and we have a dichotomous outcome variable (i.e., a dependent variable with two answer categories). In that case we cannot use linear regression because several of the assumptions of linear regression are violated.\n\nIn a study concerning the smoking behavior amongst adolescents, a logistic regression analysis is conducted to check the effect of the image of smoking (Image) on smoking behavior (Smoking).\nImage: to what degree the young adult thinks smoking is perceived as “cool”. The variable image is measured on a scale from 10 to 30, in which higher scores indicate that smoking is perceived as cooler.\nSmoking: whether or not the adolescent smokes.\n\n0 = the adolescent is a non-smoker\n1 = the adolescent is a smoker\n\nBelow you can find part of the output the researchers retrieved.\n\nFirst, write down the estimated regression model.\n\n\nAnswer\n\n\\(Logit(Smoking = 1) = -5.65 + 0.28*Image\\)\n\nWhat is the probability that an adolescent with a score of 15 on image smokes? \nTake a look at the regression coefficient.\n\nImagine that one’s score on Image will increase from 15 to 16.\nTo what degree will the logit and odds change?\nAnd what can you conclude about the increase in probability?\n\n\nAnswer\n\nThe logit increases with 0.284. So −1.387+0.284=−1.103\nThe odds increase with a factor 1.328. So, the odds become 0.25×1.328=0.332\nBy just looking at the output, it is unclear what exactly will happen with the probability. We DO know that the probability will increase because the logits and the odds increase.\nIf we would calculate the probability by hand, we would see that the probability increases with 0.05.\n\nAs you can see, the logit follows a linear function, the odds follow an exponential function, and probability follows a logistic function (perhaps less clear from the example but see the graphs below for an illustration). It is nice to work with a linear model (i.e., work with the logits), but from an interpretation point of view odds and probabilities are nicer to work with.",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>GLM VIII - Logistic Regression</span>"
    ]
  },
  {
    "objectID": "logistic.html#logistic-regression",
    "href": "logistic.html#logistic-regression",
    "title": "15  GLM VIII - Logistic Regression",
    "section": "\n18.2 Logistic Regression",
    "text": "18.2 Logistic Regression\nToday we will study whether the probability to pass a Statistics course depends on exam fear and the math grade obtained in high school (prior math ability).\nOpen LAS BE LR.sav.\nIn the table below you find the variables included in this fictional data set.\nWe want to study the following research question:\nDoes the probability of passing the statistics exam depend on exam stress and math ability?\nTo answer this question, we first need to dichotomize the dependent variable. This is an unusual step, because dichotomizing variables loses information! Still, for the purpose of the present exercise, we will do so. We will create the new dependent variable Passed (0 = fail, 1 = pass), where a 5.5 or higher counts as a pass. Use the following steps:\nNavigate to Transform → Recode into different variables. Select GradeStats as input variable and use Passed as the name for the new recoded variable. Do not forget to click on CHANGE. Click on Old and new values and specify the recoding in such a way that all grades of 5.5 or higher will get the new value 1 and all grades lower than 5.5 (i.e., all other grades) the value 0. Paste and run the syntax. Go to variable view and specify the value labels.\nObtain the frequency distribution for Passed (via Analyze –&gt; Descriptive Statistics –&gt; Frequencies).\nWhat percentage of students passed? %\nWe will use logistic regression to study the effect of exam stress and math ability on the probability to pass. Take the following steps:\nNavigate to Analyze –&gt; Regression –&gt; Binary logistic regression Select Passed as dependent variable and ExamStress and Math as independent variables (in SPSS called “covariates”). Paste and run the syntax.\nInspect the output corresponding to Block 1. Take a look at the table “Variables in the Equation”.\nWhat would be good description of the effects on the sample level? (i.e., what the effect of ExamStress and Math on the probability to pass looks like).\n\n\nAnswer\n\nTurns out Exam Stress has a negative effect on the probability to pass (controlled for Math grade), and Math a positive effect (controlled for Exam Stress).\n\nWhat is the value of the regression coefficient for the variable Exam Stress? \nGive a detailed interpretation of this number.\n\n\nAnswer\n\nIf we would increase one unit in Exam Stress the logits to pass the exam will decrease with 0.025, while keeping the variable Math constant.\n\nTrue or false: The independent variables Math and Exam Stress together have a significant effect on the probability to pass. \nTRUE\nFALSE\n\n\nExplanation\n\nWhen we inspect the model test, we see that, together, Exam Stress and Math grade have a significant effect on the probability to pass, χ2(2) = 81.043, p &lt; .001.\n\nSecond, carry out the significance tests for the individual predictors as well.\nTrue or false: There is a significant effect of Math on the probability to pass, controlled for Exam stress. \nTRUE\nFALSE\nTrue or false: There is a significant effect of Exam stress on the probability to pass, controlled for Math. \nTRUE\nFALSE\n\n\nExplanation\n\nWhen we inspect the separate regression coefficients together, we see that:\nControlled for Exam stress, Math grade has a significant effect on the probability to pass, χ2(1)=54.500, p&lt;.001. Controlled for Math grade, Exam stress has no significant effect on the probability to pass, χ2(1)=0.040, p=.841.",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>GLM VIII - Logistic Regression</span>"
    ]
  },
  {
    "objectID": "logistic.html#logistic-regression-with-categorical-predictor",
    "href": "logistic.html#logistic-regression-with-categorical-predictor",
    "title": "15  GLM VIII - Logistic Regression",
    "section": "\n18.3 Logistic Regression with Categorical Predictor",
    "text": "18.3 Logistic Regression with Categorical Predictor\nNow, we will carry out a logistic regression analysis to study whether the probability to pass can be predicted from the amount of preparation (Preparation), controlled for prior math ability (Math).\nBut… the variable Preparation is a nominal (categorical) variable. Use dummy coding to include it in the model. The variable Preparation has three categories. Create all three dummy variables!\nTake the following approach to carry out the analysis.\nNavigate to Analyze –&gt; Regression –&gt; Binary Logistic\nSelect Math as covariate.\nSelect the dummies for Preparation as covariates. At this stage, use “only reading the book” as the reference group.\nPaste and run the syntax.\nTake a look at the table Variables in the Equation.\nInspect the estimated regression coefficients. Consider the results on the sample level, ignoring inferential statistics for now.\nWhich group has the highest estimated probability to pass? \nStudent who only read the book.\nStudents who read the book and did the exercises.\nStudents who only did the exercises.\nWhich group has the lowest estimated probability to pass (controlled for math ability)? \nStudents who read the book and did the exercises.\nStudent who only read the book.\nStudents who only did the exercises.\nWrite down the full model equation, filling in the values of coefficients. Then check your answer.\n\n\nAnswer\n\n\\(logit_{passed} = -5.833 + .300*D_{exercises} + .946*D_{both} + .999 * Math\\)\n\nControlled for Math Grade, what is the difference in predicted odds between people who only read the book and people who read the book and made the exercises? \n\n\nExplanation\n\nTake the exponent of the regression coefficient for the dummy for people who read the book and made the exercises (see table).\n\nBy hand, calculate the probability that the third person in the file (respID=3) passes the exam. \nImagine that you do not know whether this person passed the exam or not.\nTrue or false: Based on your answer in the previous step and using a decision threshold of .5, you would predict this student to pass. \nTRUE\nFALSE\nSPSS can easily calculate the probability to pass.\nEither use the visual interface:\nClick on the SAVE button in the menu for logistic regression.\nSelect Probabilities under the header Predicted Values.\nClick on continue.\nOr add this line of code to your model:\n  /SAVE=PRED\nSPSS adds a new variable to the data file, which gives the predicted probability for each person. Check whether you calculated the predicted probability for person 3 correctly.\nImagine that we would have used this model to predict the probability to pass for the students in this sample before they even made the exam. Use a decision threshold of .5 to classify students as those likely to pass vs fail.\nOut of all students that were classified as “pass”, which proportion actually failed? \n\n\nExplanation\n\nOf the 370 students who were predicted to pass, 52 failed the exam (.141). As you can see, the model is not completely flawless in making predictions.\n\nWhat is worse in your opinion? Incorrectly predicting that students will pass (when they end up failing), or incorrectly predicting that students will fail (when they end up passing)? Why?\nIf you chose a different decision criteria to predict passing - say .7, what would happen to the proportion of students that were classified as “pass”, but actually failed? \ngets bigger\ncan’t say\nstays the same\ngets smaller",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>GLM VIII - Logistic Regression</span>"
    ]
  },
  {
    "objectID": "logistic.html#hierarchical-logistic-regression",
    "href": "logistic.html#hierarchical-logistic-regression",
    "title": "15  GLM VIII - Logistic Regression",
    "section": "\n18.4 Hierarchical Logistic Regression",
    "text": "18.4 Hierarchical Logistic Regression\nIn this assignment we will compare the following two models against each other.\n\nModel1: \\(Logit(Pass) = b0+b1∗Math\\)\n\nModel2: \\(Logit(Pass) = b0+b1∗Math+b2∗ExamStress+b3∗Evaluation\\)\n\n\nLater on, we want to carry out a model comparison test to check whether the larger model predicts the probability of passing the exam better than the smaller model.\nWhat would be the regression df for the model comparison test, in which we compare the larger model 2 to the smaller model 1? \nNow we will carry out the model comparison test. Take the following steps.\nNavigate to Analyze -&gt; Regression -&gt; Binary Logistic\nSelect Math as predictor (covariates).\nClick on Next (upper right); we can now indicate which block of predictors we like to add in addition to the variables added in the first model.\nEnter ExamStress and Evaluation as predictors (covariates).\nPaste and run the syntax.\nInspect the output. SPSS organizes the output in three blocks. The results in Block 0 refer to the null model without any predictors. Note that this null model also exists when you use the “Linear Regression” interface, but it’s not featured in the output.\nBlock 1 refers to the results of Model 1 and Block to the results of Model 2.\nTake a look at the results of the model comparison test.\nWhat test statistic is used to compare nested logistic regression models? \nF\nChi squared\nt\nZ\nWhat is the value of the appropriate test statistic for comparing models 1 and 2? \nTrue or false: Adding predictors ExamStress and Evaluation lead to significantly better predictions, compared to a model with only high school math grade as predictor. \nTRUE\nFALSE",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>GLM VIII - Logistic Regression</span>"
    ]
  },
  {
    "objectID": "glm_contrasts.html",
    "href": "glm_contrasts.html",
    "title": "16  GLM: Contrasts",
    "section": "",
    "text": "16.1 Effects Coding\nAnother way to include a categorical predictor is via effects coding. Effects coding compares each group to the grand mean. When we have unequal group sizes, the coding scheme should account for relative group size.",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>GLM: Contrasts</span>"
    ]
  },
  {
    "objectID": "glm_contrasts.html#contrast-coding",
    "href": "glm_contrasts.html#contrast-coding",
    "title": "16  GLM: Contrasts",
    "section": "\n16.2 Contrast Coding",
    "text": "16.2 Contrast Coding\nContrast coding is yet another coding scheme; it compares groups of means. This allows us to test specific hypotheses about differences between groups. Contrast coding is a very advanced technique that requires you to perform some basic matrix algebra in Excel.",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>GLM: Contrasts</span>"
    ]
  },
  {
    "objectID": "glm_contrasts.html#post-hoc-tests",
    "href": "glm_contrasts.html#post-hoc-tests",
    "title": "16  GLM: Contrasts",
    "section": "\n16.3 ‘Post-Hoc’ Tests",
    "text": "16.3 ‘Post-Hoc’ Tests\nThe notion of post-hoc tests is a bit outdated; it essentially refers to making all possible comparisons between group means. The name is based on the fact that such tests are rarely hypothesized beforehand. They can be considered an exploratory procedure to look for differences between groups. Note that performing many tests inflates the risk of drawing false-positive conclusions (Type I error).",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>GLM: Contrasts</span>"
    ]
  },
  {
    "objectID": "glm_contrasts.html#adjusting-for-multiple-comparisons",
    "href": "glm_contrasts.html#adjusting-for-multiple-comparisons",
    "title": "16  GLM: Contrasts",
    "section": "\n16.4 Adjusting for Multiple Comparisons",
    "text": "16.4 Adjusting for Multiple Comparisons\nWhen conducting multiple tests, we face an increased risk of committing Type I errors (false positives). If we perform \\(m\\) tests within one study, the experiment-wise Type I error rate is \\(1- (1-\\alpha)^m\\). To control the experiment-wise Type I error rate, we can apply a Bonferroni correction, which divides the significance level \\(\\alpha\\) by the number of tests \\(m\\). This trades off fewer false positive results for more false negative results.\nPlanning to test specific hypotheses before conducting the study also helps control Type I error.",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>GLM: Contrasts</span>"
    ]
  },
  {
    "objectID": "glm_contrasts.html#group-means",
    "href": "glm_contrasts.html#group-means",
    "title": "16  GLM: Contrasts",
    "section": "\n18.1 Group Means",
    "text": "18.1 Group Means\nIn this tutorial, you will learn to use the general linear model to estimate means and to test the difference between two group means, the difference between individual group means and the overall mean, and between groups of means.\nOpen hiking_long.sav in SPSS.\nThe data file describes the result of a fictitious experiment. A hiking guide has displayed five different types of behavior towards different groups of hikers. The treatment that each person received from the guide is recorded in the variable behavior.\nThe dependent variable of this experiment is feeling. Higher scores on this variable indicate a more positive attitude of a participant towards the guide. In this assignment, we will use ANOVA to determine whether the mean score on the dependent variable differs between the five experimental conditions.\nThe data file contains a third variable named weather which can be either good or bad. For now, we will only look at the results obtained during good weather. Hence, we will use “Select cases” to select only those participants with a value of 1 on the weather variable.\nAdditionally, the data contains a variable named balanced which distinguishes between data resulting from a balanced experiment (with equal sample sizes in all groups), and from an unbalanced experiment (with unequal group sizes). For now, just ignore this variable.\nClick Data &gt; Select Cases and select “If condition is satisfied” and click the “If”-button. Now enter the following condition into the equation box:\nweather = 1\nNow click “Continue” and “Paste” to paste the resulting syntax into the syntax editor. Select Run &gt; All to run it. You should now see in the Data View tab that half of the participants have been crossed out.\nFirst, let’s compute the overall mean of feeling and tabulate the group means.\nWhat is the overall mean of feeling? \nWhat are the group means:\n\nWhat is the mean of the rushing group? \n\nWhat is the mean of the stories group? \n\nWhat is the mean of the insulting group? \n\n\n\n\nAnswer\n\nTo get the mean of feeling, use Analyze -&gt; Descriptive Statistics -&gt; Descriptives.\nTo get the group means, use Analyze -&gt; Compare Means -&gt; Means\nDESCRIPTIVES VARIABLES=feeling \n  /STATISTICS=MEAN STDDEV MIN MAX.\n  \nMEANS TABLES=feeling BY behavior\n  /CELLS=MEAN COUNT STDDEV.\n\nYou have previously learned to include categorical variables in a linear model by using dummy coding. Today, we will build upon this principle of encoding the information from a categorical variable into several numerical variables.\nFirst, recall that a linear model with a five-group nominal predictor can be written as follows:\n\\(\\hat{Y} = b_0 + b_1*D_1 + b_2*D_2 + b_3*D_3 + b_4*D_4\\)\nWhat is \\(b_0\\) in this equation?\n\nThe intercept; it is the mean of the reference category.The average of the group meansThe overall sample mean.The slope of the reference category.\n\nTo estimate the model above using regression, you could code dummy variables as follows:\n\n\nbehavior\nD1\nD2\nD3\nD4\n\n\n\nrushing\n1\n0\n0\n0\n\n\ntelling stories\n0\n1\n0\n0\n\n\ninsulting\n0\n0\n1\n0\n\n\nmaking jokes\n0\n0\n0\n1\n\n\nsinging\n0\n0\n0\n0\n\n\n\nWhat is the reference category in the coding scheme above? \nsinging\nrushing\nnone\njokes\nSpecify the dummies as described in the table, and estimate the model.\n\n\nAnswer\n\nTo get the mean of feeling, use Analyze -&gt; Descriptive Statistics -&gt; Descriptives.\nTo get the group means, use Analyze -&gt; Compare Means -&gt; Means\nRECODE behavior (1=1) (2=0) (3=0) (4=0) (5=0) INTO rushing.\nRECODE behavior (1=0) (2=1) (3=0) (4=0) (5=0) INTO stories.\nRECODE behavior (1=0) (2=0) (3=1) (4=0) (5=0) INTO insulting.\nRECODE behavior (1=0) (2=0) (3=0) (4=1) (5=0) INTO jokes.\nEXECUTE.\n\n  \nREGRESSION\n  /MISSING LISTWISE\n  /STATISTICS COEFF OUTS R ANOVA\n  /CRITERIA=PIN(.05) POUT(.10)\n  /NOORIGIN \n  /DEPENDENT feeling\n  /METHOD=ENTER rushing stories insulting jokes.\n\nWhat’s the value of the intercept? \nIn this analysis, the intercept is the mean value on feeling for the reference category (singing). Verify that this is true by comparing the intercept of this regression to the Means table you made previously.\nWhat is the value of the coefficient for stories? \nHow can we interpret this coefficient?\n\nThe difference between the mean of the singing group and the mean of the stories group.The mean of the stories group.",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>GLM: Contrasts</span>"
    ]
  },
  {
    "objectID": "glm_contrasts.html#more-dummies",
    "href": "glm_contrasts.html#more-dummies",
    "title": "16  GLM: Contrasts",
    "section": "\n18.2 More Dummies",
    "text": "18.2 More Dummies\nAs we’ve previously established, dummy variables allow us to test the significance of mean differences between one reference group and all other groups.\nNow, imagine we expect rushing to have a negative effect on behavior, and we want to know which other behaviors are “better” (i.e., result in a higher score on behavior) than rushing.\nSpecify your hypotheses, then check your answer.\n\n\nAnswer\n\n\\(H_0: \\mu_{rushing} \\leq (\\mu_{stories}, \\mu_{insulting}, \\mu_{joking}, \\mu_{singing})\\)\n\\(H_1: \\mu_{rushing} &lt; (\\mu_{stories}, \\mu_{insulting}, \\mu_{joking}, \\mu_{singing})\\)\n\nUse dummy variables to test this hypothesis. Note: you will need to specify one additional dummy.\n\n\nAnswer\n\nREGRESSION\n  /MISSING LISTWISE\n  /STATISTICS COEFF OUTS R ANOVA\n  /CRITERIA=PIN(.05) POUT(.10)\n  /NOORIGIN \n  /DEPENDENT feeling\n  /METHOD=ENTER stories insulting jokes singing.\n\nWhat is the \\(R^2\\) of this model? \nCompare this to the \\(R^2\\) of your previous model. They should be identical, as should be the overall F-test and p-values. Changing the reference category doesn’t change what information the dummies convey.\nDo we perform one-sided or two sided tests? \none-sided\ntwo-sided\nUse this information to test your hypotheses.\nWhich behaviors are “better” than rushing?\n\njokes and singingno behaviorsall behaviorsstories, jokes, and insulting\n\nYou can use this technique any time you want to test the significance of the difference between one reference group and other groups.\nNote that, in the first assignment, we used a different set of dummy variables than in the second assignment. This means that you can always use different sets of dummy variables when want to compare against multiple reference groups.",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>GLM: Contrasts</span>"
    ]
  },
  {
    "objectID": "glm_contrasts.html#estimating-group-means",
    "href": "glm_contrasts.html#estimating-group-means",
    "title": "16  GLM: Contrasts",
    "section": "\n18.3 Estimating group means",
    "text": "18.3 Estimating group means\nIn the first assignment, we computed the group means. But remember that the ANOVA model allows us to estimate them using the general linear model. In this assignment, we will do so by hand. After the previous assignment, you should have five dummy variables to represent the five groups of behavior.\nUntil now, you’ve always included four dummy variables to represent five categories, as the last category is represented by the intercept.\nHowever, it is also possible to represent five groups as follows:\n\\(\\hat{Y} = b_1*D_1 + b_2*D_2 + b_3*D_3 + b_4*D_4 + b_5*D_5\\)\nWhat is \\(b_5\\) in this equation?\n\nThe mean value of group 5The intercept; it is the mean of the reference category.The slope of the reference category.The overall sample mean.\n\nTo estimate the model above using regression, you could code dummy variables as follows (note that you should already have all these dummies from the previous assignment):\n\n\nbehavior\nD1\nD2\nD3\nD4\nD5\n\n\n\nrushing\n1\n0\n0\n0\n0\n\n\ntelling stories\n0\n1\n0\n0\n0\n\n\ninsulting\n0\n0\n1\n0\n0\n\n\nmaking jokes\n0\n0\n0\n1\n0\n\n\nsinging\n0\n0\n0\n0\n1\n\n\n\nNow, go to Analyze -&gt; Regression -&gt; Linear, and add all five dummies as predictors.\nThen, click the Options button, and notice the option titled “Include Constant in Equation”.\nTurn this option off to remove the intercept from the regression equation, then paste your syntax. Notice a new line that says /ORIGIN instead of /NOORIGIN. This command removes the intercept.\nRun your syntax, and examine the results.\nYou might notice that the \\(R^2\\) and F-test changed. This is because these are computed relative to a null-model with only the intercept - but you told SPSS not to include an intercept, so it can’t compute that null model here. It’s not a big deal. As soon as you estimate models with an intercept again, the \\(R^2\\)s will be identical again, regardless of the dummy coding.\nWhat’s the value of the dummy for singing? \nCompare all coefficients to the table of means from the first assignment. They should all be identical.\nThis is how you estimate means using the linear model!\nNow, what do the t-tests and p-values in the Coefficients table tell us?\n\nWhether the means are significantly different from the reference category.Whether the means are significantly different from each other.Whether the means are significantly different from zero.They are not meaningful.\n\nKeep in mind that you can use the standard errors from the coefficients table to perform t-tests against other values than 0; for example, what would the test statistic be when testing whether the mean of the insulting group is significantly different from 5, so \\(H_0: \\mu_{insulting} = 5\\)? t = \nIs the difference significant? \nYes\nNo\nYou can use regression without an intercept any time you wish to estimate all group means in a single analysis and/or test the group means against specific hypothesized values.",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>GLM: Contrasts</span>"
    ]
  },
  {
    "objectID": "glm_contrasts.html#comparing-to-overall-mean",
    "href": "glm_contrasts.html#comparing-to-overall-mean",
    "title": "16  GLM: Contrasts",
    "section": "\n18.4 Comparing to Overall Mean",
    "text": "18.4 Comparing to Overall Mean\nUntil now, we’ve represented levels of a categorical variable using dummy variables with values 0 or 1.\nIn this assignment, we introduce an alternative coding system: effects coding.\nThe main difference with dummy coding is that the reference category does not receive 0 values on all indicator variables, but instead, receives a negative value. In a balanced design (with equal sizes for each group), this value is -1.\nSo in a balanced design, with equal group sizes, the coding scheme for effects coding is (I now use the letters E1-E4 to clarify that these are not dummies but effect coded indicators):\n\n\nbehavior\nE1\nE2\nE3\nE4\n\n\n\nrushing\n1\n0\n0\n0\n\n\ntelling stories\n0\n1\n0\n0\n\n\ninsulting\n0\n0\n1\n0\n\n\nmaking jokes\n0\n0\n0\n1\n\n\nsinging\n-1\n-1\n-1\n-1\n\n\n\nThe reference category is still “singing”.\nThe resulting model will give us the following information:\n\nThe overall sample mean for feeling\nThe difference between each group mean, except for singing, compared to the overall mean\n\nMost of the time, however, we will not have balanced designs. With this in mind, it is more useful to learn the general way to construct effect coding.\nSpecifically, the weights assigned for the singing category (reference category) differ for each dummy, and are computed as:\n\\(-1 * n_{\\text{this category}} / n_{\\text{reference category}}\\)\nCheck the group sizes in the output from assignment 1.\nWhat is the sample size for the rushing group? \nWhat is the sample size for the reference category? \nWith this in mind, what should the weight be for the singing group, on the dummy that codes for membership of the rushing group? \nComplete the following syntax, then run it:\nRECODE behavior (1=1) (2=0) (3=0) (4=0) (5= …) INTO Erushing. RECODE behavior (1=0) (2=1) (3=0) (4=0) (5=) INTO Estories. RECODE behavior (1=0) (2=0) (3=1) (4=0) (5=) INTO Einsulting. RECODE behavior (1=0) (2=0) (3=0) (4=1) (5=…) INTO Ejokes. EXECUTE.\nNote the correct answer for the effect code for the stories group. Compare the number of people in the stories group and in the reference group. Then recall that I explained that In a balanced design (with equal sizes for each group), this value is -1. You see that this is true now, and why.\nCalculate the effect indicators, then specify a regression model with these four effect indicators. Make sure to include the intercept again!\n\n\nCheck correct syntax\n\n\nRECODE behavior (1=1) (2=0) (3=0) (4=0) (5= -1.18) INTO Erushing.\nRECODE behavior (1=0) (2=1) (3=0) (4=0) (5=-1) INTO Estories.\nRECODE behavior (1=0) (2=0) (3=1) (4=0) (5=-1.18) INTO Einsulting.\nRECODE behavior (1=0) (2=0) (3=0) (4=1) (5=-1.18) INTO Ejokes.\nEXECUTE.\n\n\nREGRESSION\n  /MISSING LISTWISE\n  /STATISTICS COEFF OUTS R ANOVA\n  /CRITERIA=PIN(.05) POUT(.10)\n  /NOORIGIN \n  /DEPENDENT feeling\n  /METHOD=ENTER Erushing Estories Einsulting Ejokes.\n\n\nRun the syntax. What is the F-value of the model? \nVerify that this is the same value you got before in models with an intercept.\nWhat is the value of the intercept? \nVerify that this is identical to the overall mean of the dependent variable.\nWhich group means differ significantly from the overall mean?\n\nno behaviorsinsultingall behaviorsjokes and insulting\n\nUsing the coefficients table, calculate the mean of the jokes group. What value do you get? \nThis should be identical to the mean you observed in the previous assignment (using regression to estimate means), and in the first assignment (just computing the means).",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>GLM: Contrasts</span>"
    ]
  },
  {
    "objectID": "glm_contrasts.html#comparing-groups-of-means",
    "href": "glm_contrasts.html#comparing-groups-of-means",
    "title": "16  GLM: Contrasts",
    "section": "\n18.5 Comparing Groups of Means",
    "text": "18.5 Comparing Groups of Means\nExtending the methods above, it is also possible to compare groups of means. For example, we might wonder whether negative behaviors (rushing and insulting) differ significantly from positive behaviors (stories, jokes, and singing).\nThis approach builds upon the logic of effects coding, where the weights for the reference category were based on the relative sample size of the reference category. This time, however, the weights for the category to be compared to the reference category are also based on a sample size.\nWe are going to perform several steps, as explained in the lecture.\n\n18.5.1 Step 1: Plan Contrasts\nKeep in mind these rules:\n\nThe possible values of each indicator variable must sum to 0.\nEach group must be uniquely identified by a particular combination of the contrast variables.\n\nAssume for a moment that we have equal group sizes and want to compare groups 1 and 2 to groups 3, 4, and 5.\nAppropriate contrasts would then be (I’m using the letter C to indicate that these are not dummies or effect indicators):\n\n\nbehavior\nC1\nC2\nC3\nC4\n\n\n\nrushing\n1\n1\n0\n0\n\n\ninsulting\n1\n-1\n0\n0\n\n\ntelling stories\n-\\(\\frac{2}{3}\\)\n\n0\n2\n0\n\n\nmaking jokes\n-\\(\\frac{2}{3}\\)\n\n0\n-1\n1\n\n\nsinging\n-\\(\\frac{2}{3}\\)\n\n0\n-1\n-1\n\n\n\nNote that:\n\nEach column sums to 0\nEvery level of behavior is uniquely identified by some combination of contrasts\n\nIn this case, we only care about C1; we created C2, C3 and C4 to ensure that every level of behavior is uniquely identified. But what do C2-C4 test?\nC2 compares the two negative behaviors; C3 compares stories against jokes and singing. C4 compares jokes and singing.\n\n18.5.2 Step 2: Account for Group Size\nNow, we have to account for the relative sample sizes of these groups to ensure that we can interpret the coefficients as the difference between the means of those combinations of groups.\nUse the descriptive statistics you previously obtained to weight the contrasts from step 1.\nE.g., contrast C3 below is already completed. Which other contrasts do you still need to change? \nC1\nC1, C2, C4\nnone\nC2 and C4\n\n\nbehavior\nC1\nC2\nC3\nC4\n\n\n\nrushing\n1\n1\n0\n0\n\n\ninsulting\n1\n-1\n0\n0\n\n\ntelling stories\n-\\(\\frac{2}{3}\\)\n\n0\n1\n0\n\n\nmaking jokes\n-\\(\\frac{2}{3}\\)\n\n0\n-13/(11+13)\n1\n\n\nsinging\n-\\(\\frac{2}{3}\\)\n\n0\n-11/(11+13)\n-1\n\n\n\n18.5.3 Step 3: Do Matrix Algebra\nEnter the complete matrix into a spreadsheet program. Add one column before the contrasts with an intercept for each group, equal to \\(1/k\\).\nWhat’s the value of this intercept for this study? \n\nClick an Empty cell\nPaste =MINVERSE(TRANSPOSE(\n\nSelect your contrast matrix\nFinish the formula by typing closing brackets ))\n\n\nThese are the values you will use for your indicators!\nNow, write syntax to create the contrasts using the values you calculated in a spreadsheet. Give these contrasts informative names to help remind yourself of their interpretation. Here is one example; complete the rest yourself:\nRECODE behavior (1=.6) (2=.6) (3=-.4) (4=-.4) (5= -.4) INTO posVneg.\n\n\nAnswer\n\nRECODE behavior (1=.6) (2=.6) (3=-.4) (4=-.4) (5= -.4) INTO posVneg.\nRECODE behavior (1=.5) (2=-.5) (3=0) (4=0) (5= 0) INTO rushVinsult.\nRECODE behavior (1=-.01) (2=-.01) (3=.67) (4=-.33) (5= -.33) INTO storyVjokesing.\nRECODE behavior (1=.02) (2=.02) (3=.02) (4=.48) (5= -.53) INTO ? .\nEXECUTE.\n\nWhat does the final contrast encode? \npositive versus negative\nall levels\njoke versus singing\nstory vs singing",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>GLM: Contrasts</span>"
    ]
  },
  {
    "objectID": "glm_contrasts.html#run-the-analysis",
    "href": "glm_contrasts.html#run-the-analysis",
    "title": "16  GLM: Contrasts",
    "section": "\n18.6 Run the Analysis",
    "text": "18.6 Run the Analysis\nCreate the indicator variables and run the regression analysis.\nWhat is the mean difference in feeling between rushing and insulting behaviors? \nWhich effects are significant? \nall contrasts\npositive V negative behaviors\nstory V jokes, singing\nrushing V insulting",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>GLM: Contrasts</span>"
    ]
  },
  {
    "objectID": "glm_contrasts.html#adjusting-for-multiple-comparisons-1",
    "href": "glm_contrasts.html#adjusting-for-multiple-comparisons-1",
    "title": "16  GLM: Contrasts",
    "section": "\n18.7 Adjusting for Multiple Comparisons",
    "text": "18.7 Adjusting for Multiple Comparisons\nIn these assignments, we have been conducting many tests. You have learned that the significance level \\(\\alpha\\) indicates the probability of drawing a false-positive conclusion (Type I error). However, these probabilities add up for multiple tests! So when you perform many tests, you can be in a situation where you have a very high probability of comitting at least one Type I error.\nWe call the total probability of committing at least one Type I error across multiple tests in the same study the “family-wise” or experiment-wise Type I error. You compute it as:\n\\(P(1+ Type I error) = 1 − (1 − \\alpha)^{\\text{number of tests}}\\)\nSo if we perform 3 comparisons, the probability of committing at least one Type I error is: \nAnd if we perform 10 tests? \nIf this makes you uncomfortable - you’re not alone! People often seek to maintain a low risk of drawing any false-positive conclusions, and we can do so simply by lowering \\(\\alpha\\).\n\n18.7.1 Bonferroni correction\nBonferroni proposed a simple correction of \\(\\alpha = \\alpha_{EW}/m\\), where \\(\\alpha_{EW}\\) is the desired experiment-wise Type I error rate (e.g., .05), and \\(m\\) is the number of tests.\nWhat alpha level would you use per test if you want to achieve an experiment-wise alpha of .05 and conduct 7 tests? \nThe Bonferroni correction is quite conservative; in other words - although Bonferroni helps you avoid false-positive conclusions, it becomes much harder to detect true effects.",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>GLM: Contrasts</span>"
    ]
  },
  {
    "objectID": "glm_contrasts.html#compare-all-groups",
    "href": "glm_contrasts.html#compare-all-groups",
    "title": "16  GLM: Contrasts",
    "section": "\n18.8 Compare All Groups",
    "text": "18.8 Compare All Groups\nThrough the ANOVA interface, you can compare all groups to one another. This is equivalent to repeating a regression analysis multiple times, making each category the reference category in turn.\nGo to Analyze -&gt; Compare Means -&gt; One Way ANOVA. Enter Feeling as dependent variable and behavior as Factor.\nNow, click post-hoc. Note that you can select many different tests. Select LSD; this corresponds to “normal” p-values.\nThe other tests in this menu will either apply a penalty to the p-value, or compute the test statistic in a different way, with the purpose of adjusting for multiple comparisons.\nWe will manually apply the correction for multiple comparisons instead, because the fact that SPSS performs the correction behind the scenes has a high risk of user error.\nAssuming we perform two-sided tests at \\(\\alpha = .05\\), how many significant differences between group means are there? \nNow, apply a Bonferroni correction to the alpha level. How many tests are you performing? \nWhat is the new alpha level? \nHow many comparisons are still significant when using this new alpha level?",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>GLM: Contrasts</span>"
    ]
  },
  {
    "objectID": "factorial.html",
    "href": "factorial.html",
    "title": "17  GLM: Factorial ANOVA",
    "section": "",
    "text": "18 Lecture",
    "crumbs": [
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>GLM: Factorial ANOVA</span>"
    ]
  },
  {
    "objectID": "factorial.html#factorial-anova",
    "href": "factorial.html#factorial-anova",
    "title": "17  GLM: Factorial ANOVA",
    "section": "\n20.1 Factorial ANOVA",
    "text": "20.1 Factorial ANOVA\nConsider the following research situation: A psychologist wants to study if and to what extent different behavior of waiters affect the amount of tip money they get, and whether it matters if the behavior is shown by a waiter or waitress.\nThe researcher distinguishes the following types of behavior: neutral behavior, drawing a smiley on the bill, or making small talk.\nThey ran a fully crossed experiment with 3 (behaviors) x 2 (gender: waiter or waitress) = 6 conditions. For each condition they collected data for 10 customers who were helped by a waiter showing neutral behavior, 10 helped by a waiter drawing a smiley on the bill, and so forth.\nIs the design balanced? \nYes\nNo\nWhat is/are the independent variable(s) in this experiment? \nTip size\nBehavior\nGender\nDraw the conceptual model of the experiment. Then, check your answer.\n\n\nAnswer\n\n\nlibrary(tidySEM)\nlibrary(ggplot2)\nlo &lt;- get_layout(\"\", \"Gender\", \"\",\n                 \"Behavior\", \"\", \"Tip size\", rows = 2)\nedges &lt;- data.frame(from = \"Behavior\", to = \"Tip size\")\np &lt;- prepare_graph(layout = lo, edges= edges)\nplot(p) + geom_segment(aes(x = p$nodes$x[p$nodes$name == \"Gender\"], xend =  p$nodes$x[p$nodes$name == \"Gender\"], y = p$nodes$node_ymin[p$nodes$name == \"Gender\"], yend = p$nodes$y[p$nodes$name == \"Behavior\"]), arrow = arrow(length = unit(0.03, \"npc\"), type = \"closed\"))\n\n\n\n\n\n\n\nAs you can see, the dependent variable is Tip money, and the independent variables are Type of behavior and Gender. More specifically. Gender is the moderator, as is expected to influence the relationship between Behavior and Tip money.\n\nNow, open the dataset WaiterBehavior.sav.\nWe will run the analysis to find out what the results of the experiment are. We can do so with a factorial ANOVA.\nFirst, create all the dummy variables you need, using syntax. Check your answer below.\n\n\nAnswer\n\n\nlibrary(tidySEM)\nlibrary(ggplot2)\nlo &lt;- get_layout(\"\", \"Gender\", \"\",\n                 \"Behavior\", \"\", \"Tip size\", rows = 2)\nedges &lt;- data.frame(from = \"Behavior\", to = \"Tip size\")\np &lt;- prepare_graph(layout = lo, edges= edges)\nplot(p) + geom_segment(aes(x = p$nodes$x[p$nodes$name == \"Gender\"], xend =  p$nodes$x[p$nodes$name == \"Gender\"], y = p$nodes$node_ymin[p$nodes$name == \"Gender\"], yend = p$nodes$y[p$nodes$name == \"Behavior\"]), arrow = arrow(length = unit(0.03, \"npc\"), type = \"closed\"))\n\n\n\n\n\n\n\nAs you can see, the dependent variable is Tip money, and the independent variables are Type of behavior and Gender. More specifically. Gender is the moderator, as is expected to influence the relationship between Behavior and Tip money.",
    "crumbs": [
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>GLM: Factorial ANOVA</span>"
    ]
  },
  {
    "objectID": "factorial.html#regression-with-dummies",
    "href": "factorial.html#regression-with-dummies",
    "title": "17  GLM: Factorial ANOVA",
    "section": "\n20.2 Regression with dummies",
    "text": "20.2 Regression with dummies\nFirst, we analyze these data using regression with dummies.\nYou will need to dummy code both categorical predictors.\nDo this in the familiar way, then check your syntax.\n\n\nAnswer\n\nRECODE behavior (1=1) (2=0) (3=0) INTO talking.\nRECODE behavior (1=0) (2=1) (3=0) INTO smiling.\nRECODE behavior (1=0) (2=0) (3=1) INTO neutral.\n\nRECODE Gender (1=1) (2=0) INTO waitress.\nRECODE Gender (1=0) (2=1) INTO waiter.\nEXECUTE.\n\nEstimate a regression model with a main effect for gender and behavior. Create the syntax, then check your answer below.\n\n\nAnswer\n\nUsing neutral behavior and waiter as reference categories, the code is:\nREGRESSION\n  /MISSING LISTWISE\n  /STATISTICS COEFF OUTS R ANOVA\n  /CRITERIA=PIN(.05) POUT(.10)\n  /NOORIGIN \n  /DEPENDENT Tip\n  /METHOD=ENTER waitress smiling talking.\n\nNow, we want to examine whether there is an interaction between gender and behavior. To do so, we want to specify a “full factorial” model. This simply means that we want to know if there is an interaction effect between the two categorical variables. The way to include an interaction effect is to multiply the predictor. As each predictor is represented by multiple dummies, we have to multiply each dummy for each variable with all dummies from the other variable.\nIn this case, that means multiplying the waiter dummy with the smiling and talking dummies.\nDo this via syntax, then check your work.\n\n\nAnswer\n\nCOMPUTE smilingXwaitress = smiling*waitress.\nCOMPUTE talkingXwaitress = talking*waitress.\nEXECUTE.\n\nConduct a hierarchical regression analysis that includes these new interaction terms.\nWhat proportion of the total variance in Tip money is explained by the full factorial model? \nTrue or false: The full factorial model explains a significant amount of variance. \nTRUE\nFALSE\nIs there a significant interaction effect? \nYes\nNo\nCan’t tell\n\n\n\nExplanation\n\nEven though we see significant interaction terms in the coefficients table, determining whether there is a significant interaction between categorical variables requires more than just “eyeballing” whether those terms are significant or not. You need to perform a nested model test. \n\nBased on the output, complete the following table:\n\n\n\n\n\n\n\nBehavior\nGender\nMean\n\n\n\nNeutral\nWaiter\n4.600\n\n\nNeutral\nWaitress\n\n\n\nSmiley\nWaiter\n5.100\n\n\nSmiley\nWaitress\n7.600\n\n\nSmall talk\nWaiter\n\n\n\nSmall talk\nWaitress\n10.000\n\n\n\nDraw a rough plot of these means on a piece of paper.\nPut the type of behavior on the x-axis and draw separate lines for waiters and waitresses.\nTrue or false: The graph suggests a potential interaction. \nTRUE\nFALSE\nIf so, describe the interaction effect (i.e., what can we say about the effect of behavior on amount of tip money for waiters and waitresses?).\n\n\nAnswer\n\nThe lines are not parallel. Hence, also from the graph we see that there is interaction. The effect of type of behavior on the amount of tip money depends on the gender of the waiter/waitress.\nIt seems that for waiters the tip money does not depend much on the behavior.\nFor waitresses the effect is stronger; neutral behavior produces the least amount of tip money, whereas small talk is most beneficial.\n\nSee if you can answer the following question by yourself:\nTrue or false: The interaction effect is significant. \nTRUE\nFALSE\n\n\nAnswer\n\nTo answer this question, you need to perform a nested model test.\nThe syntax is:\nREGRESSION\n  /MISSING LISTWISE\n  /STATISTICS COEFF OUTS R ANOVA CHANGE\n  /CRITERIA=PIN(.05) POUT(.10)\n  /NOORIGIN \n  /DEPENDENT Tip\n  /METHOD=ENTER smiling talking waitress\n  /METHOD=ENTER smilingXwaitress talkingXwaitress.\nNote two things: we request CHANGE statistics, and we enter all “interaction effects” in a separate step, so we can use the R-squared change test to determine overall significance.\n\nWhat is the value of the test statistic for the significance of the interaction effect? \nReport the effect, then check your answer.\n\n\nAnswer\n\nThere was a significant interaction effect between waiters’ sex and behavior, F(2,54) = 18.315, p &lt; .001.\nThis means that the effect of Type of behavior on Tip money depends on the Gender of the waiter/waitress.\n\nOut of curiosity - how much variance is explained by the main effects only?",
    "crumbs": [
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>GLM: Factorial ANOVA</span>"
    ]
  },
  {
    "objectID": "factorial.html#anova-interface",
    "href": "factorial.html#anova-interface",
    "title": "17  GLM: Factorial ANOVA",
    "section": "\n20.3 ANOVA interface",
    "text": "20.3 ANOVA interface\nSPSS also has a dedicated “ANOVA interface”. It specifies exactly the same model as we have been investigating, but its output is more focused on information that is typically requested when estimating a model with only categorical predictors and (optionally) interactions between them.\nWe will now use the ANOVA interface and pay special attention to output it gives us that is not directly available via the Regression interface.\nYou can either use the graphical user interface, or copy-paste this syntax. Either way, pay particular attention to the following:\n\nUnder Options, ask for Homogeneity tests: /PRINT=HOMOGENEITY\n\nUnder Options, ask for Estimates of effect size: /PRINT=ETASQ\n\nUnder Options, ask for Parameter Estimates: /PRINT=PARAMETER\n\nUnder EM Means (expected marginal means), ask for the means for the interaction, and compare Main effects: /EMMEANS=TABLES(Behavior*Gender) COMPARE(Behavior) ADJ(LSD)\n\n\nUNIANOVA Tip BY Behavior Gender\n  /METHOD=SSTYPE(3)\n  /INTERCEPT=INCLUDE\n  /PLOT=PROFILE(Behavior*Gender)\n  /PRINT=ETASQ HOMOGENEITY DESCRIPTIVE PARAMETER\n  /CRITERIA=ALPHA(.05)\n  /EMMEANS=TABLES(Behavior*Gender) COMPARE(Behavior) ADJ(LSD)\n  /EMMEANS=TABLES(Behavior*Gender) COMPARE(Gender) ADJ(LSD)\n  /DESIGN=Behavior Gender Behavior*Gender.\nCopy and run this syntax.\nNote that the table labelled Parameter Estimates is identical to the Coefficients table from the previous regression analysis.\nAlso note that, for example, the F-value for the explained variance for the interaction between Gender an Behavior is identical to the F-value for the \\(\\Delta R^2\\) test you performed in the previous hierarchical regression analysis.\n\n20.3.1 Homoscedasticity\nRegression models have an assumption of homoscedasticity. If all predictors are categorical, that means that we assume equal variances in all groups.\nThe ANOVA output offers us a Levene’s test for homogeneity of variance. Find it, and answer the following question:\nTrue or false: There is reason to doubt the assumption of homogeneity. \nTRUE\nFALSE\nWhat is the value of the appropriate test statistic? \nTrue or false: As a rule, the assumption of homogeneity is more likely to be violated in a factorial ANOVA with an unbalanced design (as compared to a balanced design). \nTRUE\nFALSE\n\n20.3.2 Effect size\nWe can also calculate effect sizes \\(\\eta^2\\) or partial \\(\\eta^2\\), for the two factors and the interaction effect separately.\nRecall that \\(\\eta^2\\) is just the explained variance, \\(R^2\\). In other words: What proportion of the total sum of squares is explained by the factor of interest?\nWe obtain \\(\\eta^2\\) for Factor A by dividing the sum of squares for factor A, \\(SS_A\\), by the \\(SST\\), which is labeled “Corrected total” in the ANOVA output: \\(\\eta^2 = \\frac{SS_A}{SST}\\)\nWhat is \\(\\eta^2\\) for the interaction effect? \nGo back to your previous nested model test, where you determined whether adding the interaction terms led to a significant improvement in explained variance, \\(\\Delta R^2\\). Verify that this number is identical to the \\(\\eta^2\\) for the interaction! They are the same thing.\nAnother measure of effect size is the partial \\(\\eta^2\\). It tells us what proportion of the variance not explained by other factors is explained by the factor of interest.\nWe obtain \\(\\eta_p^2\\) for Factor A by dividing the sum of squares for factor A, \\(SS_A\\), by \\(SS_A\\) plus the residual sum of squares \\(SSE\\): \\(\\eta_p^2 = \\frac{SS_A}{SS_A+SSE}\\).\nNote that SPSS allows us to request partial \\(\\eta^2\\). We did so by including the line /PRINT=ETASQ in our syntax.\nWhat is the value of partial \\(\\eta^2\\) for the factor Behavior? \n\n20.3.3 Pairwise comparisons\nAnother unique feature of the ANOVA interface is that it gives us all pairwise comparisons when we ask for them using the code /EMMEANS=TABLES(Behavior*Gender) COMPARE(Behavior) ADJ(LSD)\nNote that this line asks for comparisons of the three levels of behavior for each gender separately. You can also ask for comparisons of the two levels of gender for each behavior separately by specifying COMPARE(Gender) instead.\nInspect the table Pairwise Comparisons. The three experimental conditions are compared in a pairwise manner, split over the factor Gender.\nFor which pair of groups do the means differ significantly from one another (at the 5% level)? \nWaiter: Neutral-Smiley\nWaitress: Neutral-Smiley\nWaiter: Neutral-Small talk\nWaiter: Small talk-Smiley\nLook at the note under the table. True or false: the p-values in this table are adjusted for multiple comparisons. \nTRUE\nFALSE\nWhy do we need to apply a correction like the Bonferroni correction?\n\n\nAnswer\n\nWhen doing multiple tests on one sample, like doing these pairwise comparisons, the level of risk of a Type I error increases. To correct for this, we should use an adjusted alpha-level, such as the Bonferroni correction.\nAlthough it is possible to ask for SPSS to adjust the p-values in the table, I have expressly not instructed you to do so. The reason for this is that, strictly speaking, Bonferroni is an adjustment of the significance level \\(\\alpha\\) - not of the p-values. Moreover, sometimes you conduct many more tests in a study aside from the pairwise comparisons performed here. In that case, you might want to include those in your Bonferroni correction too, and SPSS does not know about their existence when it applies a Bonferroni correction to the p-values.\nIn other words: It is better to set the alpha level yourself, and apply it consistently across all tests in a study.\n\n\n20.3.4 Simple Effects test\nThe significant interaction effect tells us that the effect of behavior differs by gender, or conversely, that gender differences vary across the three behavoirs.\nSimple effects analysis allows us to test the significance of these marginal effects.\nSimply put: They give us an overall test of the mean differences across levels of one factor, within each level of a different factor.\nConsult the table Univariate Tests (still for the contrast /EMMEANS=TABLES(Behavior*Gender) COMPARE(Behavior) ADJ(LSD)). This table displays the results of the simple effects tests.\nDoes the Behavior of waiters have an influence on the amount of tip money people give?\nWhat is the appropriate p-value? \nReport the simple effect test for waiters and interpret the finding, then check your answer.\n\n\nAnswer\n\nThere is no significant difference among the three behaviors within waiters. Hence, for waiters we don’t have evidence that the behavior has an effect on average tips received, F(2,52) = 0.591, p = .557.\n\nAgain, consult the table Univariate Tests. This table gives the results of the simple effects tests.\nWhat p-value do we see here? \nTrue or false: the type of behavior of waitresses has an influence on the tip people give. \nTRUE\nFALSE\nDoes it make sense to adjust your behavior as a waiter/waitress if you want to increase your tip?\n\nFor both waiters and waitresses behavior does affect amount of tip money received.For both waiters and waitresses behavior does not affect amount of tip money received.For waiters behavior does affect amount of tip money received, but for waitresses it does not.For waitresses behavior does affect amount of tip money received, but for waiters it does not.\n\nReport your results, then check the answer.\n\n\nAnswer\n\nWe do see a significant effect of behavior on average tip money for waitresses, F(2,52) = 46.385, p &lt; .001. Hence, we have convincing evidence that the type of behavior by waitresses affects the average amount of tips. Results suggest that in order to have high tips, waitresses best can make small talk.",
    "crumbs": [
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>GLM: Factorial ANOVA</span>"
    ]
  },
  {
    "objectID": "factorial.html#optional-do-it-yourself",
    "href": "factorial.html#optional-do-it-yourself",
    "title": "17  GLM: Factorial ANOVA",
    "section": "\n20.4 Optional: do it yourself!",
    "text": "20.4 Optional: do it yourself!\nOpen the datafile hiking.sav. The data file also contains data on weather.\nExamine the effect of weather and behavior and their potential interaction, with feelings as the dependent variable.\nWhat is the explained variance of the main effects and interaction effects together? \nTrue or false: the explained variance of the whole model is significant. \nTRUE\nFALSE\nTrue or false: the interaction effect is significant. \nTRUE\nFALSE\nRequest a plot from SPSS that allows you to describe what the effects look like.\nDescribe the trends in your own words, then check your answer.\n\n\nAnswer\n\nThe lines in the plot are not parallel, also pointing to an interaction effect.\n\nPerform a simple effects analysis of the effect of behavior by weather.\nReport your findings and conclusion, then check your answer.\n\n\nAnswer\n\nWe see a significant effect of behavior when the weather was good, F(4,90) = 3.864, p = .006, while the effect of behavior is not significant when the weather was bad, F(4,90) = 1.320, p = .269.\nResults suggest that when the weather is good, joking and singing significantly improves the participants’ feelings about the guide.\nWhen the weather is bad, the behavior of the guide does not have much influence.",
    "crumbs": [
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>GLM: Factorial ANOVA</span>"
    ]
  },
  {
    "objectID": "ancova.html",
    "href": "ancova.html",
    "title": "18  GLM: ANCOVA",
    "section": "",
    "text": "18.1 Covariates and Their Role\nCovariates are variables that have a relationship with the dependent variable but are not the primary focus of the study. They are often referred to as control variables, as they help control for unwanted variability and improve the precision of the analysis. Examples of common covariates include age, gender, education level, or any other variables that might influence the dependent variable.\nIn terms of causality, it’s crucial to consider the relationships between covariates, predictors, and the outcome variable. Control variables should ideally be confounders – variables that influence both the predictor of interest and the outcome. It’s essential to avoid controlling for colliders, which are variables caused by both the predictor and the outcome. A thorough understanding of causal relationships is crucial for proper interpretation.\nOne reason why researchers use control variables in ANCOVA is because they reduce the residual variance in the outcome variable, which in turn increases the power to detect the effect of the predictor of interest. Another reason to use covariates is when the goal is making causal inferences, especially in quasi-experimental designs. The proper selection of covariates that enable causal inference requires careful consideration and is beyond the scope of this course.",
    "crumbs": [
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>GLM: ANCOVA</span>"
    ]
  },
  {
    "objectID": "ancova.html#good-neutral-and-bad-controls",
    "href": "ancova.html#good-neutral-and-bad-controls",
    "title": "18  GLM: ANCOVA",
    "section": "\n18.2 Good, Neutral, and Bad Controls",
    "text": "18.2 Good, Neutral, and Bad Controls\nCovariates fall into different categories based on their relationship with the predictor of interest and the outcome. An example of a good control is a confounder: a variable that causes both the predictor and the outcome. These need to be controlled to avoid spurious relationships. An example of a neutral control is a covariate that is unrelated to the predictor but can reduce error variance in the outcome, thereby increasing statistical power. Bad controls, on the other hand, can introduce biases, such as collider bias (controlling for an outcome of predictor and outcome), case control bias (controlling for an outcome of the outcome), or overcontrol bias (controlling for a mediator of the effect of the focal predictor on the outcome).\nOne crucial insight is that in randomized controlled experiments, the random assignment of participants to different groups breaks the relationship between confounders and the treatment variable. This makes control variables related to the confounders unnecessary. Controlling for them could even introduce bias into the analysis.",
    "crumbs": [
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>GLM: ANCOVA</span>"
    ]
  },
  {
    "objectID": "ancova.html#calculating-adjusted-means",
    "href": "ancova.html#calculating-adjusted-means",
    "title": "18  GLM: ANCOVA",
    "section": "\n18.3 Calculating Adjusted Means",
    "text": "18.3 Calculating Adjusted Means\nAdjusting for covariates involves calculating adjusted means – the means that groups would have had if they scored equally on the covariate. There are two ways to mathematically calculate the adjusted means. One way is to fill in the regression equation for the desired value of the covariate.\nThe other way is to calculate the adjusted means from the group means:\n\\[\n\\bar{Y}_g^{adj} = \\bar{Y}_g - b(\\bar{X}_g-\\bar{X})\n\\]\nWhere:\n\n\n\\(\\bar{Y}_g^{adj}\\): Adjusted mean of the outcome for group g\n\n\\(\\bar{Y}_g\\): Unadjusted mean of the outcome for group g\n\n\\(b\\): Regression coefficient of the covariate\n\n\\(\\bar{X}_g\\): Group mean of covariate X\n\n\\(\\bar{X}\\): Overall mean of covariate X\n\nIn sum, ANCOVA is a different name for regression with a categorical predictor of interest, and continuous predictor(s) that are included to improve our estimate of the effect of the predictor of interest. ANCOVA can enhance statistical power and help make more accurate (potentiall causal) inferences. However, the careful selection of covariates and an understanding of causal relationships are paramount to its proper implementation and interpretation.",
    "crumbs": [
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>GLM: ANCOVA</span>"
    ]
  },
  {
    "objectID": "ancova.html#bivariate-regression-recap",
    "href": "ancova.html#bivariate-regression-recap",
    "title": "18  GLM: ANCOVA",
    "section": "\n21.1 Bivariate Regression (RECAP)",
    "text": "21.1 Bivariate Regression (RECAP)\nResearchers are interested in the relationship between age and depression.\nThey hypothesized that older people are more vulnerable to depressive thoughts than younger people.\nTo test their research hypothesis, they collected data in a random sample of 164 persons from the general population. Open the dataset HADShealthyGroup.sav.\nRun a linear regression analysis using age as the independent variable and depression as the dependent variable.\nProceed as follows:\nNavigate to Analyze &gt; Regression &gt; Linear\nSelect the correct dependent and independent variable.\nPaste and run the syntax.\nHow much of the total variance in Depression is explained by Age? \nWhat can you say about the effect size? Would you say it’s a lot?\n\n\nAnswer\n\nTo me, 2% of explained variance does not seem like a lot. There are probably better predictors of depression (i.e., predictors that explain more of the variance in depression).\n\nTrue or false: The explained variance is significant at the 10% level. \nTRUE\nFALSE\n\n\nAnswer\n\nTo conclude anything about the significance of the proportion explain variance of this model, we can look at the ANOVA table or ask SPSS to show the R2-change. This shows us that the explained variance in this model is not significant compared to an empty model (i.e. including no predictors), F(1,140) = 2.836, p = .094.\n\nWrite down the estimated regression line using the unstandardized coefficients.\nY’=  +  *Age\nHow can we interpret the constant?\n\nThe predicted level of depression when age would be 0.The average level of depression.The average age in the sample.The predicted level of depression for the average age.\n\nConsult the table with the coefficients again\nTrue or false: We can conclude from this table that the effect of age is significant at the 10% level. \nTRUE\nFALSE\n\n\nAnswer\n\nTo conclude whether the effect of Age on Depression is significant, we look at the t-test for the estimated coefficient.\nWe should conclude that the effect of Age on Depression is significant when using \\(\\alpha\\)=.10, t(140) = 1.684, p = .094.\n\nOne of the assumptions of bivariate regression analysis is that the relationship between the independent and dependent variable is linear.\nState in your own words what this assumption entails.\n\n\nAnswer\n\nThe assumption of a linear relationship entails that the relationship between the variables can be described with a straight line.\n\nHow would you evaluate the assumption of linearity graphically? Do it for the data at hand.\nTrue or false: The relationship is linear. \nTRUE\nFALSE\nIf the assumption is not met, speculate about other possible relationships between age and depression.\n\n\nAnswer\n\nThe scatter plot does not have the shape of a cigar, so it does not unambiguously suggest a linear relationship. Thus, you may doubt whether the relationship between age and depression is best described by a linear model. Perhaps the relationship is quadratic. Especially persons in middle ages may be vulnerable to depressive thoughts. Next to the plot, you find both the estimated linear trend and a non-linear trend. It seems that the quadratic curve fits better with the data. Moreover, the quadratic model explains 6% of the variance, whereas the linear model only 2%.\n\nRun a regression analysis using Age as the independent variable and Anxiety as the dependent variable.\nSummarize the results.\nInclude in your answer the proportion of explained variance (R-square), a description of the effect based on the estimated regression coefficients, and evaluate the significance of the effect of age on anxiety.\n\n\nAnswer\n\nThe proportion explained variance in Anxiety by Age is .071. The explained variance in this model is not significant compared to an empty model (i.e. including no predictors), F(1,140) = 0.710, p = .401.\nThe effect is Age on Anxiety is negative (\\(\\beta\\) = -0.013), meaning that anxiety decreases with age. However, the effect of Age on Anxiety is not significant when using \\(\\alpha\\)=.05, t(140) = -0.842, p = .401.",
    "crumbs": [
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>GLM: ANCOVA</span>"
    ]
  },
  {
    "objectID": "ancova.html#anova-recap",
    "href": "ancova.html#anova-recap",
    "title": "18  GLM: ANCOVA",
    "section": "\n21.2 ANOVA (RECAP)",
    "text": "21.2 ANOVA (RECAP)\nConsider the following hypothetical research situation…\nResearchers are interested in effects of stereotyping on cognitive performance. For their research they performed a quasi-experiment. They selected three schools and asked girls from eight grade to do a math test. However, the teacher in School A says that boys do particularly well on the test (i.e., negative stereotyping for girls). In School B the teachers says that girls do particularly well on the test (i.e., positive stereotyping for girls). In the third school, the teacher gives gender-neutral information (control group).\nAfterwards the researchers compare the average math grades across the three groups. Because the schools may also differ in the student population, researchers also measured scholastic aptitude and use that as a covariate in the analysis.\nOpen the dataset stereotyping.sav.\nIn your own words, explain what a covariate is and give two examples of covariates that should/can be included in neuro-psychological research.\n\n\nAnswer\n\nCovariates are “nuissance” variables that we are not directly interested in, but that allow us to better estimate the effect of another variable of interest.\nThis is related to causal inference.\nWe must thus justify our covariates by reference to their putative causal role with relation to our predictor and outcome.\nA covariate that causes both our predictor and our outcome is a confounder, and should be controlled for. This sometimes happens in “natural experiments”, where the factor is not randomly assigned to participants.\nA covariate that causes our outcome, but is unrelated to our predictor, can be controlled for to reduce error variance in the outcome and increase statistical power of the effect of interest. This typically happens in randomized controlled experiments, but it may also happen in natural experiments.\nAs a counter-example: A variable that is caused by our predictor and our outcome is a collider, and should never be controlled for! This will bias the effect of our predictor.\n\nMention two often-used covariates in research.\n\n\nAnswer\n\nGender and Age are two covariates that are often used in research.\n\nLet’s start analyzing the math scores using an ANOVA, thus ignoring any covariates for now.\n\nCompute the means across the three groups (Analyze à Compare means à Means.\nSelect MATH for the dependent list and STEREO as the independent.\nPaste and run the syntax.\nInspect the table that displays the mean differences between the groups.\n\nWhat is the first impression of stereotyping that we have from the mean differences?\n\n\nAnswer\n\nThe table shows that no stereotyping results in the lowest mean score on the math test. Positive stereotyping results in the highest mean score, and negative stereotyping is in between.\n\nRun an ANOVA: (Analyze -&gt; general linear model -&gt; univariate). Select MATH as the dependent variable and STEREO as fixed factor.\nWrite down the null and alternative hypothesis of the ANOVA, then check your answer.\n\n\nAnswer\n\nH0: \\(\\mu1 = \\mu2 = \\mu3\\) H1: not \\(\\mu1 = \\mu2 = \\mu3\\)\n\nTrue or false: The effect of stereotyping is significant (use \\(\\alpha\\)=0.05). \nTRUE\nFALSE\n\n\nAnswer\n\nYes, the F-test for the effect of Stereotyping on Math performance is significant, F(2,27) = 5.614, p = .009. Hence, we reject H0.\nWe have convincing evidence that, also at the population level, the means differ.\nIn other words, we have convincing evidence that the mean differences in math performance are not the result of sampling fluctuations but reflect true differences due to the manipulation (i.e. stereotyping).\n\nHow large is the R-square? \nHow do you interpretat this value of the R-square?\n\n\nAnswer\n\nThe R2 is 0.294.\nThis means that 29.4% of the variance in Math performance is explained by the Stereotyping.\n\nThe R-square should be equal to:\n\nThe ratio of the mean square for STEREO to the error mean square.The ratio of the sum of squares for STEREO to the error sum of squares.The ratio of the mean square for STEREO to the (corrected) total mean square.The ratio of the sum of squares for STEREO to the (corrected) total sum of squares.\n\nTest whether there is an effect of stereotyping (regardless of whether it is positive or negative stereotyping).\nTrue or false: The effect of stereotyping (regardless of whether it is positive or negative stereotyping) is significant. \nTRUE\nFALSE\nReport Levene’s test, significance of the contrast that you tested, and an interpretation of the difference between the two means.\n\n\nAnswer\n\nThe Levene’s test is not significant (p = .805), so there is no evidence for violation of the assumption of homoscedasticity.\n\nTest the mean math score for each experimental group against the control group; that is, you have to test two planned contrasts.\nAre the means different when tested at an experiment-wise alpha of .05 and using a Bonferroni corrected alpha per test? Substantiate your answer.\n\n\nAnswer\n\nThe contrast is significant at \\(\\alpha\\) = .05.\nThese results suggest that stereotyping (positive/negative) results in better math performance than non-stereotyping.",
    "crumbs": [
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>GLM: ANCOVA</span>"
    ]
  },
  {
    "objectID": "ancova.html#ancova",
    "href": "ancova.html#ancova",
    "title": "18  GLM: ANCOVA",
    "section": "\n21.3 ANCOVA",
    "text": "21.3 ANCOVA\nThe next step is to add scholastic aptitude as a covariate in our analysis.\nIn the lecture, we considered two situations in which ANCOVA is used; one in which the covariate was not related to the grouping variable, and one in which the covariate is associated.\nWhich situation do we have in this study? To answer the question, you need to ask for some additional statistics in SPSS.\n\n\nAnswer\n\nWe can check if the covariate is associated with the experimental factor by inspecting the means of the experimental groups on the covariate, or by running a one-way ANOVA.\nThe covariate is associated with the grouping variable, and thus mean differences in math between the three groups may be confounded by mean differences in scholastic aptitude between the three groups.\n\n\n21.3.1 Assumption or not?\nSome texts state that ANCOVA has an additional assumption, beyond those of multiple regression. This “extra assumption” is the assumption of “homogeneity in regression slopes”.\nThe assumption of homogeneity in regression slopes states that the within-group effect of the covariate is the same across groups. That is, the covariate does not interact with the grouping variable.\nFor example, in this assignment, the assumption would imply that the effect of scholastic aptitude is independent of the experimental condition.\nBut: ANCOVA is just a special name for multiple regression with a categorical predictor of interest and control variables that we’re not interested in (“nuissance variables”). If ANCOVA is multiple regression, then how can it have differen assumptions than multiple regression?\nThe answer is that ANCOVA does not have different assumptions, but if we were to allow for interaction between the factor and covariate, we would simply no longer call the resulting model an ANCOVA.\nSo instead of saying “ANCOVA has an assumption of homogeneity in regression slopes”, we could say: “it is conventional to call a model ANCOVA if it contains a factor and some control variables, but no interaction”. Of course we can add interaction terms in such a model - but then we just call it multiple regression with an interaction, not ANCOVA.\nOmitting an interaction between the factor and the covariate means that we force the within-group effect of the covariate to be the same across levels of the factor. In this study, that means that we do not allow the effect of scholastic aptitude to depend on the experimental condition.\nBefore we carry out the actual ANCOVA, we can check whether this model is correctly specified, or whether we are missing a significant interaction. We can check whether there is a significant interaction effect using the following syntax:\n    UNIANOVA SA BY STEREO WITH MATH\n      /METHOD=SSTYPE(3)\n      /INTERCEPT=INCLUDE\n      /PRINT=DESCRIPTIVE PARAMETER HOMOGENEITY\n      /CRITERIA=ALPHA(.05)\n      /DESIGN=STEREO MATH MATH*STEREO.\nCopy and run the syntax. Go to the table “Tests of Between-Subjects Effects”. Take a look at the row STEREO*MATH.\nTrue or false: There is a significant interaction effect. \nTRUE\nFALSE\nIf there is a significant interaction effect, what do we do?\n\n\nAnswer\n\nRemember we can check for a significant interaction effect for two reasons:\n\nOur hypothesis is about the interaction effect\nAs an assumption check for correct model specification (i.e., we’re interested in main effects, but we want to make sure that we’re not ignoring an interaction when we do). This is similar to checking for linearity.\n\nIn the first case, we should not be conducting ANCOVA at all; we should start with multiple regression with interaction, because the interaction effect is our effect of interest.\nIn the second case, we can do two things: We can change our analysis based on the results of the “assumption check” - but such data-dependent decisions increase the risk of overfitting and Type I errors. Alternatively, we can just report the results of our planned ANCOVA analysis, but mention in the discussion that we observed a significant interaction, which means that the model may have been misspecified. We can also report results from both models, and see if/how the conclusions change if we allow for interaction (this is called a sensitivity analysis).\n\n\n21.3.2 Back to ANCOVA\nLet’s run an ANCOVA, proceed as follows:\n\nNavigate to Analyze &gt; General linear model ? Univariate\nSelect MATH as the dependent variable, STEREO as fixed factor, and SA as the covariate.\nAlso, via OPTIONS ask for the Parameter estimates. Paste and run the syntax.\n\nConsider the Tests of Between Subjects Effects table (henceforth referred to as the “ANCOVA table”) and the FF-test for the grouping factor (STEREO).\nWhat’s the p-value for the overall test of model fit? \nWhat conclusions can be drawn from the F-test?\n\n\nAnswer\n\nThe F-test is a test of the effect of Stereotyping on Math performance controlled for Scholastic aptitude. Conceptually, it tests whether differences in the adjusted means in Math performance are significant. Adjusted means are the means we would expect if the group had an average level of Scholastic aptitude.\nIn other words, it tests the differences in the hypothetical situation we would have had three groups that had exactly the same level of Scholastic aptitude.\nThe F-test is not significant, F(2,26) = 2.333, p = .117, which means that, controlled for Scholastic aptitude, we don’t have convincing evidence that Stereotyping had an effect on Match performance.\n\nCompare the results ANOVA and ANCOVA. What important difference do we see and how would you explain those?\n\n\nAnswer\n\nThe ANOVA suggested a significant effect, whereas once controlled for Scholastic aptitude (ANCOVA) the effect was no longer significant.\nThus, the mean differences between the experimental groups we saw before were indeed confounded with differences in Scholastic aptitude!\n\nConsult the table parameter estimates.\nWhat is the regression slope for scholastic aptitude? \nExplain the meaning of estimated parameter for scholastic aptitude.\n\n\nAnswer\n\nThe parameter estimate for Scholastic aptitude is 0.470. The effect is significant when using \\(\\alpha\\) = .05.\nIt is the pooled within-group regression effect of Scholastic aptitude on Math performance, controlled for Stereotyping.\nThus, if Scholastic aptitude increases by one unit, the predicted Math score increases by .470 units, while controlling for Stereotyping.\n\nBased on the Parameters Estimates and the group-specific means, compute the adjusted group means (for each of the groups!) on MATH for an average scholastic aptitude.\nWhat is the adjusted group mean for the group that received the Negative Stereotype manipulation? \n\\(\\bar{Y}_k^{adj} = \\bar{Y}_k -b_w(\\bar{X}_k- \\bar{X})\\)\nTo use the formula, you need to know the group means on MATH (you computed them before), you have to know the group means and overall mean SA (you can compute them via means), and the regression effect which is given in the table with parameter estimates.\nCheck your adjusted means against this answer model:\n\n\nAnswer\n\n\n\nRerun the ANCOVA. Now via OPTIONS also ask for the estimated means. You do so by selecting stereo in the list of Display Means for (at the top of the menu). Look in the table Estimated Marginal Means and verify your answer to the previous question.\nWrite down in your own words – and as precise as possible – the meaning of adjusted means.\n\n\nAnswer\n\nThe estimated marginal means (i.e., the adjusted means) are the group means if all groups would’ve had an average of 6.20 on the covariate.\n\nFinally, we want to look at several effect size estimates.\nHow much of the variance in Math do SA and STEREO explain? \nControlled for SA, how much of the remaining variance in Math does STEREO explain? Use the formula mentioned in the lecture slides to calculate the partial \\(\\eta^2\\): \nVerify your answer by running the ANCOVA again. Now, in options, select the box Estimates if effect size.\nTrue or false: SPSS reports the same partial η2. \nTRUE\nFALSE\nCould you summarize your findings of the ANCOVA in a few brief sentences?\nMention the significance tests, (un)adjusted means and the effect size estimates.",
    "crumbs": [
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>GLM: ANCOVA</span>"
    ]
  },
  {
    "objectID": "rmanova.html",
    "href": "rmanova.html",
    "title": "19  GLM: Repeated Measures ANOVA",
    "section": "",
    "text": "19.1 Two Repeated Measurements\nThe paired samples t-test is suitable for scenarios where participants are measured before and after an intervention. This technique simply analyzes the difference score between pretest and posttest scores.",
    "crumbs": [
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>GLM: Repeated Measures ANOVA</span>"
    ]
  },
  {
    "objectID": "rmanova.html#more-than-two-measurements",
    "href": "rmanova.html#more-than-two-measurements",
    "title": "19  GLM: Repeated Measures ANOVA",
    "section": "\n19.2 More Than Two Measurements",
    "text": "19.2 More Than Two Measurements\nFor scenarios with more than two repeated measurements, there are two potential solutions: the linear mixed model, and the multivariate approach. The linear mixed model, treats all repeated measurements as a single variable with multiple observations per participant. Thus, if one participant gave four repeated measurements, we would have four rows in the data for that participant. The multivariate approach treats the repeated measurements as correlated outcomes. Each measurement occasion is analyzed while controlling for the other measurement occasions.",
    "crumbs": [
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>GLM: Repeated Measures ANOVA</span>"
    ]
  },
  {
    "objectID": "rmanova.html#sphericity-assumption",
    "href": "rmanova.html#sphericity-assumption",
    "title": "19  GLM: Repeated Measures ANOVA",
    "section": "\n19.3 Sphericity Assumption",
    "text": "19.3 Sphericity Assumption\nThe linear mixed model assumes sphericity, which is analogous to the assumption of homogeneity of error variance. Sphericity implies that the variances of the differences between all combinations of repeated measures are equal.\nIf you do not, or can not, assume sphericity, you can use a corrected test for the linear mixed model, or switch to the multivariate approach.",
    "crumbs": [
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>GLM: Repeated Measures ANOVA</span>"
    ]
  },
  {
    "objectID": "rmanova.html#mixed-designs",
    "href": "rmanova.html#mixed-designs",
    "title": "19  GLM: Repeated Measures ANOVA",
    "section": "\n19.4 Mixed Designs",
    "text": "19.4 Mixed Designs\nA mixed design involves both within-participants and between-participants factors. This factorial design allows researchers to examine interactions between these factors, such as the interplay between time and exposure conditions. Post hoc analyses can be used to understand the direction and significance of these interactions.",
    "crumbs": [
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>GLM: Repeated Measures ANOVA</span>"
    ]
  },
  {
    "objectID": "rmanova.html#repeated-measures-anova",
    "href": "rmanova.html#repeated-measures-anova",
    "title": "19  GLM: Repeated Measures ANOVA",
    "section": "\n22.1 Repeated Measures ANOVA",
    "text": "22.1 Repeated Measures ANOVA\nIn this tutorial, we will explore how to perform a repeated-measures ANOVA using SPSS to assess the effect of repeated measurements of depression symptoms in a sample of military veterans. The primary objective is to determine whether there are significant changes in depression symptom scores across multiple time points.\nLoad the dataset called depression.sav containing depression symptom scores at different time points for each participant.\n\nClick on “Analyze” in the top menu and select “General Linear Model” and then “Repeated Measures.”\n\n\n22.1.1 Defining the Within-Subjects Factor\n\nIn the “Repeated Measures” dialog box, name your within-subjects factor as “time.”\nSpecify the number of levels as 4 (since there are four repeated measurements).\nClick the “Add” button.\n\n22.1.2 Defining Within-Subjects Variables\n\nClick on the “Define” button to configure within-subjects variables.\nIn the “Repeated Measures” dialog box, move the variables corresponding to each time point (e.g., scl1, scl2, scl3, scl4) to the “Within-Subjects Variables” box while maintaining their correct order.\n\nConfiguring Options\n\nClick the “Options” button.\nCheck the boxes for “Descriptive statistics” and “Estimate of effect size.”\nClick “Continue.”\n\nRunning the Test\n\nClick “OK” to run the repeated-measures ANOVA.\nThe result will appear in the Output Viewer.\n\nInterpreting the Result\nDescriptive Statistics\nThe descriptive statistics provide insight into the direction of any potential effect. The means comparison shows the average depression symptom scores at different time points.\nTrue or false: There is an increase in symptoms over time. \nTRUE\nFALSE\nAssumption of Sphericity\nSPSS tests assumption of sphericity using Mauchly’s test of sphericity.\nTrue or false: In this analysis, the assumption of sphericity is met. \nTRUE\nFALSE\nTrue or false: According to the Huyn-Feldt estimate of epsilon, the deviation from sphericity is small. \nTRUE\nFALSE\nLet’s assume sphericity for now. Choose the appropriate test and correction based on this assumption.\nWhat is the appropriate F-value for the chosen test? \nWhat is the appropriate df for the chosen test?",
    "crumbs": [
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>GLM: Repeated Measures ANOVA</span>"
    ]
  },
  {
    "objectID": "rmanova.html#pairwise-comparisons",
    "href": "rmanova.html#pairwise-comparisons",
    "title": "19  GLM: Repeated Measures ANOVA",
    "section": "\n22.2 Pairwise Comparisons",
    "text": "22.2 Pairwise Comparisons\nExamine the table of pairwise comparisons.\nWhich difference is smallest? \nT1 v T2\nT3 v T4\nT2 v T3\nT2 v T4\nIf you were to use Bonferroni correction to control for multiple comparisons, you would divide the experiment-wise alpha level by the number of comparisons. How many comparisons are you making here? \nReport your results. Make sure to reference both the RM-ANOVA test, and post hoc comparisons with Bonferroni correction. Then, check your answer.\n\n\nAnswer\n\n“A repeated-measures ANOVA revealed a significant effect of time on depression symptom scores, F(3, 2931) = 7.29, p &lt; .001. For post hoc pairwise comparisons, we applied a Bonferroni correction. Since there are 6 comparisons between 4 time points, we established the alpha level as .05/6 = .008. Using this alpha level, we found that the mean depression symptom score increased significantly from T1 to T3 (Mean difference = .29, p = .003), and from T1 to T4 (Mean difference = .41, p &lt; .001). These results suggest that depression symptoms increased significantly over time for the military veteran sample.”",
    "crumbs": [
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>GLM: Repeated Measures ANOVA</span>"
    ]
  },
  {
    "objectID": "reliability_validity.html",
    "href": "reliability_validity.html",
    "title": "20  Reliability and Validity",
    "section": "",
    "text": "20.1 Classical Test Theory\nClassical Test Theory posits that observed test scores are a function of the true score on the latent construct, plus measurement error. Different sources of measurement error can influence observed scores, including instrument properties and individual factors.",
    "crumbs": [
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Reliability and Validity</span>"
    ]
  },
  {
    "objectID": "reliability_validity.html#reliability",
    "href": "reliability_validity.html#reliability",
    "title": "20  Reliability and Validity",
    "section": "\n20.2 Reliability",
    "text": "20.2 Reliability\nReliability refers to the consistency or stability of test scores over time or across different measurement occasions. It is related to the proportion of true score variance to total score variance. Reliability can be estimated using methods such as test-retest reliability (consistency across repeated measurements), internal consistency (consistency across items within a test), and inter-rater reliability (consistency across different raters).\n\n20.2.1 Test-Retest Reliability\nTest-retest reliability involves administering the same test to the same participants on two separate occasions and calculating the correlation between their scores. Test-retest reliability is suitable for stable traits and can provide insight into the stability of a construct over time. However, learning effects, memory effects, and change over time need to be considered when determining the appropriate interval between test administrations.\n\n20.2.2 Internal Consistency\nInternal consistency measures the association among items within a test. It can be estimated using methods such as split halves or Cronbach’s alpha. Split halves involve dividing the test into two halves and correlating the scores between them. Cronbach’s alpha is a measure of internal consistency that indicates how closely related items are to each other within a scale. It is affected by the number of items, their average covariance, and their average variance. Note that this means you can artificially inflate Cronbach’s alpha by using very similar items, or using very many items.\nWhen diagnosing the internal consisteny of a scale, we can compute item-total correlations to examine the correlation between individual items and the total scale score (minus that item). Low item-total correlations may indicate problematic items, and Cronbach’s alpha can be recalculated with items removed to assess their impact on reliability.",
    "crumbs": [
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Reliability and Validity</span>"
    ]
  },
  {
    "objectID": "reliability_validity.html#validity",
    "href": "reliability_validity.html#validity",
    "title": "20  Reliability and Validity",
    "section": "\n20.3 Validity",
    "text": "20.3 Validity\nValidity refers to the extent to which an instrument measures what it is intended to measure. There are several types of validity, including face validity (whether the items appear relevant to the construct), content validity (whether the instrument adequately covers all aspects of the construct), and criterion validity (whether the instrument is associated with relevant outcomes or indicators of the construct).\n\n20.3.1 Face Validity\nFace validity assesses whether items in an instrument are clearly related to the construct of interest. It considers the clarity, readability, and unambiguity of wording and answer options. Face validity is subjective and relies on a first-glance assessment of whether the items seem relevant to the construct being measured.\n\n20.3.2 Content Validity\nContent validity is usually determined by involving experts in the field, and having them define the construct’s scope, generating items for subdomains of the construct, and rating the relevance of items. An instrument has content validity if it adequately covers all aspects of the construct. Content validity is essential for ensuring that the instrument comprehensively captures the intended construct.\n\n20.3.3 Criterion Validity\nCriterion validity assesses whether an instrument is associated with outcomes or indicators of the construct it is designed to measure. This can involve correlations between the instrument and external measures (e.g., other validated scales) or predictions of behavior related to the construct. Criterion validity provides evidence that the instrument measures what it is intended to measure.\nIn sum, effective measurement instruments in the social sciences must have both high reliability and high validity. Reliability ensures that the instrument consistently measures the same construct with low measurement error, and validity ensures that the instrument accurately measures the intended construct (not something else). By considering these principles, researchers can enhance the quality and meaningfulness of their questionnaire-based measurements.",
    "crumbs": [
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Reliability and Validity</span>"
    ]
  },
  {
    "objectID": "reliability_validity.html#norm-violating-behaviors",
    "href": "reliability_validity.html#norm-violating-behaviors",
    "title": "20  Reliability and Validity",
    "section": "\n23.1 Norm Violating Behaviors",
    "text": "23.1 Norm Violating Behaviors\nIn this assignment we are going to take a look at scale that measures whether people engage in norm violating behaviors.\nThe scale consists of the following items:\n\nJoyriding\nTaking soft drugs\nAccepting a bribe\nThrowing away litter\nDriving under influence of alcohol\nSmoking in public places\nSpeeding over limit\nEuthanasia\n\nOpen the datafile evs.sav.\nIn SPSS, navigate to Analyze –&gt; Scale –&gt; Reliability Analysis.\nSelect the seven items that are in this scale.\nThen go to statistics and select the options “Item”, “Scale” and “Scale if item deleted”. Click on continue.\nNow paste and run the syntax.\nWhat is the value of Cronbach’s Alpha? \nFinish the following sentence.\nThis Cronbach’s Alpha is \nGood\nQuestionable\nAdequate\nPoor\nCronbach’s Alpha is an estimate of the scale reliability.\nDescribe in your own words what scale reliability entails.\n\n\nAnswer\n\nThe reliability of a scale shows the internal consistency of the answers on all items on a scale.\n\nLook at the “Item-Total Statistics” table.\nWhat does the last column “Cronbach’s alpha if Item Deleted” tell you?\n\n\nAnswer\n\nThe values in the column “Cronbach’s Alpha if item deleted” shows the Cronbach’s Alpha of the scale if one of the items would be deleted. In other words, it shows what the impact on the reliability of the scale would be if a certain item would be excluded from the scale.\n\nIf you would were examining the psychometric properties of this scale, which items would you consider to give cause for concern?\n\n\nAnswer\n\nWe look at the Cronbach’s Alpha if item deleted to see the internal consistency of a scale without that item.\nGiven the Cronbach’s Alpha of our original scale (.693), the table shows the only deleting the item “Euthenasia” would result in a higher Cronbach’s Alpha.\nWe might thus question whether this item belongs in the scale or not.",
    "crumbs": [
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Reliability and Validity</span>"
    ]
  },
  {
    "objectID": "reliability_validity.html#machiavellianism",
    "href": "reliability_validity.html#machiavellianism",
    "title": "20  Reliability and Validity",
    "section": "\n23.2 Machiavellianism",
    "text": "23.2 Machiavellianism\nIn this assignment we will look into the latent concept Machiavellianism.\nThe personality trait of Machiavellianism is part of what’s called the “dark triad”, a personality type that is characterized by deceitfulness, cynicism, and an absence of morality and empathy.\nOpen the datafile shortmach2.sav Download shortmach2.sav. The data file contains data on Machiavellianism and some other variables.\nThe included Machiavellianism scale consists of the following 20 items. These items are scored on a 1-5 Likert scale ranging from “Disagree” to “Agree”.\nQ1. Never tell anyone the real reason you did something unless it is useful to do so.\nQ2. The best way to handle people is to tell them what they want to hear.\nQ3. One should take action only when sure it is morally right.\nQ4. Most people are basically good and kind.\nQ5. It is safest to assume that all people have a vicious streak, and it will come out when they are given a chance.\nQ6. Honesty is the best policy in all cases.\nQ7. There is no excuse for lying to someone else.\nQ8. Generally speaking, people won’t work hard unless they’re forced to do so.\nQ9. All in all, it is better to be humble and honest than to be important and dishonest.\nQ10. When you ask someone to do something for you, it is best to give the real reasons for wanting it rather than giving reasons which carry more weight.\nQ11. Most people who get ahead in the world lead clean, moral lives.\nQ12. Anyone who completely trusts anyone else is asking for trouble.\nQ13. The biggest difference between most criminals and other people is that the criminals are stupid enough to get caught.\nQ14. Most people are brave.\nQ15. It is wise to flatter important people.\nQ16. It is possible to be good in all respects.\nQ17. P.T. Barnum was wrong when he said that there’s a sucker born every minute.\nQ18. It is hard to get ahead without cutting corners here and there.\nQ19. People suffering from incurable diseases should have the choice of being put painlessly to death.\nQ20. Most people forget more easily the death of their parents than the loss of their property.\nItems can be indicative or contra-indicative of a certain trait.\nWhich items are contra-indicative to the trait Machiavellianism?\n\n\nAnswer\n\nIn this assignment, the following questions are contra-indicative: Q3, Q4, Q6, Q7, Q9, Q10, Q11, Q14, Q16, and Q17.\nIf an item is contra indicative, low scores on these items indicate a lot of Machiavellianist traits, whereas high scores indicate not so much of an endorsement of Machiavellianist traits in one’s personality.\n\nWe need to recode contraindicative items before we carry out reliability analysis.\nHowever, just to see what happens, let’s first carry out a reliability analysis with all original (i.e. not recoded) variables.\nTake the following steps:\nAnalyze –&gt; Scale –&gt; Reliability Analysis\nSelect the 20 items (Q1A - Q20A)\nClick on Statistics\nUnder Descriptives, select Items, Scale, and Scale if item deleted\nUnder Inter-Item, select Correlations\nPaste and run the syntax\nWhat is the estimated reliability? \nTrue or false: This scale can be considered reliable. \nTRUE\nFALSE\nThis low reliability might be a result of the fact that we have not recoded our contra-indicative items yet. We can also see this in the inter-item correlation table; many of the items are negatively correlated! Let’s rectify this.\nWe have to recode all contraindicative items. Use syntax to do so, and check your answer below.\n\n\nAnswer\n\nCOMPUTE Q3r = 6-Q3A.\nEXECUTE.\n\nFor the second person in the dataset, the original score on Q4A was  and the score on the recoded variable Q4r was .\nBased on this comparison, do you think you successfully recoded the variable?\nWe will now run the reliability analysis including the recoded items. Chnge your syntax, or re-run the analysis via the visual interface.\nWhat is the value of Cronbach’s Alpha? \nThis Cronbach’s Alpha is \nPoor\nGood\nQuestionable\nAdequate\nCheck the corrected item total correlations.\nWhich of these items has the smallest association with other items in the scale? (Type its name) \nExplain why you think it makes sense (or not) that this item is correlated the least with the rest of the scale.\n\n\nAnswer\n\nThis item-total correlation of Q19 is .255.\nItem Q19 reads: “People suffering from incurable diseases should have the choice of being put painlessly to death”.\nOne could argue that a high score on this item should relate to a low score on the scale for agreeing with this item nowadays might actually show empathy with those suffering.\n\nInspect Cronbach’s alpha if item deleted. If you had to remove one item based on this Cronbach’s alpha if item deleted, which item would it be? (Type its original name) \n\n\nExplanation\n\nBased on the Cronbach’s Alpha if item deleted, we would delete the item that would result in the greatest increase in Cronbach’s Alpha if it would be deleted.\nWe find the highest Cronbach’s Alpha if item deleted for the item Q17r (.889).\nTherefore, based on the Cronbach’s Alpha if item deleted, we would delete item Q17r.\n\nTaking everything into consideration, would you remove any items from the Machiavellianism scale?\n\n\nExplanation\n\nTaking the statistical output into consideration, we might want to consider removing item Q17r or item Q19.\nWe do so for two reasons:\n\nThey both correlate less than .3 with the other items on the scale, and\nhave a Cronbach’s Alpha if item deleted higher than .887 (the current Cronbach’s Alpha of the scale).\n\nPlease note that we should always take into consideration theoretical reasons as well when deciding to delete an item from a scale. In this assignment, however, we base our conclusions on statistical reasons only.\nYou might want to consider removing item Q17 or Q19. They both correlate less than .3 with the rest of the scale, and have an Alpha if item removed higher than .887.\n\nWe always remove items one by one. We start with the worst item. After removing a bad item from a scale, the item-statistics will change a little. It might be that the item-statistics improve, and that there is no need to remove the second item.\nHowever, since the differences are not that big and the scale reliability is pretty high, we will keep both items in our scale for the remainder of this assignment.\nOnce we finished reliability analysis, we can use the scale in other analyses.\nIn order to do that, we need to arrive at a total scale score. So, we need one score for each person in the dataset that tells what their score is on the personality trait Machiavellianism.\nThere are several methods of obtaining such a total score, but one straightforward and easy way is to calculate the sum score.\nNavigate to Transform -&gt; Compute Variable.\nGive a new name to the sum score in the box Target Variable, such as Mach.\nIn the box Numeric Expression, enter all variables and add together (i.e., Q1A + Q2A + Q3r …. + Q20A). Ensure that you use the recoded variables for the contra-indicative items!\nPaste and run the syntax.\nWe will now use our newly developed scale in a regression analysis! In this analysis we will try to explain Machiavellianism based on the variables Gender (0=men; 1=women), Age and Voted (0=Voted in past election, 1= Not voted in past election).\nNavigate to Analyze –&gt; Regression –&gt; Linear\nEnter the sumscore Mach as dependent variable\nEnter Gender, Age, and Voted as independent variables\nPaste and run the syntax\nInspect the Model Summary table. How much of the variance in Machiavellianism do the variables Gender, Age and Voted explain? \nTrue or false: Gender, Age and Voting together explain a significant amount of variance in the variable Machiavellianism. \nTRUE\nFALSE\nInspect the table Coefficients and take a look at the partial effects. Which of the variables does not have a significant partial effect on Machiavellianism? \nGender\nAge\nVoting\nControlled for Age and Voting, which group (men or women) scores higher on the Machiavellianism scale? \nMen\nWomen\n\n\nExplanation\n\nGiven that in the variable Gender men are coded as 0 and women are coded as 1, and that the regressions coefficient for Gender is negative (-7.440), we should conclude that men score higher on Machiavellianism than women, controlled for Age and Voting.\n\nFinish the following sentence.\nControlled for Gender and Voting, if we would increase one year in age, the predicted score on the Machiavellianism scale would \nDecrease with 0.243 units.\nDecrease with 0.294 units.\nIncrease with 0.243 units.\nIncrease with 0.294 units.",
    "crumbs": [
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Reliability and Validity</span>"
    ]
  },
  {
    "objectID": "reliability_validity.html#solidarity",
    "href": "reliability_validity.html#solidarity",
    "title": "20  Reliability and Validity",
    "section": "\n23.3 Solidarity",
    "text": "23.3 Solidarity\nIn this assignment, you will evaluate the reliability of a scale measuring solidarity.\nDownload and open the following data file: solidarity.sav.\nYou’ve practiced with reliability analysis in the previous assignments. Now you can use that knowledge to evaluate the reliability of the solidarity scale more independently.\nInclude all eleven items that are part of the scale (v266 to v276).\nInspect the output of the reliability analysis.\nTrue or false: You have to recode questions. \nTRUE\nFALSE\n\n\nExplanation\n\nWe check if we should recode any items by looking at how they are phrased. To do so, we don’t necessarily need to look at the output.\nWe could, however, also use the inter-item correlations displayed in the output to check if we should recode items. If any of the inter-item correlations are negative, this should be in indication for contra-indicative items.\n\nWhat is the reliability of the scale? \nIf you had to remove one item from the scale based on Cronbach’s Alpha if item deleted, which one would you pick? Type the name: \nCan you think of other reasons for removing this item?\n\n\nExplanation\n\nComparing the content of item Q80E to the content of the other questions in the scale, we can conclude that the content of this item is off-topic. This is a theoretical reason for excluding item Q80E from the scale.\n\nWhich item is most typical for the scale? Type its name: \n\n\nExplanation\n\nWe can tell from the higher item-total correlation, that tells us that this item has the strongest correlation with all other variables on the scale.\nAlso, the reliability of the scale would decrease most if this item would be deleted from the scale.\n\nLast, construct sum scores on the scale for all individuals (via Transform -&gt; Compute). Make sure you do not include the one item we discussed previously!\nOnce you created the sum score, have SPSS show the mean for this total score.\nWhat is the mean value of the sum score?",
    "crumbs": [
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Reliability and Validity</span>"
    ]
  },
  {
    "objectID": "data_reduction.html",
    "href": "data_reduction.html",
    "title": "21  Dimension Reduction",
    "section": "",
    "text": "21.1 Principal Components Analysis (PCA)\nPCA is a data rotation technique designed to transform original items into uncorrelated components. These components represent linear combinations of the original items. The primary goal of PCA is dimension reduction, where a small number of components are used to explain most of the variance in the items. This allows us to represent the variance in the items more efficiently. For instance, if ten items measure extraversion, and one component explains most of the variance, we can retain that one component and discard the remaining nine.",
    "crumbs": [
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Dimension Reduction</span>"
    ]
  },
  {
    "objectID": "data_reduction.html#exploratory-factor-analysis-efa",
    "href": "data_reduction.html#exploratory-factor-analysis-efa",
    "title": "21  Dimension Reduction",
    "section": "\n21.2 Exploratory Factor Analysis (EFA)",
    "text": "21.2 Exploratory Factor Analysis (EFA)\nUnlike PCA, EFA is a latent variable method that assumes that latent variables (factors) cause people’s responses to the items. For example, extraversion may cause individuals to respond positively to questions about partying and socializing. EFA models the item covariance matrix as a function of a fixed number of factors. It is called “exploratory” because all items are allowed to load on (contribute to) all factors, without a predefined structure. In practice, well-constructed questionnaires will exhibit high loadings of items on one factor and low loadings on others.",
    "crumbs": [
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Dimension Reduction</span>"
    ]
  },
  {
    "objectID": "data_reduction.html#confirmatory-factor-analysis-cfa",
    "href": "data_reduction.html#confirmatory-factor-analysis-cfa",
    "title": "21  Dimension Reduction",
    "section": "\n21.3 Confirmatory Factor Analysis (CFA)",
    "text": "21.3 Confirmatory Factor Analysis (CFA)\nConfirmatory Factor Analysis (CFA) tests a theory about the specific associations between latent variables and observed indicators. Unlike Principal Components Analysis (PCA) and Exploratory Factor Analysis (EFA), which are exploratory, CFA is a confirmatory approach that tests how well a hypothesized measurement model fits the data. In CFA, researchers specify a theoretical model that defines the relationships between observed variables and latent constructs (factors). These latent constructs are not directly measured but are assumed to explain the correlations among the observed variables. The primary goal of CFA is to evaluate whether the data support the hypothesized model. By doing so, researchers can determine if their theoretical model fits the observed data well, providing evidence for the validity of the underlying construct and the measurement instrument. CFA is part of a family of statistical modeling techniques known as “Structural Equation Modeling” (SEM).",
    "crumbs": [
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Dimension Reduction</span>"
    ]
  },
  {
    "objectID": "data_reduction.html#comparing-method",
    "href": "data_reduction.html#comparing-method",
    "title": "21  Dimension Reduction",
    "section": "\n21.4 Comparing Method",
    "text": "21.4 Comparing Method\nPurpose:\n\nPCA: Dimensionality reduction.\nEFA: Exploration of relationships among items and identification of latent constructs.\nCFA: Testing a predefined theory about which items relate to specific latent constructs.\n\nAssumption:\n\nPCA: Does not assume latent variables; dropping components assumes they are irrelevant or represent error variance.\nEFA: Assumes all items are caused by a smaller number of latent variables (factors).\nCFA: Assumes specific items are caused by specific latent variables.\n\nInterpretation:\n\nPCA: Components are mathematical constructs with no further meaning.\nEFA: Factors represent theoretical latent constructs.\nCFA: Factors represent known theoretical latent constructs.",
    "crumbs": [
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Dimension Reduction</span>"
    ]
  },
  {
    "objectID": "data_reduction.html#principal-components-analysis",
    "href": "data_reduction.html#principal-components-analysis",
    "title": "21  Dimension Reduction",
    "section": "\n21.5 Principal Components Analysis",
    "text": "21.5 Principal Components Analysis\nPCA is a data rotation technique that aligns the largest amount of variance with the first component, the second-largest variance with the second component, and so on. These components are uncorrelated by definition, and they serve as linear combinations of the original items. The primary use of PCA is dimension reduction by retaining only components that explain a significant amount of variance, thus providing a lower-dimensional representation of the data.\nWe can understand PCA in different ways. Firstly, as rotation of the data. PCA rotates the data so that the first component best reproduces the correlation matrix, and each subsequent component improves the reproduction. Secondly, we can understand PCA as a way to summarize k items using fewer than k components, without significant information loss (lossy compression of data).\nSelecting the Number of Components:\nVarious strategies exist to determine the number of components to retain, including Kaiser’s criterion (Eigenvalue &gt; 1), Cattell’s scree plot (inflection point), and Horn’s Parallel Analysis (comparison with random data’s Eigenvalues). Additionally, theoretical knowledge about the underlying data can guide the choice of components.\nInterpreting PCA Loadings:\nInterpreting PCA loadings can be challenging, especially in cases where multiple components are correlated. Orthogonal rotation, such as Varimax, can be employed to simplify the pattern of loadings and improve interpretability. However, it is essential to remember that rotated loadings should not be directly interpreted as correlations between items and factors as in PCA.",
    "crumbs": [
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Dimension Reduction</span>"
    ]
  },
  {
    "objectID": "data_reduction.html#exploratory-factor-analysis",
    "href": "data_reduction.html#exploratory-factor-analysis",
    "title": "21  Dimension Reduction",
    "section": "\n21.6 Exploratory Factor Analysis",
    "text": "21.6 Exploratory Factor Analysis\nEFA is a model-based approach that assumes the existence of latent variables that cause item responses. It is suitable when you expect clusters of items to be correlated (multicollinear) and seeks to explain correlations between items. EFA assumes that unexplained variance in the items can be attributed to measurement error. This aligns with test theory, where it is assumed that observed items measure latent constructs with error. EFA is particularly suitable when there is a theoretical basis for assuming the existence of latent variables, such as when developing a new questionnaire that has not been validated yet. However, if a theoretical model already exists, Confirmatory Factor Analysis (CFA) may be more appropriate.\nTo conduct EFA, we estimate the unknown factor loadings. Two common estimation methods are Principal Axis Factoring (PAF) and Maximum Likelihood (ML). PAF is a default method in SPSS and is based on an iterative procedure involving matrix algebra. It provides a solution even when the model is complex or the data are non-normal. On the other hand, ML is the same estimator used for CFA and works well when the data are multivariate normal. However, ML may not perform well when the model is overly complex (which is not necessarily a bad thing). ML estimation also allows for a test of model fit, which is useful for evaluating the appropriateness of the chosen model.\nFactor loadings represent the correlations between each item and the extracted factors. They indicate the strength and direction of the relationship between the observed item and the underlying factor. Factor loadings range from -1 to +1, with values closer to 1 indicating a stronger relationship. In our example, we can see the factor loadings in a factor matrix, where each row corresponds to an item and each column corresponds to a factor. The factor loadings help us identify which items load more strongly on specific factors.\nWe can compute Eigenvalues in EFA just as in PCA by taking the column sums of the squared loadings and indicate the amount of variance explained by each factor. Eigenvalues are always smaller than the initial eigenvalues obtained in Principal Component Analysis (PCA) because some variance is now attributed to error variance. Consequently, the sum of the Eigenvalues is also less than the number of indicators, and some Eigenvalues may even be negative.\nSimilarly, communalities in EFA are always &lt; 1 because EFA assumes the existence of error variance.\n\n21.6.1 Selecting the Number of Factors\nDetermining the appropriate number of factors to extract is a critical step in EFA. Researchers often use eigenvalues as a cue to determine the number of factors to extract, similar to the Kaiser’s criterion and Scree plot used in PCA - but note that in EFA, this can be misleading as Eigenvalues now depend on the number of extracted factors. Also, by default, SPSS applies Kaiser’s criterion and the Scree plot to PCA Eigenvalues, even if you request EFA!\nAn alternative criterion for determining the number of factors is using theoretical knowledge to guide the decision. For example, if emotions are believed to break down into positive and negative emotions, we may choose to extract two factors. Additionally, the chi-square test can be used to evaluate the appropriateness of different factor solutions and assist in selecting the best-fitting model. To directly compare models, one can compute the Bayesian Information Criterion (BIC) - a relative model fit index designed for comparing models, which balances model fit and complexity. It is computed from the chi square as follows:\n\\[\nBIC = \\chi^2 - df ∗ log(n)\n\\]",
    "crumbs": [
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Dimension Reduction</span>"
    ]
  },
  {
    "objectID": "data_reduction.html#efa-assumption-checks",
    "href": "data_reduction.html#efa-assumption-checks",
    "title": "21  Dimension Reduction",
    "section": "\n21.7 EFA Assumption Checks",
    "text": "21.7 EFA Assumption Checks\nBefore conducting exploratory factor analysis (EFA), it is good practice to perform several assumption checks to ensure the validity and appropriateness of the analysis. One critical aspect to consider is multicollinearity. While factor analysis aims to identify clusters of items that are correlated, excessive multicollinearity can lead to issues. This occurs when multiple items are perfectly linearly dependent, meaning that one item’s score can be exactly reproduced using other variables. In such cases, it becomes difficult to discern the unique contribution of collinear items to the underlying factor model. To detect multicollinearity, researchers can examine the determinant, a value between 0 and 1. It has been argued that the determinant should be greater than 0.00001, which indicates multicollinearity is not too high.\nAnother assumption check for EFA is the proportion of common variance among items. The Kaiser-Meyer-Olkin (KMO) statistic provides an estimate of this proportion. A higher KMO value indicates that more of the variance among items can be explained by common factors, making the data more suitable for factor analysis. Researchers can interpret the KMO value as follows:\n\n\nValue\nInterpretation\n\n\n\n0.00 to 0.49\nunacceptable\n\n\n0.50 to 0.59\nmiserable\n\n\n0.60 to 0.69\nmediocre\n\n\n0.70 to 0.79\nmiddling\n\n\n0.80 to 0.89\nmeritorious\n\n\n0.90 to 1.00\nmarvelous",
    "crumbs": [
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Dimension Reduction</span>"
    ]
  },
  {
    "objectID": "data_reduction.html#rotating-factor-loadings",
    "href": "data_reduction.html#rotating-factor-loadings",
    "title": "21  Dimension Reduction",
    "section": "\n21.8 Rotating Factor Loadings",
    "text": "21.8 Rotating Factor Loadings\nIn factor analysis, we aim to interpret the underlying structure of observed variables. The pattern of factor loadings is crucial in this process, helping us identify items that load highly on specific factors and potentially naming those factors based on high-loading indicators. In a perfect world, factor loadings would be clear and straightforward, with each item loading highly on only one factor. However, real-life factor loadings are not always so clear-cut, making interpretation more challenging.\nTo improve interpretability, we use rotation, which applies a linear transformation to the original factor loadings. Two main types of rotation are orthogonal and oblique rotation. Orthogonal rotation produces uncorrelated factors. The most common technique is VARIMAX rotation, which maximizes the variance of the squared loadings within each factor. Oblique rotation allows factors to correlate; the most common technique is oblimin rotation. In the social sciences, it is often sensible to allow factors to correlate (e.g., different personality dimensions are probably associated).\nOne-Factor EFA and One-Factor CFA:\nAlthough this course is not about confirmatory factor analysis, it is nevertheless useful to know that a one-factor EFA model is identical to a one-factor CFA model. In other words, if our theory implies a one-factor model, we can use exploratory factor analysis (EFA) with maximum likelihood (ML) estimation to test that model. While EFA aims to identify underlying factors without any preconceived hypotheses about their association with items, CFA tests a hypothesized model - in this case, that one factor explains all item scores. CFA with ML estimation produces a chi-square test that can be used to assess model fit. Note, however, that this test can be sensitive to sample size and may reject good models. Researchers can also use the Root Mean Square Error of Approximation (RMSEA) as an alternative model fit index, where values below 0.08 indicate good fit. RMSEA is calculated from the chi square as:\n\\[\nRMSEA = \\frac{\\sqrt{\\chi^2 - df}}{\\sqrt{(n - 1)*df}}\n\\]\nTreating a one-factor EFA as CFA also allows us to estimate latent variable reliability. Recall that Cronbach’s alpha assumes that all items are equally important. This means that it assumes that all factor loadings are the same. Factor analysis tests this assumption. Especially when factor loadings differ, it may be useful to compute latent variable reliability instead, using McDonald’s Omega (or composite reliability). It allows for different factor loadings, making it more appropriate for cases where items have varying contributions to the latent variable. The formula for McDonald’s Omega is:\n\\[\n\\omega = \\frac{SSL}{SSL+SSR} = \\frac{\\text{Sum of Squared Loadings}}{SSL + \\text{Sum of  Squared Residuals}}\n\\]\nCalculate SSL as: \\(SSL = (\\sum_{j=0}^k L_{1,k})^2\\) (first sum loadings, then square sum)\nCalculate SSR as: \\(SSR = 1-\\sum_{j=0}^k L_{1,k}^2\\) (first square loadings, then sum)",
    "crumbs": [
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Dimension Reduction</span>"
    ]
  },
  {
    "objectID": "data_reduction.html#estimating-factor-scores",
    "href": "data_reduction.html#estimating-factor-scores",
    "title": "21  Dimension Reduction",
    "section": "\n21.9 Estimating Factor Scores",
    "text": "21.9 Estimating Factor Scores\nIn many cases, researchers want to conduct further analyses using idividuals’ scores on components or latent variables. In previous sections, we learned about two common methods for obtaining scale scores from multiple items: sum scores and mean scores. In sum scores, we add up the responses from each item to create a total score for each individual. Similarly, in mean scores, we take the average of the responses from all items to obtain a score. In both cases, all items contribute equally to the final scale score. However, this approach assumes that all items are equally important, which might not always be the case. PCA and EFA both allow us to determine whether items are indeed equally important. We can also try to compute scale scores that take differences in item loadings into account.\nFor PCA, computing such scores is straightforward; these are simply given by multiplying the loadings for one component with the observed item scores. Since this is not a latent variable technique, there is only one possible solution to this calculation. To compute a PCA score for a specific individual, we multiply their standardized item scores by the corresponding factor loadings and then sum the results. For instance, if an individual has standardized item scores of 1, 3, and 2 on items with factor loadings of 0.85, 0.80, and 0.14, respectively, their PCA score would be calculated as \\((0.85 * 1 + 0.80 * 3 + 0.14 * 2) / (0.85^2 + 0.80^2 + 0.14^2) = 2.44\\). This score represents the individual’s relative level on the component.\nEstimating latent variable scores in exploratory factor analysis (EFA) is more complex compared to PCA. Unlike PCA, which provides unique factor scores for each individual, EFA does not uniquely determined factor scores. An infinite number of latent variable datasets is consistent with the same EFA model. To estimate factor scores, researchers use methods like the regression method and the Bartlett method. The regression method involves ordinary least squares estimates and aims to maximize the multiple correlation between factor scores and common factors. However, these estimates are biased and the estimated factor scores correlate with one another and with the different latent variables. The Bartlett method produces factor scores that only correlate with their own latent variable but still correlate with estimated scores for other factors. Both methods thus have shortcomings. Some (see references below) have argued that it might be preferable to simply use mean scores instead of factor scores. In cases where factor loadings are approximately equal, this is probably fine.\nFurther reading:\nEveritt, B. S., & Howell, D. C. (2005). Encyclopedia of Statistics in Behavioral Science. DOI:10.1002/0470013192.bsa726 DiStefano, C., Zhu, M., & Mindrila, D. (2009). Understanding and Using Factor Scores: Considerations for the Applied Researcher. DOI:10.7275/da8t-4g52",
    "crumbs": [
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Dimension Reduction</span>"
    ]
  },
  {
    "objectID": "data_reduction.html#pca",
    "href": "data_reduction.html#pca",
    "title": "21  Dimension Reduction",
    "section": "\n24.1 PCA",
    "text": "24.1 PCA\nOpen the data file: emotions.sav.\nThe data file consists of data from the International College Survey 2001 (Diener and colleagues, 2001). In this survey, data on emotions was collected for 41 countries. The data you’ll analyze in this assignment is about norms for experiencing/expressing 12 emotions in Belgium.\n\n\nLet’s look at the data. The first two columns contain the number of the participant and the nation, so you don’t need to include them in the analysis.\nTrue or false: There are missing data. \nTRUE\nFALSE\nSuppose we are only interested in reducing the number of dimensions of the data, which method would you use? \nExplanatory Factor Analysis\nPath Analysis\nConfirmatory Factor Analysis\nPrincipal Component Analysis\nNavigate to Analyze → Dimension Reduction → Factor in SPSS\nIn the tab Extraction: choose the correct method.\nAlso enable the option Scree plot and specify which variables need to be included in the analysis.\nCheck the Options tab. Can you determine what method is used to deal with missing data?\n\nNo action is takenAll missing values are removed prior to analysisAll cases with missing values are removed prior to analysisAll correlations are computed based on available data for that pair of variables\n\nPaste the syntax and run the analysis.\nTake a look at the output.\nWhat number of component have an Eigenvalue greater than 1 (Kaiser’s criterion)? \nHow many components does the scree plot suggest?\n\nRedo the analysis with the number of components you need to retain according to the scree plot.\nYou can specify the number of components in the Extraction menu of the Factor Analysis window.\nClick Fixed number of factors and enter the number of components (2).\nRun the analysis and look at the loadings in the Component matrix.\nTrue or false: This solution is easy to interpret. \nTRUE\nFALSE\nThe two principal components seem to correspond with positive emotions (appropriate and valued), and negative emotions (inappropriate and not valued), but there is not enough simple structure (too many variables have a high loading on both components).\nTo aid interpretation, you could rotate the solution. Which type of rotation is most appropriate here? \northogonal\noblique\n\n\nAnswer\n\nIt is unlikely that positive and negative emotions are uncorrelated! An oblique rotation seems by far the most sensible choice.\n\nRegardless of your previous answer, redo the analysis and choose Direct Oblimin in the Rotation menu.\nTake a look at the component loadings in the Pattern matrix.\nWhich component would you label Positive Emotions? Number.. \nCompare the component loadings in the Pattern Matrix with the loadings in the Component Matrix.\nWe now observe that the loadings resemble a simple structure more closely than before the rotation: the low loadings are lower and the high loadings are higher.\nNote: Due to the oblique rotation, the loadings are no longer equal to item-component correlations.\nWhat is the correlation between the two rotated components? \nRedo the Principal Component Analysis again one last time to save the component scores in the data set. Open Scores in the Factor Analysis window, check the Save as variables checkbox. Have a look at these component scores (now added to your data set): these are the scores for each person on the two components.\nAlternatively, add this syntax:\n  /SAVE REG(ALL)\nWhat is the component score for the first person on the first component? \nTake a look at the table Total Variance Explained.\nHow much of the variance do the two components together account for? %\nWhat proportion of the variance in the item stress is accounted for by the two components? \nWhich item has the highest unicity? \nPride\nHappy\nAnger\nCheerful",
    "crumbs": [
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Dimension Reduction</span>"
    ]
  },
  {
    "objectID": "data_reduction.html#exploratory-factor-analysis-1",
    "href": "data_reduction.html#exploratory-factor-analysis-1",
    "title": "21  Dimension Reduction",
    "section": "\n24.2 Exploratory Factor Analysis",
    "text": "24.2 Exploratory Factor Analysis\nWe will move on to work with Exploratory Factor Analysis.\nFor this second assignment you will perform an Exploratory Factor Analysis (EFA) in SPSS on a set of 18 items. These items measure Tolerance and are part of the European Value Survey (EVS).\nDiscuss with your group when we decide to use Exploratory Factor Analysis and when we decide to use Principal Component Analysis.\n\n\nExplanation\n\nPCA is a data reduction technique. We use it when we want to summarize information in the items.\nEFA is used to identify latent variables underlying the measured items. EFA is typically used when a questionnaire has not been validated yet. When we use EFA, we usually do not know exactly which item belongs to which dimension (although we might have an idea based on our theory).\n\nDiscuss with your group: When do we use Confirmatory Factor Analysis?\n\n\nExplanation\n\nCFA is used when we DO know which items belong to which dimension. With CFA we can then check whether the model that we have in mind corresponds with what we see in the data.\n\n\n\n\nOpen the file evs.sav in SPSS.\n\nSelect Factor via Analyze -&gt; Dimension Reduction.\nWhich extraction method should we use if we want a test of model fit? \nMaximum Likelihood\nPrincipal Components Analysis\nPrincipal Axis Factoring\nUnweighted Least Squares\nDrag all items of the tolerance scale (i.e., V225 - V2242) into the ‘items’ window. Go to Descriptives and select the options “Coefficients”, “Determinant”, and “KMO and Bartlett’s test of sphericity”. Then, go to extraction and select “unrotated factor solution” and “scree plot”. Paste and run the syntax.\nWhat is the Determinant? \nTrue or false: The determinant indicates that multicollinearity might be a problem for these data. \nTRUE\nFALSE\nThe factorability, as determined by the KMO index, is \nMarvelous\nMiddling\nMediocre\nHow many factors would you want to select based on the scree plot? \nHow many factors would you want to select based on Kaiser’s criterion? \nWhat are the limitations of using these criteria?\n\n\nAnswer\n\nBoth are based on eigenvalues computed for PCA, but you are performing EFA now.\nAlthough you can also compute eigenvalues for EFA, SPSS doesn’t use those for the scree plot and Kaiser’s criterion - and moreover, eigenvalues for EFA depend on the number of extracted factors, which defeats the purpose of using them to determine how many factors to extract.\nFurthermore, EFA is a theory-driven technique; it makes sense to use theory to determine how many factors to retain.\n\nAssume that we’re extracting two factors for now. Re-do your analysis with the appropriate number of factors.\nIn the tab Extraction: choose the number of factors you want to extract.\nIn the tab Rotation: Tick the box Direct Oblimin.\nIn the tab Options: The interpretation of the pattern matrix is easier if you suppress all coefficients in that table that are small (e.g., values &lt; 0.30). To do so, click on options and ask SPSS to suppress the small coefficients.\nIn the tab Descriptives: Ask for the reproduced matrix.\nPaste and run the syntax.\nWhen we interpret the output of the factor analysis, we inspect 4 tables: the pattern matrix, the communalities, the factor correlation matrix, and the reproduced correlation matrix.\nWe will start with the pattern matrix.\nInspect the factor loadings in the pattern matrix.\nWhich item has the highest absolute factor loading on Factor 2? Type the variable label from the table: \nDecide for yourself: are the two factors clearly interpretable? Then check your answer.\n\n\nAnswer\n\nThe solution almost follows a simple structure where each item loads on one factor. Only for the item Having casual sex do we see high factor loadings on both factors.\n\nInspect the communalities table.\nHow much of the variance in the item “suicide” do the factors explain? \nCheck the correlations between the three factors.\nHow substantial is the correlation between the factors? \nweak\nmoderate\nlarge\nInspect the residual correlations.\nWhich residual correlation is most concerning?\n\nBetween driving under the influence and claiming state benefits.Between Cheating on tax and Paying cashBetween speeding over the limit and smoking in public places.Between taking soft drugs and joyriding.\n\nTake a look at the pattern matrix again.\nCan you think of a meaningful label for each of the factors? (Take into consideration whether the loadings are positive or negative). Then check your answer.\n\n\nAnswer\n\nThere appears to be a distinction between legal and religious issues.",
    "crumbs": [
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Dimension Reduction</span>"
    ]
  },
  {
    "objectID": "data_reduction.html#exploratory-factor-analysis-ii",
    "href": "data_reduction.html#exploratory-factor-analysis-ii",
    "title": "21  Dimension Reduction",
    "section": "\n24.3 Exploratory Factor Analysis II",
    "text": "24.3 Exploratory Factor Analysis II\nOpen the dataset called “student_questionnaire.sav”.\nIt contains data on moral judgment in a variety of domains of social life (variables whose names start with MACJ). Note that you need the variable MACJ13_imputed, not MACJ13.\n\n24.3.1 Model Selection using the BIC\nWhen conducting EFA with ML estimation, we obtain a chi-square test of model fit that allows us to compute the BIC, a comparative fit index that can help us choose the number of factors that best balances model fit and complexity.\nRun an EFA analysis for 1-3 and 7-9 factors. Using syntax can help you do this easily - just copy-paste the basic syntax below four times and change the number of classes:\nFACTOR\n  /VARIABLES MACJ1 MACJ2 MACJ3 MACJ4 MACJ5 MACJ6 MACJ7 MACJ8 MACJ9 MACJ10 MACJ11 MACJ12 MACJ13_imputed\n    MACJ14 MACJ15 MACJ16 MACJ17 MACJ18 MACJ19 MACJ20 MACJ21\n  /MISSING LISTWISE \n  /CRITERIA FACTORS(1) ITERATE(100)\n  /EXTRACTION ML\n  /ROTATION NOROTATE.\nOpen a spreadsheet in Excel or Google Sheets, and copy-paste the chi-square values and degrees of freedom into the first two columns. Obtain the number of (valid) observations using whatever procedure you want (for example, Descriptives).\nAssuming that you have used the first two columns, paste the following formula into the fourth column. Replace “n” with the number of valid observations. Drag the formula down to copy it the all cells in its column:\n= A1 - B1 * LOG(n)\nWhat is the BIC for 3 factors? \nBased on the BIC, out of the set of models compared, which number of factors would you choose? \nTrue or false: This finding corresponds to the conclusion you would draw from the Scree plot. \nTRUE\nFALSE\nTrue or false: This finding corresponds to the conclusion you would draw from Kaiser’s criterion. \nTRUE\nFALSE\nTrue or false: KMO suggests that there is insufficient common variance for factor analysis. \nTRUE\nFALSE\nTrue or false: The determinant suggests a potential problem with multicollinearity. This might be because there are so many similar items. \nTRUE\nFALSE\nIf I told you that the theory specified 7 factors, how many factors would you prefer? Explain why, then check your answer.\n\n\nAnswer\n\nThe BIC for 7 factors is almost identical to the one for 8 factors. If theory dictates 7 factors, you might prefer to stick with 7, as the evidence for 8 factors is not overwhelmingly stronger.\n\n\n24.3.2 Latent Variable Reliability\nRegardless of your previous answer, perform EFA with one factor. Recall that this is equivalent to performing CFA with one factor.\nCronbach’s alpha assumes that all items have equal factor loadings. Examine the factor loadings matrix.\nTrue or false: it looks like the factor loadings are indeed all equivalent. \nTRUE\nFALSE\nCompute Cronbach’s alpha for these items, and report the value: \nCopy-paste the factor loadings into a spreadsheet.\nUse the spreadsheet function =SUM() to sum the loadings, then square the sum to get the SSL, \\(SSL = (\\sum_{j=0}^k L_{1,k})^2\\)\nCreate a new column with the squared factor loadings. Use the function =A1^2 (assuming that cell A1 contains your first factor loading). Then sum these squared loadings to get the SSR, \\(SSR = 1-\\sum_{j=0}^k L_{1,k}^2\\).\nFinally, calculate McDonald’s Omega:\n\\[\n\\omega = \\frac{SSL}{SSL+SSR}\n\\]\nReport McDonald’s Omega: \nNote that McDonald’s Omega is larger than Cronbach’s alpha. This is a rule; Cronbach’s alpha underestimates reliability compared to McDonald’s omega, and the underestimation becomes worse as the assumption of equal factor loadings is more violated.\n\n24.3.3 Model Fit\nFinally, calculate the RMSEA model fit index for this one-factor model. The cutoff for acceptable fit is RMSEA &lt; .08.\n\\[\nRMSEA = \\frac{\\sqrt{\\chi^2 - df}}{\\sqrt{(n - 1)*df}}\n\\]\nTrue or false: The one-factor model has acceptable fit. \nTRUE\nFALSE",
    "crumbs": [
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Dimension Reduction</span>"
    ]
  },
  {
    "objectID": "confint.html",
    "href": "confint.html",
    "title": "22  BE2 - Confidence Intervals",
    "section": "",
    "text": "23 Lecture\nThere is no lecture for this topic, but you can re-watch part of the lecture on the sampling distribution to refresh your knowledge about confidence intervals!",
    "crumbs": [
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>BE2 - Confidence Intervals</span>"
    ]
  },
  {
    "objectID": "confint.html#confidence-intervals",
    "href": "confint.html#confidence-intervals",
    "title": "22  BE2 - Confidence Intervals",
    "section": "\n25.1 Confidence Intervals",
    "text": "25.1 Confidence Intervals\nIn this assignment we will work on some questions regarding the confidence interval. We focus on the confidence interval around the mean, but everything you learn can also be applied to confidence intervals around the mean difference or regression coefficients.\nFinish the following sentence. The confidence interval around the mean is constructed around the \nPopulation mean (under H0)\nSample mean\nIn the population the variable IQ is normally distributed with \\(IQ \\sim N(\\mu=100, \\sigma=15\\).\nImagine that we drew 2000 samples from the population. For each of the samples we would calculate a 90% confidence interval around the sample mean. If you had to make a guess, how many intervals would you expect to contain the value 100? \nImagine we drew a sample from the population and we calculated the 95% confidence interval around the sample mean for a particular variable. The lower bound of the confidence interval is equal to 85 and the upper bound to 95.\nWhich of the following statements is correct?\n\nThere is a 95% probability that a confidence interval calculated based on a sample from this population contains the true population value.There is a 95% probability that the population mean lies between 85 and 95.The probability that the population mean lies between 85 and 95 is 95%.There is a 95% probability that if we would draw a new sample for the same population, the true population value lies between 85 and 95.\n\nConfidence intervals are interpreted in terms of long-run probability. IF we could draw a huge number of samples from the population, 95% of those samples would provide a confidence interval that contains the population mean.\nWe can never know whether one specific confidence interval contains the population value, however.\nSo we can NEVER draw a conclusion like “there is a 95% probability that the population mean lies between 85 and 95”.\nRecall the first lecture, in which I explained the idea of a “random experiment”. Think of a 95% confidence interval as a random experiment with a 95% probability of containing the population value. One specific confidence interval is not a random experiment. Whether the population mean lies within the interval is not a matter of probability. It either does or it does not. We just don’t know which of these is true.\nImagine a population with variable X, where \\(X \\sim N(\\mu 50, \\sigma = 10)\\)\nAssume a confidence level of 95% for all intervals.\nYou plan to draw a sample with \\(n=20\\) and compute a 95% confidence interval. What’s the probability that this interval will contain 50? %\nYour colleague has already drawn a sample of \\(n=20\\). What’s the probability that their confidence interval includes 50? \n0%\n95%\nCan’t say\n100%\nIf you would draw 20 samples, how many samples would you expect the confidence interval to contain the value 50? \nTrue or false: if you draw 100 samples, 95 of them will provide a confidence interval that contains the population value. \nTRUE\nFALSE\n\n\nExplanation\n\nThis is false because the phrase “will provide” is not a probability statements, but a deterministic one.\n“The number of 95% confidence intervals out of 100 samples that contain the population value” is a random experiment. We expect an outcome of 95, but if we conduct this random experiment, the observed outcome may differ a little, e.g. 93, 94, 97 times are all fine.\n\nAll else being equal, what would you expect to happen to the confidence intervals of smaller samples? \nThey become wider\nThey become narrower\nThey stay the same\n\n\nExplanation\n\nBy increasing the sample size, our estimate becomes more precise. This will lead to more narrow confidence intervals.\nMathematically it also makes sense, because the confidence interval is based on the standard error. Remember that the formula for the standard error is \\(SE = \\frac{\\sigma}{n}\\) . A smaller sample size leads to a smaller standard error, which leads to a narrower interval.\nNote that this does affect the probability of confidence intervals containing \\(\\mu\\).\n\nIf the standard deviation increases (and everything else stays the same) the confidence interval will \nbecome wider\nstay the same\nbecome narrower.\nIf we change the confidence level to 90%, the interval will \nbecome narrower\nstay the same\nbecome wider and \nthe same number of\nfewer\nmore intervals will contain \\(\\mu\\).",
    "crumbs": [
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>BE2 - Confidence Intervals</span>"
    ]
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Data for Portfolio",
    "section": "",
    "text": "SS: Values and Beliefs about Individuals and Collectives\nThis synthetic dataset was inspired by Wave 7 of the World Values Survey (Haerpfer et al., 2022).\nThe World Values Survey (WVS) is a global research project that explores people’s values and beliefs and what social and political impact these have. Among topics covered are support for democracy, tolerance of ethnic minorities, support for gender equality, the role of religion and changing levels of religiosity, the impact of globalization, attitudes toward the environment, work, family, politics, national identity, culture, diversity, insecurity, and subjective well-being. This data source is used by governments, scholars, and international organizations like the United Nations.\nExamples of research questions:\nData documentation: https://www.worldvaluessurvey.org/WVSDocumentationWV7.jsp\nReference: Haerpfer, C., Inglehart, R., Moreno, A., Welzel, C., Kizilova, K., Diez-Medrano J., M. Lagos, P. Norris, E. Ponarin & B. Puranen (eds.). 2022. World Values Survey: Round Seven - Country-Pooled Datafile Version 5.0. Madrid, Spain & Vienna, Austria: JD Systems Institute & WVSA Secretariat. doi:10.14281/18241.20.",
    "crumbs": [
      "Appendices",
      "Data for Portfolio"
    ]
  },
  {
    "objectID": "data.html#ss-values-and-beliefs-about-individuals-and-collectives",
    "href": "data.html#ss-values-and-beliefs-about-individuals-and-collectives",
    "title": "Data for Portfolio",
    "section": "",
    "text": "What proportion of participants considers work to be very important in life? (Q5)\nWhat proportion of participants score more extreme than 9/10 on a left-right political ideology scale? (Q240)\nIs trust in the government significantly higher than the neutral middle of the scale (3)? (Q292O)\nDoes participants’ age predict the attitude that children should take care of their parents? (Q38 and Q262)",
    "crumbs": [
      "Appendices",
      "Data for Portfolio"
    ]
  },
  {
    "objectID": "data.html#cn-behavioral-and-neural-correlates-of-empathy-in-adolescents",
    "href": "data.html#cn-behavioral-and-neural-correlates-of-empathy-in-adolescents",
    "title": "Data for Portfolio",
    "section": "CN: Behavioral and Neural Correlates of Empathy in Adolescents",
    "text": "CN: Behavioral and Neural Correlates of Empathy in Adolescents\nThis synthetic dataset was inspired by a study by Overgaauw and colleagues (2014).\nAdolescence is characterized by significant changes in how individuals perceive and interact with others, both cognitively and emotionally. Empathy is a crucial element in appropriately responding to the emotions and actions of others. It is often described as the capacity to understand and share the emotional experiences of others, enabling us to comprehend and anticipate their intentions. Children who possess higher levels of empathy demonstrate greater emotional regulation and engage in more prosocial behavior towards others. This experimental study presented adolescents with either positive or negative social situations, and asked them to focus either on person A or person B in those situations (in negative situations, person A was the perpetrator and person B was the victim). They then measured how many coins participants were willing to give to the focal person. Empathy was measured using a scale with three sub-dimensions of empathy (Contagion, Understanding, and Support), and brain activation in several regions of interest was measured.\nReference: Overgaauw, S., Güroğlu, B., Rieffe, C., & Crone, E. A. (2014). Developmental Neuroscience, 36 (3-4). Behavior and Neural Correlates of Empathy in Adolescents. https://doi.org/10.1159/000363318",
    "crumbs": [
      "Appendices",
      "Data for Portfolio"
    ]
  },
  {
    "objectID": "data.html#be-sustainable-food-choices",
    "href": "data.html#be-sustainable-food-choices",
    "title": "Data for Portfolio",
    "section": "BE: Sustainable Food Choices",
    "text": "BE: Sustainable Food Choices\nThis synthetic dataset was inspired by a study by De Boer and colleagues (2007).\nSustainability goals may require people in Western countries to reduce their meat consumption. This study investigated which values motivate sustainable food choices related to meat consumption. The researchers surveyed 1530 Dutch consumers and found that various human values were related to different food choice motives. Universalism, in particular, had a unique impact on food choices that favored reduced meat, or free-range meat consumption. This study provided insight into the way values, motives and attitudes influencing sustainable food choices and shape individuals’ dietary decisions.\nReference: Joop de Boer; Carolien T. Hoogland; Jan J. Boersema (2007). Towards more sustainable food choices: Value priorities and motivational orientations. Food Quality and Preference, 18(7), 0–996. doi:10.1016/j.foodqual.2007.04.002.",
    "crumbs": [
      "Appendices",
      "Data for Portfolio"
    ]
  },
  {
    "objectID": "probability_tables.html",
    "href": "probability_tables.html",
    "title": "Appendix A — Z-table",
    "section": "",
    "text": "Table gives the right-tail probability corresponding to a Z-value of the value in the Z-column plus the value in the column name, which indicates the second digit of the Z-score.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nB t-table\nTable gives the t-value corresponding to the right-tail probability indicated by the columns.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Z-table</span>"
    ]
  },
  {
    "objectID": "formula_sheet2.html",
    "href": "formula_sheet2.html",
    "title": "Appendix B — Formula sheet",
    "section": "",
    "text": "B.1 General Part\nMean: \\(\\bar{X} = \\frac{\\Sigma_{i=1}^nx_i}{N}\\)\nVariance: \\(S^2_x = \\frac{\\Sigma_{i=1}^n(x_i-\\bar{x})^2}{n-1}\\)\nStandardized values (Z-values): \\(Z = \\frac{X-\\mu}{\\sigma}\\)\nZ-statistic in one sample Z-test: \\(Z = \\frac{\\bar{x}-\\mu_x}{\\sigma_{x}}\\)\nStandard error of the mean: \\(\\sigma_{\\bar{x}} = \\frac{\\sigma}{\\sqrt{n}}\\)\nCohen’s d: \\(\\frac{\\bar{X}_1-\\bar{X}_2}{s_{pooled}}\\)\n\\(s^2_{pooled} = \\frac{(n_1-1)*s_1^2 + (n_2-1)*s_2^2}{n_1+n_2-2}\\)\n\\(s_{pooled} = \\sqrt{s^2_{pooled}}\\)\nF-statistic in one-way ANOVA: \\(F (df_b, df_w) = \\frac{(SS_b/df_b)}{(SS_w/df_w)} = \\frac{MS_b}{(MS_w}\\)\nSimple regression model: \\(Y' = b_0+b_1X\\)\nMultiple regression model: \\(Y' = b_0+b_1X_1 + b_2X_2\\)\nExplained variance: \\(R^2 = \\frac{s^2_{y'}}{s^2_y}\\)\nt-statistic in a one sample t-test: \\(t = \\frac{\\bar{X}-\\mu_{H0}}{se_x}\\), where \\(se_x = \\frac{s_x}{\\sqrt{n}}\\), \\(df = n - 1\\)\nt-statistic in an independent samples t-test: \\(t = \\frac{(\\bar{X}_1-\\bar{X}_2)-(\\mu_1-\\mu_2)_{H0}}{se_{x_1-x_2}}\\)\n\\(se_{x_1-x_2} = \\sqrt{s^2_{pooled}(\\frac{1}{n_1}+\\frac{1}{n_2})}\\)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Formula sheet</span>"
    ]
  },
  {
    "objectID": "formula_sheet2.html#business-and-economics",
    "href": "formula_sheet2.html#business-and-economics",
    "title": "Appendix B — Formula sheet",
    "section": "B.2 Business and economics",
    "text": "B.2 Business and economics\nLogistic function: \\(P(Y=1|X) = \\frac{e^{(b_0 + b_1X)}}{1 + e^{(b_0 + b_1X)}}\\)\nFrom probability to odds: \\(\\text{odds} = \\frac{P}{1 - P}\\)\nFrom odds to probability: \\(P = \\frac{\\text{odds}}{1 + \\text{odds}}\\)\nFrom odds to logit: \\(\\text{logit} = \\ln(\\text{odds})\\)\nFrom probability to logit: \\(\\text{logit} = \\ln\\left(\\frac{P}{1 - P}\\right)\\)\nFrom logit to odds: \\(\\text{odds} = e^{\\text{logit}}\\)\nFrom logit to probability: \\(P = \\frac{e^{\\text{logit}}}{1 + e^{\\text{logit}}}\\)\nWald test statistic: \\(W = (\\frac{b}{se_b})^2\\)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Formula sheet</span>"
    ]
  },
  {
    "objectID": "formula_sheet2.html#cognitive-neuroscience",
    "href": "formula_sheet2.html#cognitive-neuroscience",
    "title": "Appendix B — Formula sheet",
    "section": "B.3 Cognitive neuroscience",
    "text": "B.3 Cognitive neuroscience\nNumber of Possible Pairwise Comparisons: \\(k \\times \\frac{(k - 1)}{2}\\)\nFactorial ANOVA Linear Model: \\(Y_{jkl} = \\mu_Y + \\alpha_k + \\beta_l + \\alpha\\beta_{kl} + \\epsilon_{jkl}\\)\nEta-squared for Factor A: \\(\\eta_A^2 = \\frac{SS_A}{SS_{total}}\\)\nPartial eta-squared for Factor A: \\(\\eta_{partial.A}^2 = \\frac{SS_A}{SS_A + SS_w}\\)\nAdjusted Mean: \\(\\bar{Y}_{i(adj)} = \\bar{Y}_i - b_w(\\bar{X}_i - \\bar{X})\\)\nt-Statistic in Paired Samples t-Test: \\(t = \\frac{\\bar{d}}{\\frac{s_{\\bar{d}}}{\\sqrt{n}}}, \\quad \\text{df} = n - 1\\)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Formula sheet</span>"
    ]
  },
  {
    "objectID": "formula_sheet2.html#social-sciences",
    "href": "formula_sheet2.html#social-sciences",
    "title": "Appendix B — Formula sheet",
    "section": "B.4 Social Sciences",
    "text": "B.4 Social Sciences\nReliability: \\(r_{xx'} = \\frac{\\text{var}(T)}{\\text{var}(X)} = \\frac{\\text{var}(T)}{\\text{var}(T) + \\text{var}(E)}\\)\nEigenvalue of Component 1 for 6 Items: \\(\\lambda_1 = a_{11}^2 + a_{21}^2 + a_{31}^2 + a_{41}^2 + a_{51}^2 + a_{61}^2\\)\nThe proportion of Variance Accounted For by component 1 (when there are J items) is: \\(\\text{Proportion VAF} = \\frac{\\lambda_1}{\\text{TotalVar}} = \\frac{\\lambda_1}{J}\\)\nComponent loadings for component 1 and item j are represented as: \\(a_{j1} = r_{X_jC_1}\\)\nCommunality for 2 Components: \\(h_{j2} = r_{XjC1}^2 + r_{XjC2}^2 = a_{j1}^2 + a_{j2}^2\\)\nUnicity for 2 Components: \\(b_{j2} = 1 - h_{j2}\\)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Formula sheet</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "DeBruine, L. M., & Lakens, D. (n.d.). Methods Book\nTemplate. Retrieved June 4, 2025, from https://debruine.github.io/booktem/\n\n\nHalpern, J. Y. (2015, May 1). A Modification of the\nHalpern-Pearl Definition of Causality. https://doi.org/10.48550/arXiv.1505.00162\n\n\nHoijtink, H., Bruin, J. de, Duken, S. B., Flores, J., Frankenhuis, W.,\n& Lissa, C. J. van. (2023). The Open Empirical\nCycle for Hypothesis Evaluation in\nPsychology. https://doi.org/10.31234/osf.io/wsxbh\n\n\nMorabia, A. (2013). Hume, Mill, Hill, and the\nSui Generis Epidemiologic Approach to Causal\nInference. American Journal of Epidemiology,\n178(10), 1526–1532. https://doi.org/10.1093/aje/kwt223\n\n\nPearl, J. (2009). Causal inference in statistics: An\noverview. Statistics Surveys, 3, 96–146. https://doi.org/10.1214/09-SS057\n\n\nPeikert, A., Ernst, M. S., & Brandmaier, A. M. (2023). Why does\npreregistration increase the persuasiveness of evidence? A\nBayesian rationalization [Preprint]. https://osf.io/cs8wb.\nhttps://doi.org/10.31234/osf.io/cs8wb\n\n\nVan Lissa, C. J. (2022a). Developmental data science: How\nmachine learning can advance theory formation in Developmental\nPsychology. Infant and Child Development,\n32(6), 1–12. https://doi.org/10.1002/icd.2370\n\n\nVan Lissa, C. J. (2022b). Complementing preregistered confirmatory\nanalyses with rigorous, reproducible exploration using machine learning.\nReligion, Brain & Behavior, 0(0), 1–5. https://doi.org/10.1080/2153599X.2022.2070254",
    "crumbs": [
      "Appendices",
      "References"
    ]
  }
]