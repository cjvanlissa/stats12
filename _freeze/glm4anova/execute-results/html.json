{
  "hash": "f60acfad6f05bb69d286b2211cab97a2",
  "result": {
    "engine": "knitr",
    "markdown": "# GLM-IV: ANOVA {#sec-glm4}\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can also use regression analysis to examine mean differences between the categories of a nominal or ordinal predictor with more than two categories.\nSuppose we have a categorical predictor, such as socioeconomic status (SES), with three categories: Low, Medium, and High. We want to predict fathers' involvement in child rearing based on these SES categories. We can use regression analysis to model this relationship by using dummy variables.\n\nWe previously discussed how *bivariate* linear regression allows us to model the effect of a binary categorical predictor by using dummy coding.\nWe code one variable as the reference group (giving it the value 0), \nand estimate the mean difference between the reference group and the other category.\n\nWhen we have two or more categories, we can use the same principle - but we need to expand the model. For our example with SES, we can select one reference category (say, High SES), and we would create **two** dummy variables to estimate the mean differences between the reference category and the Medium and Low SES categories.\nOur regression model then includes both dummy variables as predictors, along with the intercept term.\n\nThis regression model is completely equivalent to one-way ANOVA (Analysis of Variance). Think of ANOVA as a different interface to the same analysis, which presents the results in a slightly different way that is more common in some subfields of social science.\n\nWhen we perform an ANOVA, we conduct an omnibus test of differences between group means.\nThe default null hypothesis is that all group means are equal, and the alternative hypothesis suggests that at least two group means differ.\nWe test this hypothesis with an F-test for the overall significance of the model.\nYou are already familiar with this test from the lecture on sums of square.\n\nOne way to think about the F-test in the context of ANOVA is that it compares the size of the variance (differences) in group means, relative to the error variance in the data.\nIf the differences between group means are large relative to the spread of the data, we observe a significant test.\nIn ANOVA, the regression sum of squares is also called the \"between-group sum of squares\",\nand the error sum of squares is also called \"within-group sum of squares\".\n\nWhen interpreting the results of ANOVA,\nit's common to use eta squared $\\eta^2$ as an effect size.\nIt is simply another name for the familiar $R^2$.\nIt reflects the proportion of variance in the outcome variable that can be explained by the categorical predictor.\n\n# Lecture\n\n\n\n\n\n\n{{< video https://www.youtube.com/embed/2Z8fhhs69N0 >}}\n\n\n\n\n\n\n\n\n\n\n# Formative Test\n\nA formative test helps you assess your progress in the course, and helps you address any blind spots in your understanding of the material. If you get a question wrong, you will receive a hint on how to improve your understanding of the material.\n\nComplete the formative test ideally after you’ve seen the lecture, but before the lecture meeting in which we can discuss any topics that need more attention\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.webex-check .webex-box}\n\n**Question 1**\n\nHow can you model a categorical predictor with more than 2 categories in regression? <div class='webex-radiogroup' id='radio_SDTPKAGVWC'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_SDTPKAGVWC\" value=\"answer\"></input> <span>Create dummy variables for each category and include them in the regression equation.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_SDTPKAGVWC\" value=\"\"></input> <span>Exclude the categorical predictor from the regression model.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_SDTPKAGVWC\" value=\"\"></input> <span>Use a single continuous variable to represent all categories.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_SDTPKAGVWC\" value=\"\"></input> <span>Convert the categorical predictor into a binary predictor.</span></label></div>\n\n\n**Question 2**\n\nWhat does the intercept term represent in a regression model with dummy variables? <div class='webex-radiogroup' id='radio_YXTOPEMJJT'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_YXTOPEMJJT\" value=\"\"></input> <span>The mean difference between all categories.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_YXTOPEMJJT\" value=\"answer\"></input> <span>The mean value of the reference category.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_YXTOPEMJJT\" value=\"\"></input> <span>The standard deviation of the predictor variable.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_YXTOPEMJJT\" value=\"\"></input> <span>The difference between the means of all categories.</span></label></div>\n\n\n**Question 3**\n\nHow many dummy variables are created for a categorical predictor with three categories? <div class='webex-radiogroup' id='radio_OUNRGRESNY'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_OUNRGRESNY\" value=\"answer\"></input> <span>Two dummy variables are created, each representing membership in one of the non-reference categories.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_OUNRGRESNY\" value=\"\"></input> <span>Three dummy variables are created, each representing membership in a category.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_OUNRGRESNY\" value=\"\"></input> <span>One dummy variable is created, representing membership in the reference category.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_OUNRGRESNY\" value=\"\"></input> <span>For three categories, you don&apos;t need dummy variables.</span></label></div>\n\n\n**Question 4**\n\nWhat does the F-value represent in ANOVA? <div class='webex-radiogroup' id='radio_IGOZYUYVOF'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_IGOZYUYVOF\" value=\"answer\"></input> <span>How large the variance between group means is relative to variance within groups.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_IGOZYUYVOF\" value=\"\"></input> <span>An overall test of the difference between group means.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_IGOZYUYVOF\" value=\"\"></input> <span>The proportion of variance explained by the predictor variable.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_IGOZYUYVOF\" value=\"\"></input> <span>How large the difference between the group means is, relative to the error variance.</span></label></div>\n\n\n**Question 5**\n\nWhat is the purpose of follow-up analyses after a significant ANOVA? <div class='webex-radiogroup' id='radio_CGWKLDBSBB'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_CGWKLDBSBB\" value=\"\"></input> <span>To calculate the effect size.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_CGWKLDBSBB\" value=\"answer\"></input> <span>To understand which specific group means differ significantly from each other.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_CGWKLDBSBB\" value=\"\"></input> <span>To adjust the p-value for multiple comparisons.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_CGWKLDBSBB\" value=\"\"></input> <span>To understand which groups are significant.</span></label></div>\n\n\n**Question 6**\n\nHow are the degrees of freedom calculated for the F-distribution in ANOVA? <div class='webex-radiogroup' id='radio_IEITOYNWBV'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_IEITOYNWBV\" value=\"\"></input> <span>Numerator df: Number of groups - 1; Denominator df: Total number of observations</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_IEITOYNWBV\" value=\"\"></input> <span>Numerator df: Total number of observations - 1; Denominator df: Number of groups</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_IEITOYNWBV\" value=\"\"></input> <span>Numerator df: Total number of observations - Number of groups; Denominator df: Number of groups - 1</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_IEITOYNWBV\" value=\"answer\"></input> <span>Numerator df: Number of groups - 1; Denominator df: Total number of observations - Number of groups</span></label></div>\n\n\n**Question 7**\n\nWhat is the correct interpretation of a small eta squared (η²) value in ANOVA? <div class='webex-radiogroup' id='radio_AKGEQZNBZN'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_AKGEQZNBZN\" value=\"answer\"></input> <span>A small proportion of the total variance is explained by the group differences.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_AKGEQZNBZN\" value=\"\"></input> <span>A small proportion of the total variance is due to individual differences.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_AKGEQZNBZN\" value=\"\"></input> <span>A small proportion of the total variance is due to error.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_AKGEQZNBZN\" value=\"\"></input> <span>A small proportion of the error variance is explained by the group differences.</span></label></div>\n\n\n**Question 8**\n\nGiven the regression equation Y = 20 + 5*D1 - 3*D2 for an ANOVA model with dummy coded predictors, what is the predicted value of Y when D1 = 2 and D2 = 1? <div class='webex-radiogroup' id='radio_NHCMEVBAMW'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_NHCMEVBAMW\" value=\"answer\"></input> <span>This cannot happen as the dummy variables are orthogonal.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_NHCMEVBAMW\" value=\"\"></input> <span>Y = 20 - 5*0 - 3*1 = 17</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_NHCMEVBAMW\" value=\"\"></input> <span>Y = 20 + 5*1 - 3*1 = 22</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_NHCMEVBAMW\" value=\"\"></input> <span>Y = 20 + 5*1 + 3*0 = 25</span></label></div>\n\n\n**Question 9**\n\nIn an ANOVA model with 4 groups and 300 observations, calculate the degrees of freedom for the numerator and denominator for the F-test. <div class='webex-radiogroup' id='radio_RSUFFOKISA'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_RSUFFOKISA\" value=\"\"></input> <span>Numerator df: 4 - 1 = 3; Denominator df: 300 - 1 = 299</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_RSUFFOKISA\" value=\"answer\"></input> <span>Numerator df: 4 - 1 = 3; Denominator df: 300 - 4 = 296</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_RSUFFOKISA\" value=\"\"></input> <span>Numerator df: 300 - 4 = 296; Denominator df: , 4 - 1 = 3</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_RSUFFOKISA\" value=\"\"></input> <span>Numerator df: 300 - 1 = 299; Denominator df: , 4 - 1 = 3</span></label></div>\n\n\n**Question 10**\n\nIn an ANOVA model, the variation of individual observations with respect to the grand mean (SST) is 1200, and the variation of individuals with respect to group means (SSW) is 800. Calculate the proportion of variance explained by the group means (η²). <div class='webex-radiogroup' id='radio_CXTAKCKWJC'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_CXTAKCKWJC\" value=\"answer\"></input> <span>η² = SSB/SST = (SST - SSW)/SST = (1200 - 800)/1200 = 0.333</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_CXTAKCKWJC\" value=\"\"></input> <span>η² = SSW/SST = 800/1200 = 0.667</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_CXTAKCKWJC\" value=\"\"></input> <span>η² = SSB/SSW = (1200 - 800)/800 = 0.5</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_CXTAKCKWJC\" value=\"\"></input> <span>η² = SSB/SST = (1200 + 800)/1200 = 2.0</span></label></div>\n\n\n:::\n\n\n<div class='webex-solution'><button>Show explanations</button>\n**Question 1**\n\n To model a categorical predictor with more than 2 categories, you create dummy variables for each category and include them as predictors in the regression equation.\n\n**Question 2**\n\n The intercept term in a regression model with dummy variables represents the mean value of the reference category.\n\n**Question 3**\n\n For a categorical predictor with three categories, two dummy variables are created, each representing membership in one of the non-reference categories.\n\n**Question 4**\n\n The F-test in ANOVA measures how large the variance in group means is relative to the error variance, helping us determine if there are significant differences between group means.\n\n**Question 5**\n\n Follow-up analyses are conducted after a significant ANOVA to understand which specific groups differ significantly from each other, as the omnibus ANOVA only tells us there are differences among groups but not which ones.\n\n**Question 6**\n\n The degrees of freedom for the F-distribution in ANOVA are calculated as follows: Numerator df = Number of groups - 1; Denominator df = Total number of observations - Number of groups.\n\n**Question 7**\n\n A small eta squared (η²) value in ANOVA indicates that a small proportion of the total variance is explained by the group differences, suggesting weaker group effects.\n\n**Question 8**\n\n It is not possible for an observation to score 1 on two dummies.\n\n**Question 9**\n\n The degrees of freedom for the F-test are calculated as follows: Numerator df = Number of groups - 1; Denominator df = Total number of observations - Number of groups.\n\n**Question 10**\n\n The proportion of variance explained by the group means (η²) is calculated as η² = SSB/SST = (SST - SSW)/SST = (1200 - 800)/1200 = 0.333.\n\n\n</div>\n:::\n\n\n\n\n\n\n# In SPSS\n\n## ANOVA\n\nUsing the ANOVA interface and the regression interface:\n\n\n\n\n\n\n{{< video https://www.youtube.com/watch?v=LXkytSgHl6c >}}\n\n\n\n\n\n\n\n\n\n\n# Tutorial\n\n## ANOVA\n\nFor this assignment, we will use the data file [`5groups.sav`](data/5groups.sav). Please open it in SPSS.\n\nAs you have seen in the previous assignments, this file contains the measurements of the y variable for 5 different groups. So far, we have - at most - compared two groups at once. This time, we will compare the means of all 5 groups simultaneously using an Analysis of Variance (ANOVA).\n\nANOVA is often used to examine the results of experimental research where different groups receive different manipulations of an independent variable, and a continuous dependent variable is measured. In that case, rejecting the null hypothesis indicates a causal effect of the manipulated independent variable on the dependent variable.\n\nLet's say the 5 groups in our data file have received 5 different types of training, and the dependent variable y measures the effect of the training.\n\nWe will now perform an ANOVA to see if these trainings have an equal effectiveness.\n\nThe null hypothesis of the ANOVA with 5 groups is as follows:\n\n$H_0: \\mu_1 = \\mu_2 = \\mu_3 = \\mu_4 = \\mu_5$\n\nThat is, the null hypothesis states that the population means of all five groups are the same. Rejecting the null hypothesis implies that at least one one of these means is different from the rest.\n\nLet's run the analysis!\n\nNavigate to Analyze > General Linear Model > Univariate.\nChoose y as the dependent variable.\nChoose group as the fixed factor.\nNow click on the \"Options\" button and check the two boxes named \"Descriptive statistics\" and \"Homogeneity tests\".\nFinally, click \"Paste\" to paste the syntax into the syntax editor, and run it from there.\n \nYou should end up with the following syntax:\n\n```\n    UNIANOVA y BY group\n      /METHOD=SSTYPE(3)\n      /INTERCEPT=INCLUDE\n      /PRINT=HOMOGENEITY DESCRIPTIVE\n      /CRITERIA=ALPHA(.05)\n      /DESIGN=group.\n```\n \n\nThe first table in the output we will inspect is the \"Descriptive Statistics\" table. This table displays the means and standard deviations of the variable y for each of the five groups.\n\nDo you think the population standard deviations are different for each group? If they are, why could that pose a problem for our analysis?\n\nOne of the assumptions of ANOVA is homoscedasticity. In this case, that means that the population of each group has the same variance (and hence, the same standard deviation). This assumption is also called \"homogeneity of variance\" (= translation of homoscedasticity). Of course the variance in each sample will differ somewhat. If these differences are significant, there is evidence to doubt our assumption. That's why we asked SPSS to perform \"Homogeneity tests\".\n\n\nNote that the SD’s of groups 1 and 2 are quite different from the SD’s of groups 3, 4, 5.\n \nThe next table shows the output of Levene's test. You might remember using Levene's test for comparing the variances of two groups in the context of the independent samples t-test. This time, it tests whether the variance of all 5 groups should be considered equal.\n\nIs there a reason to doubt the assumption of homoscedasticity based on Levene's test? Note: Use the Levene’s test “Based on mean”. `mcq(c(answer = \"Yes\", \"No\"))`\n\n\nIf Levene's test is significant, there is evidence that the population variances of at least 2 of the groups differ.\nThis is evidence against our assumption.\nThis could pose a problem for our analysis.\nWe may choose to use a version of the analysis that is robust to violations of this assumption instead, but that makes our analysis dependent on the data (= no longer confirmatory). Instead, we could discuss the violation, and compare results with and without a robust test. \n\nFor now, we continue with interpreting the output of the final table. There's a lot of information, but for now we are only interested in the Sig. value of the \"Corrected Model\" in the first row. This is the two-sided p-value we can use to test our null hypothesis.\n\nWhat is the two-sided p-value? Do you reject the null hypothesis? What does that mean?\n\n\n<div class='webex-solution'><button>Answer</button>\n\nThe p-value is <.001. This is smaller than 0.05. Therefore, we reject the null hypothesis, which was: $H_0: \\mu1=\\mu2=\\mu3=\\mu4=\\mu5$\n\nThis means that the means of at least two groups are different. Note that we do not yet know for which groups the means differ!\n\n</div>\n\n\n\nFinally, there's an interesting nugget of information below the final table. It's called R Squared. This shows the total amount of variance in y that is explained by group membership.\n\nWhat is the value of R Squared? <input class='webex-solveme nospaces' data-tol='0.01' size='4' data-answer='[\"0.57\",\".57\"]'/>\n\n\nBy rule of thumb, what is the magnitude of this value (small, medium, or large)?\n\nCohen (1988) proposed the following guidelines for interpreting the magnitude of R2:\n\nSize\t| R2\n------|------\nSmall\t| 0.01\nMedium\t| 0.06\nLarge\t| 0.138\n\n\n## ANOVA using regression\n\nThis time, we will conduct the ANOVA using the regression interface.\n\nWhen we conduct ANOVA using regression, we still test the null hypothesis mentioned before:\n\n$H_0: \\mu_1 = \\mu_2 = \\mu_3 = \\mu_4 = \\mu_5$\n\nA different way to phrase this when using regression is to state that all regression coefficients will be zero:\n\n$H_0: \\beta_0 =\\beta_1 = \\beta_2 = \\beta_3 = \\beta_4$\n\nOr to say that the explained variance will be zero:\n\n$H_0: \\rho^2 =0$\n\nAll of these hypotheses are interchangeable and imply that the means of all five groups are the same. If this is not the case, each of these null-hypotheses would be rejected.\nRejecting these null hypothesis implies that at least one one of these means is different from the rest.\n\nTo test the differences between groups, we first create dummy variables. Let's make them for all categories, but we will mostly use group 1 as reference category.\nWhen making dummies, it's most convenient to use syntax:\n\n```\nRECODE group (1=1) (2=0) (3=0) (4=0) (5=0) INTO dgroup1.\nRECODE group (1=0) (2=1) (3=0) (4=0) (5=0) INTO dgroup2.\nRECODE group (1=0) (2=0) (3=1) (4=0) (5=0) INTO dgroup3.\nRECODE group (1=0) (2=0) (3=0) (4=1) (5=0) INTO dgroup4.\nRECODE group (1=0) (2=0) (3=0) (4=0) (5=1) INTO dgroup5.\nEXECUTE.\n```\n\n\nCreate the necessary syntax for a regression with the dummy variable that compares the means of group 1 against all other groups.\n\nYou can find the dialog for the regression under Analyze > Regression > Linear\n\nIn the SPSS dialog you have to specify the Dependent and Independent variable. In our case, the independent variables are all dummies we created, except for the reference category! Use category 1 as reference category.\n \nCompare your syntax to the correct syntax:\n\n```\nREGRESSION\n  /MISSING LISTWISE\n  /STATISTICS COEFF OUTS R ANOVA\n  /CRITERIA=PIN(.05) POUT(.10)\n  /NOORIGIN \n  /DEPENDENT y\n  /METHOD=ENTER dgroup2 dgroup3 dgroup4 dgroup5.\n```\n\nAlso compare this syntax to the one we used for t-test using regression. What is the only difference?\n\nWhich test statistic do you use to determine the significance of your ANOVA? <select class='webex-select'><option value='blank'></option><option value=''>t for the Constant</option><option value='answer'>F</option><option value=''>All of the ts</option><option value=''>R2</option></select>\n\nWhat is the value of the test statistic? <input class='webex-solveme nospaces' data-tol='0.01' size='6' data-answer='[\"14.783\"]'/>\n\nCompare this output to the output of your previous ANOVA!\n\nWhich parts are the same? Which parts are different?\n\n\n<div class='webex-solution'><button>Answer</button>\n\nThe F-test is identical to the one from the ANOVA. What's different is that the regression also gives us t-tests for the difference between each group and the reference group. By changing the reference group, we can make all possible comparisons.\n\n\n</div>\n\n\nNote that, unlike the t-test interface, the regression interface does not provide a Levene's test.\nThis is one reason you might want to use the t-test interface.\nThe regression interface provides a more generic way to test the assumption of homoscedasticity: a residual plot.\n\nGo back through the regression interface, but this time click the Plots button and plot the predicted value (X = ZPRED) against the residual value (Y = ZRESID). \n\nAlternatively, just add this line to your syntax (make sure to remove the period . from what was previously the last line):\n\n```\n  /SCATTERPLOT=(*ZRESID ,*ZPRED).\n```\n\nIf the assumption of homoscedasticity is met, we should see that the dots in this plot are equally distributed around the zero line for all values on the X-axis. In this case, we see some differences that could lead us to question the assumption. However, we don't get an actual test, which is a pity. Thus, you could use the ANOVA interface if you want this test.\n\n\n## One-Way ANOVA\n\nWe have prepared the following data file for this assignment: [`hiking.sav`](data/hiking.sav). Please download it and open it in SPSS.\n\nThe data file describes the result of a fictitious experiment in which a hiking guide has displayed five different types of behavior towards different groups of hikers. The treatment that each person received from the guide is recorded in the variable behavior.\n\nThe dependent variable of this experiment is feeling. Higher scores on this variable indicate a more positive attitude of a participant towards the guide. In this assignment, we will use ANOVA to determine whether the mean score on the dependent variable differs between the five experimental conditions.\n\n\nWhat type of design do we use for this experiment? <select class='webex-select'><option value='blank'></option><option value=''>Combination of the two</option><option value='answer'>Between-subjects design</option><option value=''>Within-subjects design</option></select>\n\nAs you will have noticed, the data file contains a third variable named weather, which can be either good or bad. For now, we will only look at the results obtained during good weather. Hence, we will use \"Select cases\" to select only those participants with a value of 1 on the weather variable.\n\nClick Data > Select Cases and select \"If condition is satisfied\" and click the \"If\"-button. Now enter the following condition into the equation box:\n\nweather = 1\n\nNow click \"Continue\" and \"Paste\" to paste the resulting syntax into the syntax editor. Select Run > All to run it.\n\n \nVerify that half of the participants have been crossed out in the Data View.\n\n \nWe are now ready to perform an ANOVA with the 50 remaining participants.\n\nTo run an ANOVA in SPSS there are multiple options. We will use the module \"General Linear Model\", which encompasses ANOVA and all of its extensions which we will discuss later on (factorial ANOVA, ANCOVA, and repeated measurements). \n\nAnyway, let's first create the basic syntax.\n\nAnalyze > General Linear Model > Univariate\nChoose feeling as the dependent variable and behavior as the fixed factor\nClick on the \"Options\" button and check the two boxes named \"Descriptive\" and \"Homogeneity tests\".\nAfter clicking \"Paste\" you should get the following syntax:\n\n```\nUNIANOVA feeling BY behavior    \n    /METHOD=SSTYPE(3)   \n    /INTERCEPT=INCLUDE   \n    /PRINT=DESCRIPTIVE HOMOGENEITY    \n    /CRITERIA=ALPHA(.05)   \n    /DESIGN=behavior.   \n```\n \n\nWhat is the p-value of the Levene's test? Use the Levene’s test “Based on mean” again. <input class='webex-solveme nospaces' data-tol='0.01' size='5' data-answer='[\"0.611\",\".611\"]'/>\n\nDo we have reason to question the assumption of equal population variances? <select class='webex-select'><option value='blank'></option><option value=''>Yes</option><option value='answer'>No</option></select>\n\nIn ANOVA, we distinguish between three sources of variation: the Sums of Squares total (SSt), the Sums of Squares between (SSb, or SSR) and the Sums of Squares within (SSw, or SSE).\n\nWhat does the Sum of squares total mean (phrase your answer in your own words)? Look up the value of the SSt in the ANOVA output and write it down as well. \n\nWhat does the Sum of squares between entail (phrase your answer in your own words)? Look up the value of the SSb in the ANOVA output, and write it down as well. \n\n\nWhat does the Sums of squares within entail (phrase your answer in your own words)? Look up the value of the SSw in the ANOVA output, and write it down as well.\n\n\n<div class='webex-solution'><button>Answer</button>\n\n\nThe Between Groups Sum of squares or SSb is equal to 18.330 and simply give the squared distance of individual scores to the mean, summed together. In other words, it shows how much variability there is in the group means. If all group means would be equal to each other, the SSb equals 0. \n\n\nThe SSw here is 38.405. It tells us how much the individual scores within a group deviate from the group mean. In other words, it shows how much variability there is within the groups. The is the variation that is independent from the experimental effect (because variation within groups cannot be caused by differences in experimental conditions). \n\nThe SSt tells us how much the invidual scores deviate from the grand mean. In other words, it shows how much variability there is in the dependent variable in total.\n\nRecall that SSB is the same as SSR; it can be found in the row \"Corrected Model\", column Type III Sums of Squares.\n\nRecall that the SSW is the same as SSE; it islabeled \"Error\" in the column Type III Sums of Squares.\n\n\n\n</div>\n\n\n\nHow do we use the different types of Sum of Squares to calculate the F statistic?\n\n<div class='webex-radiogroup' id='radio_XOXBACJWOV'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_XOXBACJWOV\" value=\"answer\"></input> <span>(SSB/dfb)/(SSW/dfw)</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_XOXBACJWOV\" value=\"\"></input> <span>(SSW/dfw)/(SSB/dfb)</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_XOXBACJWOV\" value=\"\"></input> <span>(SSW)/(SSB)</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_XOXBACJWOV\" value=\"\"></input> <span>(SSB)/(SSW)</span></label></div>\n\n\n\n<div class='webex-solution'><button>Answer</button>\n\n\nWe can calculate F using the following formula:\n\n$F = \\frac{MSb}{MSw}$\n\nThe MSb and MSw give the between group variance and within group variance, respectively. They can be calculated using the following formula's:\n\n$MSb = \\frac{SSb}{k-1}$, $MSw = \\frac{SSw}{N-k}$\n\n\n</div>\n\n\nAgain, consider the table Tests of Between Subjects, which represents the results of ANOVA.\n\nWhat is the F-value of the ANOVA? <input class='webex-solveme nospaces' data-tol='0.01' size='5' data-answer='[\"5.369\"]'/>\n\nThe degrees of freedom between (dfb) are <input class='webex-solveme nospaces' size='1' data-answer='[\"4\"]'/> and the degrees of freedom within (dfw) are <input class='webex-solveme nospaces' size='2' data-answer='[\"45\"]'/>. \n\ndfb = k-1\n\ndfw = N-k\n\nAgain consider the table Tests of Between Subjects\n\nWhat is the p-value of the ANOVA? <input class='webex-solveme nospaces' data-tol='0.001' size='5' data-answer='[\"0.001\",\".001\"]'/>\n\nYou can find the p-value of the ANOVA in the table named \"Tests of Between-Subjects Effects\". The p-value is equal to the Sig.-value in the first row of this table.\n\nWhat can you conclude from this? \n\nWrite down a statistical conclusion and a conclusion within the context of this research example.\n\n\n<div class='webex-solution'><button>Answer</button>\n\n\nThe p-value is smaller than our alpha level (0.05). Therefore, we can conclude that there was a statistically significant difference in positive attitude between the groups, based on the behaviour the guide displayed towards them, (F(4,45) = 5.369, p = .001).\n\n\n</div>\n\n\n\nWhat is the proportion of variance explained by behavior? <input class='webex-solveme nospaces' data-tol='0.01' size='5' data-answer='[\"0.323\",\".323\"]'/>\n\n\nHow would you describe this number in words? So what does it mean? \n\nRemark: Cohen formulated some rules of thumb for interpreting the $R^2$\nHow would you qualify the strength of the effect based on Cohen's rules of thumb? And why should we not take the rules of thumb too seriously?\n\nCohen (1988) proposed the following guidelines for interpreting the magnitude of $R^2$\n\nSize  | $R^2$\n--------|------------\nSmall      | 0.01\nMedium  | 0.06\nLarge      | 0.14\n\nNote that, in ANOVA, $R^2$ is also called $\\eta^2$ (eta squared) is a measure of effect size, it indicates the amount of variance in thedependen t variable that is explained by the independent variable(s). In our case, 32.3% of the variance in feeling is explained by behaviour. According to Cohen’s guidelines this is a large effect size (see slide 28). However, these guidelines are rather arbitrary,  which Cohen himself also stresses.\n\n\nThe correct conclusion so far is that the five groups differ significantly on the dependent variable feeling. However, we do not yet know which groups differ.\n\n## One-Way ANOVA using regression\n\nIn this assignment, we will conduct the same ANOVA using the regression interface.\n\nTo test the differences between groups, we first create dummy variables. Let's make them for all categories, but we will mostly use group 1 as reference category.\nWhen making dummies, it's most convenient to use syntax.\nLet's give the dummies informative names this time:\n\n```\nRECODE behavior (1=1) (2=0) (3=0) (4=0) (5=0) INTO rushing.\nRECODE behavior (1=0) (2=1) (3=0) (4=0) (5=0) INTO stories.\nRECODE behavior (1=0) (2=0) (3=1) (4=0) (5=0) INTO insulting.\nRECODE behavior (1=0) (2=0) (3=0) (4=1) (5=0) INTO jokes.\nRECODE behavior (1=0) (2=0) (3=0) (4=0) (5=1) INTO singing.\nEXECUTE.\n```\n\nCreate the necessary syntax for a regression with the dummy variable that compares the means of the rushing group against all other groups.\n\nYou can find the dialog for the regression under Analyze > Regression > Linear\n\nIn the SPSS dialog you have to specify the Dependent and Independent variable. In our case, the independent variables are all dummies we created, except for the reference category! Use category 1 as reference category.\n \nCompare your syntax to the correct syntax:\n\n```\nREGRESSION\n  /MISSING LISTWISE\n  /STATISTICS COEFF OUTS R ANOVA\n  /CRITERIA=PIN(.05) POUT(.10)\n  /NOORIGIN \n  /DEPENDENT feeling\n  /METHOD=ENTER stories insulting jokes singing.\n```\n\n\nCan you find all three of the aforementioned sources of variation in the output? The Sums of Squares total (SSt), the Sums of Squares between (SSb, or SSR) and the Sums of Squares within (SSw, or SSE).\n\nCompare the results to those of the One-Way ANOVA interface.\n\n\n<div class='webex-solution'><button>Answer</button>\n\nIn the ANOVA table, the Regression Sum of Squares is identical to the \"Between Groups Sum of Squares\" from the One-Way ANOVA interface.\nThe Residual Sum of Squares is identical to the \"Within Groups Sum of Squares\" from the One-Way ANOVA interface.\nAnd the Total Sums of Squares are also the same.\n\n\n</div>\n\n",
    "supporting": [
      "glm4anova_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}