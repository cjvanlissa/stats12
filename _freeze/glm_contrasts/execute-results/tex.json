{
  "hash": "6d7ec30c01f716bb7589e1f56f37085d",
  "result": {
    "engine": "knitr",
    "markdown": "# GLM: Contrasts {#sec-glmcontrasts}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRecall that in one-way ANOVA, we have a categorical predictor and a continuous outcome variable. The overall F-test of an ANOVA provides an omnibus (overall) test of differences between group means. The null hypothesis tested in this case is that all $k$ groups have the same mean, $H_0: \\mu_1 = \\mu_2 = \\ldots \\mu_k$. Today, we delve deeper into tests you can perform when you have more complex hypotheses about group means, or want to perform follow-up tests to determine which groups differ significantly.\n\nFirst, we already covered that we can use dummy variables to incorporate this categorical predictor in a regression model. We pick one reference category and create dummy variables to indicate membership in the other groups. These dummy variables take binary values (0 or 1) to represent group membership.\n\nThe formula for regression with dummies is:\n\n$\\hat{Y}_i = a + b_1D_{1i}+ b_2D_{2i}+ b_3D_{3i}+ b_4D_{4i}$\n\nThe intercept represents the mean value of the reference category, and the coefficients $b$ represent the differences between each group and that reference category.\n\nA different way to specify the same model is to omit the intercept, and include a dummy for each of the $k$ groups, so we represent $k$ groups with $k$ dummies:\n\n$\\hat{Y}_i = b_1D_{1i}+ b_2D_{2i}+ b_3D_{3i}+ b_4D_{4i}+ b_5D_{5i}$\n\nBoth of these models are mathematically identical.\nThe advantage of estimating all group means is that this model provides a standard error for each group mean, allowing us to test each group mean against hypothesized values.\n\n## Effects Coding\n\nAnother way to include a categorical predictor is via effects coding. Effects coding compares each group to the grand mean.\nWhen we have unequal group sizes, the coding scheme should account for relative group size.\n\n## Contrast Coding\n\nContrast coding is yet another coding scheme; it compares groups of means. This allows us to test specific hypotheses about differences between groups. Contrast coding is a very advanced technique that requires you to perform some basic matrix algebra in Excel.\n\n## 'Post-Hoc' Tests\n\nThe notion of post-hoc tests is a bit outdated; it essentially refers to making all possible comparisons between group means. The name is based on the fact that such tests are rarely hypothesized beforehand. They can be considered an exploratory procedure to look for differences between groups. Note that performing many tests inflates the risk of drawing false-positive conclusions (Type I error).\n\n\n## Adjusting for Multiple Comparisons\n\nWhen conducting multiple tests, we face an increased risk of committing Type I errors (false positives). If we perform $m$ tests within one study, the experiment-wise Type I error rate is $1- (1-\\alpha)^m$.\nTo control the experiment-wise Type I error rate, we can apply a Bonferroni correction, which divides the significance level $\\alpha$ by the number of tests $m$. This trades off fewer false positive results for more false negative results.\n\nPlanning to test specific hypotheses before conducting the study also helps control Type I error.\n\n# Lecture\n\n\n\n\n\n\n{{< video https://www.youtube.com/embed/8UDpTwXoINU >}}\n\n\n\n\n\n\n\n\n\n\n# Tutorial\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n\n\n\n## Group Means\n\nIn this tutorial, you will learn to use the general linear model to estimate means and to test the difference between two group means, the difference between individual group means and the overall mean, and between groups of means.\n\nOpen [`hiking_long.sav`](data/hiking_long.sav) in SPSS.\n\nThe data file describes the result of a fictitious experiment. A hiking guide has displayed five different types of behavior towards different groups of hikers. The treatment that each person received from the guide is recorded in the variable `behavior`.\n\nThe dependent variable of this experiment is `feeling`. Higher scores on this variable indicate a more positive attitude of a participant towards the guide. In this assignment, we will use ANOVA to determine whether the mean score on the dependent variable differs between the five experimental conditions.\n\n \nThe data file contains a third variable named `weather` which can be either good or bad. For now, we will only look at the results obtained during good weather. Hence, we will use “Select cases” to select only those participants with a value of 1 on the weather variable.\n\nAdditionally, the data contains a variable named `balanced` which distinguishes between data resulting from a balanced experiment (with equal sample sizes in all groups), and from an unbalanced experiment (with unequal group sizes). For now, just ignore this variable.\n\nClick Data > Select Cases and select “If condition is satisfied” and click the “If”-button. Now enter the following condition into the equation box:\n\n`weather = 1`\n\nNow click “Continue” and “Paste” to paste the resulting syntax into the syntax editor. Select Run > All to run it. You should now see in the Data View tab that half of the participants have been crossed out.\n\n \nFirst, let's compute the overall mean of feeling and tabulate the group means.\n\nWhat is the overall mean of feeling? ____^[5\\.74]\n\nWhat are the group means:\n\n* What is the mean of the rushing group? ____^[5\\.47]\n* What is the mean of the stories group? ____^[6\\.12]\n* What is the mean of the insulting group? ____^[4\\.62]\n\n\n```{=latex}\n\n\\begin{tcolorbox}[colback=red!5!white,colframe=red!75!black,title=Answer]\n\n```\n\nTo get the mean of feeling, use Analyze -> Descriptive Statistics -> Descriptives.\n\nTo get the group means, use Analyze -> Compare Means -> Means\n\n```\nDESCRIPTIVES VARIABLES=feeling \n  /STATISTICS=MEAN STDDEV MIN MAX.\n  \nMEANS TABLES=feeling BY behavior\n  /CELLS=MEAN COUNT STDDEV.\n```\n\n\n```{=latex}\n\n\\end{tcolorbox}\n```\n\n\nYou have previously learned to include categorical variables in a linear model by using dummy coding. Today, we will build upon this principle of encoding the information from a categorical variable into several numerical variables.\n\nFirst, recall that a linear model with a five-group nominal predictor can be written as follows:\n\n$\\hat{Y} = b_0 + b_1*D_1 + b_2*D_2 + b_3*D_3 + b_4*D_4$\n\nWhat is $b_0$ in this equation?\n\n^[The intercept; it is the mean of the reference category.]\n\n* (A) The intercept; it is the mean of the reference category.  \n* (B) The average of the group means  \n* (C) The overall sample mean.  \n* (D) The slope of the reference category.  \n\n \n\nTo estimate the model above using regression, you could code dummy variables as follows:\n\nbehavior | D1 | D2 | D3 | D4\n---------|----|----|----|----\nrushing | 1 | 0 | 0 | 0\ntelling stories | 0 | 1 | 0 | 0\ninsulting | 0 | 0 | 1 | 0\nmaking jokes | 0 | 0 | 0 | 1\nsinging | 0| 0|0|0\n\nWhat is the reference category in the coding scheme above? ^[singing]\n\n* (A) singing  \n* (B) rushing  \n* (C) none  \n* (D) jokes  \n\n\n\nSpecify the dummies as described in the table, and estimate the model.\n\n\n```{=latex}\n\n\\begin{tcolorbox}[colback=red!5!white,colframe=red!75!black,title=Answer]\n\n```\n\nTo get the mean of feeling, use Analyze -> Descriptive Statistics -> Descriptives.\n\nTo get the group means, use Analyze -> Compare Means -> Means\n\n```\nRECODE behavior (1=1) (2=0) (3=0) (4=0) (5=0) INTO rushing.\nRECODE behavior (1=0) (2=1) (3=0) (4=0) (5=0) INTO stories.\nRECODE behavior (1=0) (2=0) (3=1) (4=0) (5=0) INTO insulting.\nRECODE behavior (1=0) (2=0) (3=0) (4=1) (5=0) INTO jokes.\nEXECUTE.\n\n  \nREGRESSION\n  /MISSING LISTWISE\n  /STATISTICS COEFF OUTS R ANOVA\n  /CRITERIA=PIN(.05) POUT(.10)\n  /NOORIGIN \n  /DEPENDENT feeling\n  /METHOD=ENTER rushing stories insulting jokes.\n```\n\n\n```{=latex}\n\n\\end{tcolorbox}\n```\n\n\nWhat's the value of the intercept? ____^[6\\.35]\n\nIn this analysis, the intercept is the mean value on feeling for the reference category (singing). Verify that this is true by comparing the intercept of this regression to the Means table you made previously.\n\nWhat is the value of the coefficient for `stories`? _____^[-0\\.23]\n\nHow can we interpret this coefficient?\n\n^[The difference between the mean of the singing group and the mean of the stories group.]\n\n* (A) The difference between the mean of the singing group and the mean of the stories group.  \n* (B) The mean of the stories group.  \n\n \n\n## More Dummies\n\nAs we've previously established, dummy variables allow us to test the significance of mean differences between one reference group and all other groups.\n\nNow, imagine we expect rushing to have a negative effect on behavior, and we want to know which other behaviors are \"better\" (i.e., result in a higher score on behavior) than rushing. \n\nSpecify your hypotheses, then check your answer.\n\n\n\n```{=latex}\n\n\\begin{tcolorbox}[colback=red!5!white,colframe=red!75!black,title=Answer]\n\n```\n\n\n$H_0: \\mu_{rushing} \\leq (\\mu_{stories}, \\mu_{insulting}, \\mu_{joking}, \\mu_{singing})$\n\n$H_1: \\mu_{rushing} < (\\mu_{stories}, \\mu_{insulting}, \\mu_{joking}, \\mu_{singing})$\n\n\n```{=latex}\n\n\\end{tcolorbox}\n```\n\n\nUse dummy variables to test this hypothesis. Note: you will need to specify one additional dummy.\n\n\n\n```{=latex}\n\n\\begin{tcolorbox}[colback=red!5!white,colframe=red!75!black,title=Answer]\n\n```\n\n\n```\nREGRESSION\n  /MISSING LISTWISE\n  /STATISTICS COEFF OUTS R ANOVA\n  /CRITERIA=PIN(.05) POUT(.10)\n  /NOORIGIN \n  /DEPENDENT feeling\n  /METHOD=ENTER stories insulting jokes singing.\n```\n\n\n```{=latex}\n\n\\end{tcolorbox}\n```\n\n\nWhat is the $R^2$ of this model? ____^[0\\.37]\n\nCompare this to the $R^2$ of your previous model. They should be identical, as should be the overall F-test and p-values. Changing the reference category doesn't change what information the dummies convey.\n\nDo we perform one-sided or two sided tests? ^[one-sided]\n\n* (A) one-sided  \n* (B) two-sided  \n\n\n\nUse this information to test your hypotheses.\n\nWhich behaviors are \"better\" than rushing?\n\n^[stories, jokes, and insulting]\n\n* (A) jokes and singing  \n* (B) no behaviors  \n* (C) all behaviors  \n* (D) stories, jokes, and insulting  \n\n \n\nYou can use this technique any time you want to test the significance of the difference between one reference group and other groups.\n\nNote that, in the first assignment, we used a different set of dummy variables than in the second assignment. This means that you can always use different sets of dummy variables when want to compare against multiple reference groups.\n\n## Estimating group means\n\nIn the first assignment, we computed the group means. But remember that the ANOVA model allows us to estimate them using the general linear model. In this assignment, we will do so by hand. After the previous assignment, you should have five dummy variables to represent the five groups of `behavior`.\n\nUntil now, you've always included four dummy variables to represent five categories, as the last category is represented by the intercept.\n\nHowever, it is also possible to represent five groups as follows:\n\n$\\hat{Y} = b_1*D_1 + b_2*D_2 + b_3*D_3 + b_4*D_4 + b_5*D_5$\n\nWhat is $b_5$ in this equation?\n\n^[The intercept; it is the mean of the reference category.]\n\n* (A) The mean value of group 5  \n* (B) The intercept; it is the mean of the reference category.  \n* (C) The slope of the reference category.  \n* (D) The overall sample mean.  \n\n \n\nTo estimate the model above using regression, you could code dummy variables as follows (note that you should already have all these dummies from the previous assignment):\n\nbehavior | D1 | D2 | D3 | D4 | D5\n---------|----|----|----|----|----\nrushing | 1 | 0 | 0 | 0| 0\ntelling stories | 0 | 1 | 0 | 0| 0\ninsulting | 0 | 0 | 1 | 0| 0\nmaking jokes | 0 | 0 | 0 | 1 | 0\nsinging | 0 | 0 | 0 | 0 | 1\n\nNow, go to Analyze -> Regression -> Linear, and add **all five** dummies as predictors.\n\nThen, click the Options button, and notice the option titled \"Include Constant in Equation\".\n\nTurn this option off to remove the intercept from the regression equation, then paste your syntax. Notice a new line that says `/ORIGIN` instead of `/NOORIGIN`. This command removes the intercept.\n\nRun your syntax, and examine the results.\n\nYou might notice that the $R^2$ and F-test changed. This is because these are computed relative to a null-model with only the intercept - but you told SPSS not to include an intercept, so it can't compute that null model here. It's not a big deal. As soon as you estimate models with an intercept again, the $R^2$s will be identical again, regardless of the dummy coding.\n\nWhat's the value of the dummy for singing? ____^[6\\.35]\n\nCompare all coefficients to the table of means from the first assignment. They should all be identical.\n\nThis is how you estimate means using the linear model!\n\nNow, what do the t-tests and p-values in the Coefficients table tell us?\n\n^[Whether the means are significantly different from zero.]\n\n* (A) Whether the means are significantly different from the reference category.  \n* (B) Whether the means are significantly different from each other.  \n* (C) Whether the means are significantly different from zero.  \n* (D) They are not meaningful.  \n\n \n\nKeep in mind that you can use the standard errors from the coefficients table to perform t-tests against other values than 0; for example, what would the test statistic be when testing whether the mean of the insulting group is significantly different from 5, so $H_0: \\mu_{insulting} = 5$? t = _____^[-1\\.52]\n\nIs the difference significant? ^[No]\n\n* (A) Yes  \n* (B) No  \n\n\n\nYou can use regression without an intercept any time you wish to estimate *all* group means in a single analysis and/or test the group means against specific hypothesized values.\n\n## Comparing to Overall Mean\n\nUntil now, we've represented levels of a categorical variable using *dummy variables* with values 0 or 1.\n\nIn this assignment, we introduce an alternative coding system: *effects coding*.\n\nThe main difference with dummy coding is that the reference category does not receive 0 values on all indicator variables, but instead, receives a negative value. In a balanced design (with equal sizes for each group), this value is -1.\n\nSo in a balanced design, with equal group sizes, the coding scheme for effects coding is (I now use the letters E1-E4 to clarify that these are not dummies but effect coded indicators):\n\nbehavior | E1 | E2 | E3 | E4\n---------|----|----|----|----\nrushing | 1 | 0 | 0 | 0\ntelling stories | 0 | 1 | 0 | 0\ninsulting | 0 | 0 | 1 | 0\nmaking jokes | 0 | 0 | 0 | 1\nsinging | -1 | -1 | -1 | -1\n\nThe reference category is still \"singing\".\n\nThe resulting model will give us the following information:\n\n* The overall sample mean for feeling\n* The difference between each group mean, except for singing, compared to the overall mean\n\nMost of the time, however, we will **not** have balanced designs. With this in mind, it is more useful to learn the general way to construct effect coding.\n\nSpecifically, the weights assigned for the singing category (reference category) differ for each dummy, and are computed as:\n\n$-1 * n_{\\text{this category}} / n_{\\text{reference category}}$\n\nCheck the group sizes in the output from assignment 1. \n\nWhat is the sample size for the rushing group? __^[13]\n\nWhat is the sample size for the reference category? __^[11]\n\nWith this in mind, what should the weight be for the singing group, on the dummy that codes for membership of the rushing group? _____^[-1\\.18]\n\nComplete the following syntax, then run it:\n\nRECODE behavior (1=1) (2=0) (3=0) (4=0) (5= ...) INTO Erushing.\nRECODE behavior (1=0) (2=1) (3=0) (4=0) (5=__^[-1]) INTO Estories.\nRECODE behavior (1=0) (2=0) (3=1) (4=0) (5=_____^[-1\\.18]) INTO Einsulting.\nRECODE behavior (1=0) (2=0) (3=0) (4=1) (5=...) INTO Ejokes.\nEXECUTE.\n\nNote the correct answer for the effect code for the stories group. Compare the number of people in the stories group and in the reference group. Then recall that I explained that *In a balanced design (with equal sizes for each group), this value is -1.* You see that this is true now, and why.\n\nCalculate the effect indicators, then specify a regression model with these four effect indicators. Make sure to include the intercept again!\n\n\n```{=latex}\n\n\\begin{tcolorbox}[colback=red!5!white,colframe=red!75!black,title=Check correct syntax]\n\n```\n\n\n```\n\nRECODE behavior (1=1) (2=0) (3=0) (4=0) (5= -1.18) INTO Erushing.\nRECODE behavior (1=0) (2=1) (3=0) (4=0) (5=-1) INTO Estories.\nRECODE behavior (1=0) (2=0) (3=1) (4=0) (5=-1.18) INTO Einsulting.\nRECODE behavior (1=0) (2=0) (3=0) (4=1) (5=-1.18) INTO Ejokes.\nEXECUTE.\n\n\nREGRESSION\n  /MISSING LISTWISE\n  /STATISTICS COEFF OUTS R ANOVA\n  /CRITERIA=PIN(.05) POUT(.10)\n  /NOORIGIN \n  /DEPENDENT feeling\n  /METHOD=ENTER Erushing Estories Einsulting Ejokes.\n\n```\n\n```{=latex}\n\n\\end{tcolorbox}\n```\n\n\nRun the syntax. What is the F-value of the model? ____^[8\\.34] \n\nVerify that this is the same value you got before in models with an intercept.\n\nWhat is the value of the intercept? ____^[5\\.74]\n\nVerify that this is identical to the overall mean of the dependent variable.\n\nWhich group means differ significantly from the overall mean?\n\n^[jokes and insulting]\n\n* (A) no behaviors  \n* (B) insulting  \n* (C) all behaviors  \n* (D) jokes and insulting  \n\n \n\nUsing the coefficients table, calculate the mean of the jokes group. What value do you get? ___^[6\\.3]\n\nThis should be identical to the mean you observed in the previous assignment (using regression to estimate means), and in the first assignment (just computing the means).\n\n## Comparing Groups of Means\n\nExtending the methods above, it is also possible to compare *groups* of means.\nFor example, we might wonder whether negative behaviors (rushing and insulting) differ significantly from positive behaviors (stories, jokes, and singing).\n\nThis approach builds upon the logic of effects coding, where the weights for the reference category were based on the relative sample size of the reference category. This time, however, the weights for the category to be compared to the reference category are *also* based on a sample size.\n\nWe are going to perform several steps, as explained in the lecture.\n\n### Step 1: Plan Contrasts\n\nKeep in mind these rules:\n\n1. The possible values of each indicator variable must sum to 0.\n1. Each group must be uniquely identified by a particular combination of the contrast variables.\n\nAssume for a moment that we have equal group sizes and want to compare groups 1 and 2 to groups 3, 4, and 5.\n\nAppropriate contrasts would then be (I'm using the letter C to indicate that these are not dummies or effect indicators):\n\nbehavior | C1 | C2 | C3 | C4\n---------|----|----|----|----\nrushing | 1 | 1 | 0 | 0\ninsulting | 1 | -1 | 0 | 0\ntelling stories | -$\\frac{2}{3}$ | 0 | 2 | 0\nmaking jokes | -$\\frac{2}{3}$ | 0 | -1 | 1\nsinging | -$\\frac{2}{3}$ | 0 | -1 | -1\n\nNote that:\n\n* Each column sums to 0\n* Every level of behavior is uniquely identified by some combination of contrasts\n\nIn this case, we only care about C1; we created C2, C3 and C4 to ensure that every level of behavior is uniquely identified. But what do C2-C4 test?\n\nC2 compares the two negative behaviors; C3 compares stories against jokes and singing. C4 compares jokes and singing.\n\n### Step 2: Account for Group Size\n\nNow, we have to account for the relative sample sizes of these groups to ensure that we can interpret the coefficients as the difference between the means of those combinations of groups.\n\nUse the descriptive statistics you previously obtained to weight the contrasts from step 1.\n\nE.g., contrast C3 below is already completed. Which other contrasts do you still need to change? ^[C1]\n\n* (A) C1  \n* (B) C1, C2, C4  \n* (C) none  \n* (D) C2 and C4  \n\n\n\nbehavior | C1 | C2 | C3 | C4\n---------|----|----|----|----\nrushing | 1 | 1 | 0 | 0\ninsulting | 1 | -1 | 0 | 0\ntelling stories | -$\\frac{2}{3}$ | 0 | 1 | 0\nmaking jokes | -$\\frac{2}{3}$ | 0 | -13/(11+13) | 1\nsinging | -$\\frac{2}{3}$ | 0 | -11/(11+13) | -1\n\n\n### Step 3: Do Matrix Algebra\n\nEnter the complete matrix into a spreadsheet program.\nAdd one column before the contrasts with an intercept for each group, equal to $1/k$.\n\nWhat's the value of this intercept for this study? ___^[0\\.2]\n\n* Click an Empty cell\n* Paste `=MINVERSE(TRANSPOSE(`\n* Select your contrast matrix\n* Finish the formula by typing closing brackets `))`\n\n**These are the values you will use for your indicators!**\n\nNow, write syntax to create the contrasts using the values you calculated in a spreadsheet. Give these contrasts informative names to help remind yourself of their interpretation. Here is one example; complete the rest yourself:\n\n```\nRECODE behavior (1=.6) (2=.6) (3=-.4) (4=-.4) (5= -.4) INTO posVneg.\n```\n\n\n```{=latex}\n\n\\begin{tcolorbox}[colback=red!5!white,colframe=red!75!black,title=Answer]\n\n```\n\n\n```\nRECODE behavior (1=.6) (2=.6) (3=-.4) (4=-.4) (5= -.4) INTO posVneg.\nRECODE behavior (1=.5) (2=-.5) (3=0) (4=0) (5= 0) INTO rushVinsult.\nRECODE behavior (1=-.01) (2=-.01) (3=.67) (4=-.33) (5= -.33) INTO storyVjokesing.\nRECODE behavior (1=.02) (2=.02) (3=.02) (4=.48) (5= -.53) INTO ? .\nEXECUTE.\n```\n\n\n```{=latex}\n\n\\end{tcolorbox}\n```\n\n\nWhat does the final contrast encode? ^[joke versus singing]\n\n* (A) positive versus negative  \n* (B) all levels  \n* (C) joke versus singing  \n* (D) story vs singing  \n\n\n\n## Run the Analysis\n\nCreate the indicator variables and run the regression analysis.\n\nWhat is the mean difference in feeling between rushing and insulting behaviors? _____^[-0\\.65]\n\nWhich effects are significant? ^[story V jokes, singing]\n\n* (A) all contrasts  \n* (B) positive V negative behaviors  \n* (C) story V jokes, singing  \n* (D) rushing V insulting  \n\n\n\n## Adjusting for Multiple Comparisons\n\nIn these assignments, we have been conducting many tests.\nYou have learned that the significance level $\\alpha$ indicates the probability of drawing a false-positive conclusion (Type I error).\nHowever, these probabilities add up for multiple tests! So when you perform many tests, you can be in a situation where you have a very high probability of comitting at least one Type I error.\n\nWe call the total probability of committing at least one Type I error across multiple tests in the same study the \"family-wise\" or experiment-wise Type I error. You compute it as:\n\n$P(1+ Type I error) = 1 − (1 − \\alpha)^{\\text{number of tests}}$\n\nSo if we perform 3 comparisons, the probability of committing at least one Type I error is: ____^[0\\.14]\n\nAnd if we perform 10 tests? ___^[0\\.4]\n\nIf this makes you uncomfortable - you're not alone! People often seek to maintain a low risk of drawing any false-positive conclusions, and we can do so simply by lowering $\\alpha$.\n\n### Bonferroni correction\n\nBonferroni proposed a simple correction of $\\alpha = \\alpha_{EW}/m$, where $\\alpha_{EW}$ is the desired experiment-wise Type I error rate (e.g., .05), and $m$ is the number of tests.\n\nWhat alpha level would you use per test if you want to achieve an experiment-wise alpha of .05 and conduct 7 tests? ___________^[0\\.007142857]\n\nThe Bonferroni correction is quite conservative; in other words - although Bonferroni helps you avoid false-positive conclusions, it becomes much harder to detect true effects.\n\n## Compare All Groups\n\nThrough the ANOVA interface, you can compare all groups to one another. This is equivalent to repeating a regression analysis multiple times, making each category the reference category in turn.\n\nGo to Analyze -> Compare Means -> One Way ANOVA. Enter Feeling as dependent variable and behavior as Factor.\n\nNow, click post-hoc. Note that you can select many different tests. Select LSD; this corresponds to \"normal\" p-values.\n\nThe other tests in this menu will either apply a penalty to the p-value, or compute the test statistic in a different way, with the purpose of adjusting for multiple comparisons.\n\nWe will manually apply the correction for multiple comparisons instead, because the fact that SPSS performs the correction behind the scenes has a high risk of user error.\n\nAssuming we perform two-sided tests at $\\alpha = .05$, how many significant differences between group means are there? _^[6]\n\nNow, apply a Bonferroni correction to the alpha level. How many tests are you performing? __^[10]\n\nWhat is the new alpha level? _____^[0\\.005]\n\nHow many comparisons are still significant when using this new alpha level? _^[3]\n\n<!-- Tukey's HSD: https://stats.stackexchange.com/questions/610993/the-theory-behind-tukeys-hsd-test -->\n<!-- Tukey's HSD: https://real-statistics.com/one-way-analysis-of-variance-anova/unplanned-comparisons/tukey-hsd/ -->\n\n",
    "supporting": [
      "glm_contrasts_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}