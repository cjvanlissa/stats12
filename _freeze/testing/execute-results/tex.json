{
  "hash": "460c0c984e94f02d6b66798be5db03c9",
  "result": {
    "engine": "knitr",
    "markdown": "# Hypothesis Testing {#sec-testing}\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Falsificationism {#sec-falsificationism}\n\nIn science, it is rarely possible to **prove** a general theory true. Instead, theories earn credibility by **surviving** serious attempts to refute them. This is the core of **falsificationism**, most closely associated with Karl Popper (Popper, 1959/2002). A scientific claim must be **testable** and **falsifiable**: it should make predictions that could, in principle, be shown false by observation. The proverbially simple example is “All swans are white.” No number of white swans can verify the claim, but a **single** black swan would falsify it.\n\nThis logic connects directly to statistical practice. In hypothesis testing we do not “prove the theory”; rather, we pose a **precise** claim—the null hypothesis $H_0$—and ask whether the observed data are sufficiently incompatible with $H_0$ to warrant rejecting it. A small $p$-value is evidence **against** $H_0$, not proof **for** any particular alternative. Likewise, **failing to reject** $H_0$ does not verify $H_0$; it merely indicates that the data are not unusually discordant with it given the test’s design and assumptions. Good scientific practice increases the *riskiness* of tests—deriving clear, prior predictions; minimizing researcher degrees of freedom; and using designs that would make discordant data likely **if** the theory were false (e.g., preregistration and prospective power analysis). In short, falsificationism reminds us that scientific conclusions are **provisional** and should be sharpened by attempts to refute, not by post hoc confirmation.\n\n\n\n## Hypothesis testing {#sec-Hypothesis testing}\n\nHypothesis testing is a method of inferential statistics which allows researchers to draw conclusions about the population based on sample data. It involves formulating hypotheses, calculating test statistics, determining p-values, and drawing conclusions about the null hypothesis.\n\nHypothesis testing builds upon previously covered topics like sampling theory and estimation, where sample statistics are used as the best estimate of population parameters;\nstandard errors to express the uncertainty surrounding those estimates;\nand probability calculus, using probability distributions - like the standard normal distribution - to compute the probability of observing certain values based on the sampling distribution.\n\nTo introduce the concept of hypothesis testing, let's consider an intuitive example. Imagine your car won't start, and you hypothesize that the battery is dead. You then perform an experiment by replacing the battery. If the car starts, you conclude that your initial hypothesis was correct - the battery was indeed dead.\n\nIn this thought experiment, you only need one piece of evidence.\nStatistical hypothesis instead rely on evidence from many observations, and use probability calculus to test hypotheses in the presence of uncertainty.\nStatistical tests use probability calculations to compute how probable it is to observe the sample data if the null hypothesis were true.\nIf the resulting probability is very low, we may doubt whether the null hypothesis is indeed true.\n\nThe steps involved in hypothesis testing are as follows:\n\n1. Formulate hypotheses: This involves stating a testable proposition about population parameters.\n2. Calculate a test statistic: The test statistic describes how many standard errors away from the population statistic, under the null hypothesis, the sample statistic is.\n3. Calculate the p-value: The p-value represents the probability of observing a value at least as extreme as the sample statistic, assuming the null hypothesis is true.\n4. Draw a conclusion about the null hypothesis: Based on the p-value, we either reject or fail to reject the null hypothesis.\n\nHypotheses can be formulated as equality or inequality statements. Equality hypotheses state that a value, difference, or effect is equal to zero, while inequality hypotheses state that a value, difference, or effect is larger or smaller than a specific value. It's important to keep in mind that hypothesis testing does not provide evidence for hypotheses but rather helps in casting doubt on a null hypothesis.\n\nIn addition to the null hypothesis, we can also specify an alternative hypothesis.\nThe specification of the alternative hypothesis depends on a bit of philosophy of science.\nFisher's philosophy suggests using only a null hypothesis; if this null hypothesis is rejected, the \"truth\" must be anything other than the null hypothesis.\nWe could thus say that, according to Fisher's philosophy, the alternative hypothesis is the negation of the null hypothesis. If $H_0: \\mu = 0$, then $H_a: \\mu \\neq 0$; or, if $H_0: \\mu > 0$, then $H_a: \\mu \\leq 0$. The alternative hypothesis is in both cases the \"opposite\" of the null hypothesis.\n\nNeyman-Pearson's philosophy instead involves stating specific null and alternative hypotheses, with an explicit expected effect size for the alternative hypothesis. Assuming a specific expected effect size allows us to calculate the probabilities of drawing correct or incorrect conclusions.\n\nIn hypothesis testing, we calculate a test statistic, which measures the distance between the hypothesized population value and the sample statistic in terms of standard errors.\nThe probability of observing a test statistic at least as extreme as the one we did observe is computed using an appropriate probability distribution.\nFor many tests, we use either the Z-distribution or t-distribution, depending on whether we know the population standard deviation or not.\nThis gives us a probability value (p-value), representing the probability of observing data as extreme as or more extreme than the sample data, assuming that the null hypothesis is true.\n\nWhen interpreting p-values, it's crucial to understand that they give the probability of observing certain data assuming the null hypothesis is true, rather than providing the probability of the null hypothesis being true or false. The p-value is then compared to a pre-determined significance level (usually denoted as alpha) to make a decision about accepting or rejecting the null hypothesis.\n\nRejecting the null hypothesis indicates that the observed data is unlikely to occur if the null hypothesis were true. On the other hand, failing to reject the null hypothesis means that the observed data is not surprising or does not provide sufficient evidence to reject it.\n\nWhen testing hypotheses, we can make two types of errors: A Type I error refers to rejecting the null hypothesis when it is true (a false-positive conclusion), while Type II error refers to accepting the null hypothesis when it is false (failing to detect a true effect).\n\n## Causality {#sec-causality}\n\nCausal knowledge explains **what would change if we intervened**: “If we change $X$, $Y$ will tend to change in a predictable direction.” This is why causality matters for science and policy—causal claims connect description to **action** (Shadish, Cook, & Campbell, 2002). Two levels are useful to distinguish. **Type (general) causality** concerns population regularities (e.g., “Smoking causes lung cancer.”). **Actual (token) causality** concerns whether a **specific** event in a concrete situation caused a particular outcome (e.g., “This crash occurred because the brakes failed.”). For the latter, the modified Halpern–Pearl account captures the core intuition: $X$ counts as a cause of $Y$ when (i) both occurred; (ii) had $X$ been different, and relevant background factors held as they actually were, $Y$ would have been different; and (iii) nothing extraneous is needed for the claim (Halpern, 2015).\n\nHow do we justify causal claims in practice? A helpful everyday test traces to Mill’s requirements: **covariation**, **temporal precedence**, and **non-spuriousness** (Oppewal, 2010). Randomized experiments are powerful because they **enforce** these conditions by design: random assignment severs links from unmeasured causes to treatment, outcomes are measured **after** assignment, and treatment–control contrasts establish covariation (Shadish et al., 2002). Outside experiments, causal inference relies on design and assumptions—e.g., careful measurement of confounders, quasi-experimental strategies, and transparent modeling. Hypothesis tests then assess whether the observed data are compatible with specific causal predictions, but **testing alone does not create causality**: the strength of a causal claim ultimately rests on research design, the plausibility of assumptions, and the theory’s survival of severe attempts at refutation.\n\n# Lecture\n\n\n\n\n\n\n{{< video https://www.youtube.com/embed/-1J2Ge0B3Ro >}}\n\n\n\n\n\n\n\n\n\n\n# Statistical Power\n\n\n## Hypothesis Testing: Type I and Type II Errors\n\nWhen we conduct a null-hypothesis significance test,\nwe select the significance level $\\alpha$.\nAlpha is the probability of committing a Type I error (drawing a false-positive conclusion).\nSince we select the alpha level, it is known.\nIf we use $\\alpha = .05$, that means that - by definition - we accept a 5% risk of committing a Type I error.\n\nThere is also the probability of committing a Type II error.\nThis is called $\\beta$.\nWe don't know the value of $\\beta$ beforehand, but we can calculate it if we make some assumptions.\nThe probability of committing a Type II error (drawing a false-negative conclusion) depends on a few factors:\n\n### How big the effect is\n\nBig effects are harder to miss; imagine trying to detect a difference between two groups.\nIf the mean of both groups is really close together, it will be harder to detect a difference (see below):\n\n::: {#fig-effectsize layout-ncol=2}\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](testing_files/figure-pdf/unnamed-chunk-2-1.pdf){fig-align='center' width=100%}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](testing_files/figure-pdf/unnamed-chunk-3-1.pdf){fig-align='center' width=100%}\n:::\n:::\n\n\n\n\n\n\nEffect of Effect Size\n:::\n\n\n### How big the sample is\n\nLarge samples make it easier to detect smaller effects;\nimagine that the two distributions below are sampling distributions for two groups\nwith very small sample sizes (left) and very large sample sizes (right):\n\n::: {#fig-effectsize layout-ncol=2}\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](testing_files/figure-pdf/unnamed-chunk-4-1.pdf){fig-align='center' width=100%}\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](testing_files/figure-pdf/unnamed-chunk-5-1.pdf){fig-align='center' width=100%}\n:::\n:::\n\n\n\n\n\n\nEffect of Sample Size\n:::\n\n### How 'noisy' the data are\n\nThe standard deviation is a measure of how \"noisy\" the data are.\nIf observations are very spread out (high standard deviation), it will be harder to detect small differences. Consider that a small difference between two groups would be hard to detect if the two groups overlapped very much (= high standard deviation).\nLook at the same picture from the previous point (sample size); it illustrates this principle.\nThe reason that both sample size and \"noise in the data\" have an impact on the probability of committing a Type II error is because they are used to calculate the standard error:\n\n$$\nSE_M = \\frac{SD}{\\sqrt{n}}\n$$\n\n## Power of a Test\n\n\nThe \"power\" of a test is the probability that it will correctly detect a true effect of a specific size.\nSince $\\beta$ is the probability of *missing* a true effect,\nit follows that $1-\\beta$ must be the probability of *detecting* a true effect, or the power.\n\nAs explained in the previous paragraph, we must know a few pieces of information to be able to calculate $\\beta$:\n\n1. Effect size\n2. Sample size\n3. Standard deviation\n\nWhen we conduct a study, we often know the sample size and standard deviation.\nThe effect size is unknown, but we can assume a specific effect size.\nThink of this as an \"informative\" alternative hypothesis.\nThe standard alternative hypothesis in null-hypothesis significance testing is just \"anything that's not the null hypothesis\".\nSo if $H_0: \\mu = 0$, then $H_a: \\mu \\neq 0$.\nNow, we must specify an exact value.\nFor example, we could choose the smallest effect size of interest as the alternative hypothesis:\nLet's say we'd be interested in a mean value of $\\mu = 0.2$.\nThen we could set our informative alternative hypothesis as $H_i: \\mu = 0.2$.\n\nNow we have all the information needed to calculate the power of the test.\nTo do so, we draw two sampling distributions (see illustration below):\nOne (in red) centered around the null hypothesis, $H_0: \\mu = 0$, and one centered around the informative alternative hypothesis, $H_i: \\mu = 0.2$.\nWe find the critical value in the red distribution around the null hypothesis;\nremember that $\\alpha$ is the 5% of probability in the right tail of the red distribution.\nBut we can now also calculate $\\beta$, the unknown probability in the tail of the blue distribution **to the left** of the critical value.\nIf the informative alternative hypothesis is true, then this is the probability of failing to detect that true effect.\nAlthough this example has no numeric values, we see that the blue shaded area representing $\\beta$ is slightly smaller than the red shaded area representing $\\alpha$, so the probability of committing a Type II error must be less than .05, and therefore the power $1-\\beta$ must be greater than 95%! If our assumptions are correct, we'd be really well able to detect a true effect of the size specified under $H_i$.\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](testing_files/figure-pdf/unnamed-chunk-6-1.pdf){fig-align='center' width=100%}\n:::\n:::\n\n\n\n\n\n\n## Try it Yourself\n\nNow, let's calculate this by hand.\nImagine that last year's average grade was $M = 5$, with a standard deviation of $SD = 1.5$.\nThis year, we have 73 students.\nWe've made some changes to the teaching material, and we hope to reach an average grade of $M = 6$.\n\nAssume that the standard deviation this year will be the same as last year, and calculate the power of being able to detect a mean grade of $H_i: \\mu = 6$ when the null hypothesis is that the mean grade is the same as last year, $H_0: \\mu = 5$.\n\n**Step 1: Calculate the SE**\n\nWe calculate the SE as $SE = \\frac{SD}{\\sqrt{n}} = \\frac{1.5}{\\sqrt{73}} = 0.18$\n\n**Step 2: Calculate Critical Value**\n\nThe critical value is the boundary that corresponds to $\\alpha = .05$ in the distribution centered around $H_0$.\nLooking at the t- or Z-table (because sample size is >>30),\nwe see that this corresponds to a Z-value of about 1.64.\n\n![](./z-05.png)\n\nConverting this back to a score on the grades scale, we get:\n\n$$\n\\text{Grade}_{\\text{critical}} = (Z_{\\text{critical}} * SE) + \\mu_{H_0} = (1.64 * 0.18) + 5 = 5.3\n$$\n\n**Step 3: Get Left-Tail Probability for That Value**\n\nNow, we just need to get the left-tail probability for that critical value, in the blue distribution.\nConvert that critical value back to a Z-value, but now in the blue distribution which is centered around $\\mu_{H_i} = 6$:\n\n$$\nZ = \\frac{\\text{Grade}_{\\text{critical}}-\\mu_{H_i}}{SE} = \\frac{5.3 - 6}{0.18}  = -3.89\n$$\n\nThis is an extremely large (negative) Z-value; it's not even in our table.\nThus, the left-tail probability $\\beta$ will be tiny - $\\beta < .01$.\n\n**That means that our power to detect a true effect of 6 would be very high - $1-\\beta = 1-.01 = .99$, 99%!**\n\n\n\n# Formative Test\n\nA formative test helps you assess your progress in the course, and helps you address any blind spots in your understanding of the material. If you get a question wrong, you will receive a hint on how to improve your understanding of the material.\n\nComplete the formative test ideally after you’ve seen the lecture, but before the lecture meeting in which we can discuss any topics that need more attention\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.webex-check .webex-box}\n\n**Question 1**\n\nFor a two-tailed Z-test of the sample mean, the p-value is the probability of finding a more extreme sample mean than the observed sample mean, if the alternative hypothesis were true. ^[FALSE]\n\n* (A) FALSE  \n* (B) TRUE  \n\n\n\n**Question 2**\n\nA researcher performs a Z-test to test the hypotheses H0: mu = 0 versus H1: mu > 0. She finds a test statistic of Z = 2.03 and a one-tailed p-value of 0.02. Statement: If the researcher had performed a two-tailed Z-test, the value of the two-tailed p-value would have been halved: 0.01. ^[FALSE]\n\n* (A) TRUE  \n* (B) FALSE  \n\n\n\n**Question 3**\n\nChris expects that people who have bungee jumped will score high on average on the Big 5 personality trait 'Openness to Experience'. Openness to Experience has been measured on a 10 point scale (1= not at all open, 10 = extremely open). He takes a random sample of 45 persons who have bungee jumped and observes a mean of 6 and SD of 1.954. He tests the following hypotheses: H0: mu =< 5.5 versus H1: mu > 5.5 with a one-sample t-test. He assumes that Openness to Experience is normally distributed in the population. What is the smallest significance level for which Chris can reject the null hypothesis? ^[0.05]\n\n* (A) 0.1  \n* (B) 0.01  \n* (C) 0.05  \n* (D) Cannot reject H0  \n\n\n\n**Question 4**\n\nWhat is the purpose of inferential statistics? ^[Using sample data to infer properties of the population]\n\n* (A) Testing the null hypothesis  \n* (B) Calculating sample statistics  \n* (C) Using sample data to infer properties of the population  \n* (D) Estimation of population parameters  \n\n\n\n**Question 5**\n\nWhat is the standard error? ^[An estimate of the average sampling error when estimating a population parameter using a sample statistic]\n\n* (A) The spread of the sample data  \n* (B) An estimate of the average sampling error when estimating a population parameter using a sample statistic  \n* (C) An estimate of the uncertainty about the average of the sample values  \n* (D) An estimate of the uncertainty about the sample statistic  \n\n\n\n**Question 6**\n\nWhat is a hypothesis in the context of statistical testing? ^[A proposition about the population that can be tested in a sample]\n\n* (A) An explanation for observed phenomena  \n* (B) Something you want to know about the population  \n* (C) A proposition about the population that can be tested in a sample  \n* (D) A statement that some parameter is equal to zero  \n\n\n\n**Question 7**\n\nWhat is meant by 'power' in statistical testing? ^[The probability of correctly finding a true effect]\n\n* (A) The probability of committing a Type II error  \n* (B) The probability of rejecting the null hypothesis  \n* (C) The probability of committing a Type I error  \n* (D) The probability of correctly finding a true effect  \n\n\n\n**Question 8**\n\nYou want to test if the mean height of a sample of 50 students is significantly different from the population mean of 65 inches. The sample mean is 68 inches, and the standard deviation is 2 inches. What is the calculated t-value for this hypothesis test? ^[10.61]\n\n* (A) 1.50  \n* (B) 10.61  \n* (C) 75.00  \n* (D) 240.42  \n\n\n\n**Question 9**\n\nYou want to test if the average time spent on a particular task is different from 30 minutes. You collect a sample of 25 participants, and the sample mean time spent on the task is 28 minutes with a standard deviation of 3 minutes. Conducting a two-tailed t-test, what is the calculated t-value? ^[-3.33]\n\n* (A) -0.67  \n* (B) 3.33  \n* (C) -3.33  \n* (D) -16.67  \n\n\n\n:::\n\n```{=latex}\n\n\\begin{tcolorbox}[colback=red!5!white,colframe=red!75!black,title=Show explanations]\n\n```\n**Question 1**\n\nWhen calculating a test statistic, we assume the null hypothesis to be true - not the alternative hypothesis.\n\n**Question 2**\n\nThe p-value for a two-tailed test is twice as large as for a one-tailed test (because you have the same one-tailed probability in both tails). For two-tailed tests, if the observed effect is in the direction of the alternative hypothesis, you can half the two-tailed p-value.\n\n**Question 3**\n\nDivide the standard deviation by the square root of 45 to get the standard error. Then, divide the difference between the observed mean of 6 and the hypothesized mean of 5.5 by that standard error to get the test statistic. Then, find the critical t-values for a one-sided test with the three alpha levels mentioned in the answers in the t-distribution for 44 degrees of freedom (n - 1). Note that the answer is .05!\n\n**Question 4**\n\nInferential statistics involves using sample data to make inferences or draw conclusions about the larger population from which the sample was drawn. It allows researchers to make educated guesses about population parameters based on the information collected from the sample. Calculating sample statistics is a step in the inferential process, but it is not the primary purpose of inferential statistics. Testing the null hypothesis is another inferential procedure, but it is a specific type of hypothesis testing, and not the overall purpose of inferential statistics.\n\n**Question 5**\n\nThe standard error is a measure of the uncertainty associated with the sample statistic as estimator of the population parameter. It represents how much the sample statistic is expected to vary from one sample to another if multiple samples were drawn from the same population.\n\n**Question 6**\n\nIn statistical testing, a hypothesis is a testable proposition about the population that can be examined using sample data. It is a statement or assumption that researchers put to the test to determine if there is evidence to support it or not. The hypothesis is formulated based on the theory or observations made about the population.\n\n**Question 7**\n\nPower in statistical testing refers to the probability of correctly detecting a true effect or relationship between variables. It is the likelihood of finding a significant result in a study when the effect being investigated truly exists in the population. It is important to have sufficient power in a study to avoid false-negative findings, where we fail to reject the null hypothesis when there is a real effect. Power is one minus the probability of committing a Type II error, or 1-beta.\n\n**Question 8**\n\nTo calculate the t-value for this hypothesis test, you can use the formula: t = (sample mean - population mean) / (standard deviation / square root of sample size). Plugging in the values, t = (68 - 65) / (2 / sqrt(50)) = 10.61.\n\n**Question 9**\n\nThe t-value for a two-tailed t-test can be calculated using the formula: t = (sample mean - population mean) / (standard deviation / square root of sample size). In this case, the population mean is 30 minutes. Plugging in the values, t = (28 - 30) / (3 / sqrt(25)) = -3.33.\n\n```{=latex}\n\n\\end{tcolorbox}\n```\n:::\n\n\n\n\n\n\n\n\n# Tutorial\n\n## Assignment 1: Hypothesis Testing - Formulating Hypotheses\n\nDiscuss with your portfolio group the logic behind hypothesis testing, and how it relates to your personal (and group's) research interests.\n\nConsider the following three research descriptions. Formulate H0 and H1 in words. Discuss your answers with your group members.\n\nResearchers want to know whether it matters for test performance if an exam is completed on a computer or using paper and pencil.\nHence, the research question reads: Is there an effect of the type of administration (computer or paper and pencil) on the test performance?\n\nWhat would be the H0 and HA for this study?\n\n\n```{=latex}\n\n\\begin{tcolorbox}[colback=red!5!white,colframe=red!75!black,title=Show answer]\n\n```\n\nThis appears to be an undirected hypothesis about a mean difference for two independent samples, without a clearly specified alternative hypothesis. Thus, we could state:\n\n$H_0: \\mu_{computer} = \\mu_{paper}$\n$H_A: \\mu_{computer} \\neq \\mu_{paper}$\n\n```{=latex}\n\n\\end{tcolorbox}\n```\n\n\nResearchers want to know whether the alcohol consumption among Dutch students differs from the alcohol consumption in the general Dutch population. Using CBS statistics, they know that in the general population the average alcohol consumption is 5.6 glasses a week. The question is whether the average alcohol consumption among students is different from this national average.\n\nWhat would be the H0 and H1 for this study?\n\n\n```{=latex}\n\n\\begin{tcolorbox}[colback=red!5!white,colframe=red!75!black,title=Show answer]\n\n```\n\nThis appears to be an undirected hypothesis about the difference between a mean and a hypothesized value, without a clearly specified alternative hypothesis. Thus, we could state:\n\n$H_0: \\mu = 5.6$\n$H_A: \\mu \\neq 5.6$\n\n```{=latex}\n\n\\end{tcolorbox}\n```\n\n\nResearchers want to study whether social isolation is associated with income.\n\nWhat would be the H0 and H1 for this study?\n\n\n```{=latex}\n\n\\begin{tcolorbox}[colback=red!5!white,colframe=red!75!black,title=Show answer]\n\n```\n\nThis appears to be an undirected hypothesis about an association between two variables, without a clearly specified alternative hypothesis. We could thus state:\n\n$H_0: \\rho = 0$\n$H_A: \\rho \\neq 0$\n\n```{=latex}\n\n\\end{tcolorbox}\n```\n\n\nFormulating the hypothesis is an important very first step in hypotheses testing. Continue with the next assignment, in which we will go through the steps of a hypothesis test.\n\n## Assignment 2: Test Statistics, Alpha and Significance\n\nIn this assignment we will go through the steps of a hypothesis test.\n\nWhile going through the steps we will come across the most important concepts related to hypothesis testing.\n\nFor the next steps, we consider the following situation:\n\nSuppose we are interested in the personality profile of musicians; that is, we want to know whether, on average, personality characteristics of musicians differ from those of the general population. For now, we'll only focus on Openness. We pretend that we have collected data among 25 musicians using a validated scale for which previous research has shown that in the general population the scores are normally distributed with mean 50 and SD 15. It is our task to test whether the mean of Openness for musicians differs from the mean in the general population. To keep things simple, we assume that in the population of musicians the SD is the same as in the general population; that is, we assume that LaTeX: $\\sigma = 15$. \n\n\nLet openness be the variable of interest. Let $\\mu_{musicians}$ represent the mean openness in the population of musicians. The hypothesis test amounts to testing:\n\n$H0: \\mu_{musicians} = 50$\n\n$H1: \\mu_{musicians} \\neq 50$\n\nNow, when we do the hypothesis test, we seek for evidence against the null hypothesis. More specifically, our testing procedure starts with the assumption that H0 represents the truth and as long as we don’t have convincing evidence that our assumption is false we stick to that assumption.\n\nThe question is, however, when do we have convincing evidence against H0?\n\nFinding evidence against H0 works as follows:\n\nIf H0 is true, we expect mean values close to H0.\nAnd, if we observe a mean value that is much different from the value under H0, we have convincing evidence against H0. If this happens, we reject H0 as representing the truth and accept the alternative hypothesis, H1.\n\nHypothesis testing fits Popper’s philosophy of falsification. He introduced this well-known analogy to explain the logic of falsificationism:\n\n1. Suppose we assume that all Swans are white, $H_0: Swans = white$\n2. We would then not expect to observe black ones.\n3. If we do observe black swans, our initial hypothesis is called into question.\n4. The number of white swans we see (= observations consistent with the hypothesis) does not provide evidence for $H_0$, because there could always be a black swan out there we haven't observed yet.\n\nSo, the next questions are: \n\nWhat are the sample values we can expect under H0?\nWhen is evidence \"convincing\" enough? \nTo answer the first question we have to go back to sampling distributions!\n\nFor the second question, we need a criterion. We have to realize that even if H0 is true, sample values can be far off just by sampling fluctuations (i.e., by chance). The common criterion is: if the observed value is among the 5% most unlikely samples under H0 (i.e. if H0 is true), we reject the null hypothesis.\n\n\nLet's go back to our example about musicians.\n\nLet X be openness. Under H0 we assume that X is normally distributed with mean 50 and SD equal to 15. \n\nWhat are the mean and standard deviation of the sampling distribution of the mean under H0 given that the sample size is 25? And what do we call the standard deviation of the sampling distribution? \n\n(Use what you have learned in the previous lectures. Hint: first make a drawing of the situation, then do the computations).\n\n\n```{=latex}\n\n\\begin{tcolorbox}[colback=red!5!white,colframe=red!75!black,title=Explanation]\n\n```\n\nSampling distribution:\n\n- Mean: $\\mu = 50$\n- Standard error ( =SD of sampling distribution!): $\\sigma_{\\bar{X}} = \\frac{15}{\\sqrt{25}}= 3$\n\n\n```{=latex}\n\n\\end{tcolorbox}\n```\n\n \nSuppose we want to indicate sample means that are unlikely if H0 would be true. In particular, we want to know how far the sample mean must be from the hypothesized mean to be among the 5% of all possible samples under H0 that are furthest away from the hypothesized means.\n\nWhat should the value of the sample mean be to fall within the 5% most deviant samples if the sample size is 25?\n\n\n```{=latex}\n\n\\begin{tcolorbox}[colback=red!5!white,colframe=red!75!black,title=Explanation]\n\n```\n\nWe are talking about the distribution of the mean; so we need to work with the sampling distribution. We want to know the cut offs that mark the 2.5% highest and 2.5% lowest means. We first have to find the Z-values: they are 1.96 for the highest 2.5%, and (by symmetry) -1.96 marks the 2.5% lowest.\n\nHence, to be among the 5% of all possible sample means that are most unlikely under H0, the sample mean should be:\n\nlarger than 50+1.96 x 3 = 55.88\nor smaller than 50-1.96 x 3 = 44.12\n \n\n```{=latex}\n\n\\end{tcolorbox}\n```\n\n\nLet's do some more exercises on the Z-test.\n \nSuppose the mean for Openness we found in our sample was 59.\n\nIf we use a significance level of 5%, would we reject the null hypothesis? ^[Yes]\n\n* (A) Yes  \n* (B) No  \n\n\n\nIn the previous step we used cut offs for the sample means to decide about significance. The cut off scores were obtained via the Z-distribution. However, doing all these computations is not necessary (there's a shortcut!!). In fact, if we know the Z-value for the sample, we can easily find out if the sample is among the 5% of the most unlikely sample means. We only have to compare the value with 1.96 and -1.96 to see whether that is the case.\n\nIn this course, we will use Z-values for different purposes. In these specific calculations, Z is used as a *Test Statistic*. A test statistic quantifies evidence against the null hypothesis. In this case, the Z test statistic expresses how far away from the mean under the null hypothesis the observed mean is, in terms of the number of standard errors.\n\nThe Z test-statistic follows the standard normal distribution. The values 1.96 and -1.96 are called the critical values and they mark the 5% most unlikely sample means under H0. In other words, the critical values mark the reject region for H0. \n\nSo, if we compute the Z-value for the sample mean, and if that sample value of Z falls in the rejection region, we reject H0 (we found something that is unlikely enough to no longer believe H0 is true). If H0 is rejected we speak of a significant result. See the graph below:\n\n![](images/LAS_3_2_Graph-1-1.jpg)\n \nFollowing these steps to test a mean is one example of performing a *\"Z-test\"*!\n\nWe can use the Z-test to test hypotheses about the population mean if we know the population $\\sigma$.\n\nThe test statistic for the Z-test is:\n\n$z  = \\frac{\\bar{X}-\\mu_{H_0}}{\\sigma_{\\bar{X}}}$\n\n\nThis statistic is computed using the mean from the sample, the hypothesized mean under H0 and $\\sigma$.\n\nH0 is rejected at the 5% significance level if z is either larger than 1.96 or smaller than -1.96.\n\nSo far, we rejected the null hypothesis if the sample is among the 5% most unlikely sample means under H0. This 5% was called the significance level, and is denoted as $\\alpha = .05$. However, we could just as well choose 1% or .5%.\n\nWhat would be the critical values for the Z-test if one tests at $\\alpha = .01$? ____^[2\\.58]\n\nWhat would be the critical values for the Z-test if one tests at $\\alpha = .005\\%$? ____^[2\\.81]\n\nFor historical reasons, social scientists tend to use $\\alpha = 0.05$ as a default. So in this course, if alpha is not explicitly stated, assume $\\alpha = 0.05$.\n\n\nWhen we test hypotheses we reject H0 if the sample we find is unlikely if H0 is true. However, the flip side is that, even though H0 is true, we may find a sample that is much different by chance, and erroneously reject H0. Or, in other words, we could make an error. Rejecting H0 while it is true in reality is called a Type I error!\n\nConsider the following:\n\n1. If H0 is true, and you test at $\\alpha = 0.05$, what is the probability of committing a Type I error?\n2. What is the link between the $\\alpha$-level and type I error rate?\n\n\n```{=latex}\n\n\\begin{tcolorbox}[colback=red!5!white,colframe=red!75!black,title=Explanation]\n\n```\n\n1. If H0 is really true (i.e., H0 should not be rejected), then the probability that the sample mean is among the 5% most unlikely is equal to 5%. \n\n2. The alpha level specifies the risk of a Type I error. So if one tests at an alpha level of .05, it means that one accepts a risk of 5% to commit a Type I error. \n\n```{=latex}\n\n\\end{tcolorbox}\n```\n\n \n\nProperties of the Z-test:\n\nUsed to test hypotheses about the mean in a population, assuming $\\sigma$ known.\n\nThe test-statistic equals $z = \\frac{\\bar{X}-\\mu}{\\sigma_{\\bar{X}}}$\n\nThe test statistic is normally distributed.\n\n## Assignment 3: Z-test\n\nIn this assignment we will apply the Z-test.\n\nThis assignment first presents an example, followed by two practice questions.\n\nA researcher wants to test $H_0: \\mu = 50$ against $H_1: \\mu \\neq 50$\n\nData are available from a random sample of 26 respondents. The mean was 53.7. The researcher assumes the SD in the population is 8.5. Perform all steps of the Z-test. \n\n\n```{=latex}\n\n\\begin{tcolorbox}[colback=red!5!white,colframe=red!75!black,title=Explanation]\n\n```\n\nStep 1: Formulate hypotheses\n\n$H_0: \\mu = 50$\n$H_1: \\mu \\neq 50$\n\nStep 2: Compute test statistic\n\nStandard error: $\\frac{8.5}{\\sqrt{26}}=1.667$\n\nTest statistic: $z = \\frac{53.7-50}{1.667}=2.212$\n\nStep 3: Decide about significance\n\n$\\alpha = .05$, so critical values +/- 1.96.\n\nOur test statistic exceeds this critical value.\n\nThe sample mean thus falls in the rejection region, and we should conclude that the test is significant so $H_0$ s rejected.\n\nStep 4: Draw conclusion\n\nWe have convincing evidence that the population mean differs from 50.\n \n\n```{=latex}\n\n\\end{tcolorbox}\n```\n\n\nA researcher wants to test whether the population mean is equal to 80.\nData are available from a random sample of 60 respondents. The mean was 74. The researchers assume the SD in the population is 40. Perform and report all steps of the Z-test. What is the resulting p-value? ____^[0\\.12]\n\nA researcher wants to test whether the population mean is equal to 500. Data are available from a random sample of 75 respondents. The mean was 546. The researchers assume that the SD in the population is 200. Perform all steps of the Z-test. Use $\\alpha = .01$. Perform and report all steps.\n\n\n```{=latex}\n\n\\begin{tcolorbox}[colback=red!5!white,colframe=red!75!black,title=Show answer]\n\n```\n\n\nStep 1: Hypotheses: $H_0: \\mu=500$, $H_1: \\mu \\neq 500$\n\nstep 2: Compute Statistic: \n\n- standard error: $\\frac{200}{\\sqrt{75}} = 23.094$\n- test statistic: $z  = \\frac{546-500}{23.094}=1.992$\n\nStep 3: Decide about significance. \n\nZ does not exceed +/- 2.576. This means that Z does not fall in the reject region when tested at the 1% significance level. The test is not significant.\n\n\nStep 4: Draw conclusion\n\n$H_0$ is not rejected.\n\n```{=latex}\n\n\\end{tcolorbox}\n```\n\n\n## Quiz\n\n::: {.webex-check .webex-box}\n\n\n\"The null and alternative hypothesis are deduced from the data.\" TRUE / FALSE^[FALSE]\n\n\"When performing a hypothesis test, we start by assuming $H_0$ is true.\" TRUE / FALSE^[TRUE]\n\n\"If we reject $H_0$ with $\\alpha=0.05$, then we will also reject it at $\\alpha=0.10$, assuming all other quantities are held constant.\" TRUE / FALSE^[TRUE]\n\n\n```{=latex}\n\n\\begin{tcolorbox}[colback=red!5!white,colframe=red!75!black,title=Explanation]\n\n```\n\nThe critical values of $\\alpha =0.05$ are +/- 1.96. Hence, if $H_0$ is rejected it means that z in the sample is larger than 1.96 or smaller than -1.96.\"\n\nThe critical values of $\\alpha =0.1$ are +/- 1.645. This means that for rejecting $H_0$ at this alpha level, that z should be larger than 1.645 or smaller than -1.645. That is implied by the fact that it exceeds +/- 1.96.\n\n```{=latex}\n\n\\end{tcolorbox}\n```\n\n\n\"If we reject $H_0$, then $H_0$ is surely wrong.\" TRUE / FALSE^[FALSE]\n\n\n```{=latex}\n\n\\begin{tcolorbox}[colback=red!5!white,colframe=red!75!black,title=Explanation]\n\n```\n\nWe should always be aware of the possibility of making a Type I error.\nThe probability of making a Type I error is equal to $\\alpha$.\n\n```{=latex}\n\n\\end{tcolorbox}\n```\n\n\n\"Increasing the sample size n (and holding all the rest constant) decreases the probability of a Type I error.\" TRUE / FALSE^[FALSE]\n\n\n```{=latex}\n\n\\begin{tcolorbox}[colback=red!5!white,colframe=red!75!black,title=Explanation]\n\n```\n\nIncreasing the sample size n (and holding all the rest constant) does not decrease the probability of a Type I error.\n\nThe Type I error is determined by the alpha level.\n\nIf our sample is among the 5% most unlikely sample means of all possible sample means with the same size under $H_0$, whatever that sample size N may be.\n\nIncreasing the sample size n (and holding all the rest constant) does not decrease the probability of a Type I error.\n\n```{=latex}\n\n\\end{tcolorbox}\n```\n\n\n:::\n\n## Assignment 4: Z-test and Alpha-levels\n\nIn this assignment we will practice some more with the Z-test, meanwhile we will review important concepts of hypothesis testing. In particular, we will look at significance levels.\n \nTo test hypotheses, we need to specify the \"significance level\", usually denoted by $\\alpha$. The significance level is our *decision criterion* to reject H0.\n\nThe most common choice is .05. But what does this criterion exactly entail?\n\n\nDiscuss with your group what an $\\alpha$ level entails.\n\n\n```{=latex}\n\n\\begin{tcolorbox}[colback=red!5!white,colframe=red!75!black,title=Explanation]\n\n```\n\nIf we test at an $\\alpha$ of .05 it means that we are willing to reject H0 in favor of H1 if our sample mean belongs to the 5% most extreme scores (2.5% in each tail) under the null hypothesis.\n\nIf indeed the sample mean is among this 5%, it means that we have observed a sample in a range that is quite unlikely if the null hypothesis would be true and, therefore, justifies rejection of the null hypothesis.\n\n```{=latex}\n\n\\end{tcolorbox}\n```\n\n \n\nIn the previous assignments you already used the critical values for the Z-test for specific alpha levels.\n\nFor two-tailed tests, it holds that if the absolute value of Z exceeds the critical value, we may reject $H_0$.\n\nLet $Z_\\text{crit}$ be the critical value. For the Z-test it holds that:\n\n* $Z_\\text{crit} = 1.65$, if $\\alpha = 0.10$ (two-tailed)\n* $Z_\\text{crit} = 1.96$, if $\\alpha = 0.05$ (two-tailed)\n* $Z_\\text{crit} = 2.58$, if $\\alpha = 0.01$ (two-tailed)\n\n## Quiz\n\n::: {.webex-check .webex-box}\n\nResearchers want to test whether $\\mu=70$. They assume that $\\sigma = 10$. Researchers found a mean of 72 in a random sample of 40 persons.\n\nTrue or false:\n\n$H_0$ can be rejected at one of the three levels discussed above ($\\alpha = .10, .05, .01$. TRUE / FALSE^[FALSE]\n\n\"If the two-tailed test is significant at the 5% level, it will also be significant at the 1% level (keeping everything else fixed).\" TRUE / FALSE^[FALSE]\n\n\"If the two-tailed test is not significant at the 10% level, it won't be significant at the 5% level either (keeping everything else fixed).\" TRUE / FALSE^[TRUE]\n\n\"If the two-tailed test is not significant at the 5% level, it could still be significant at the 10% level (keeping everything else fixed).\" TRUE / FALSE^[TRUE]\n\n\"If the two-tailed test is significant at the 1% level, it might not be significant at the 5% level (keeping everything else fixed).\" TRUE / FALSE^[FALSE]\n\n:::\n\n\n## Assignment 5: P-values\n\nWe will now focus on the interpretation of the p-values and how to use the p-values to decide about significance. \n \nConsider the following situation:\n\nScores on a test measuring confidence in police are normally distributed in the general population, with $\\mu = 500$ and an $\\sigma = 50$. Researchers want to know if the average confidence level is different for those who have been a victim of crime. They collect data for 60 victims. They find a sample mean of 511. They test $H_0: \\mu = 500$ against $H_1: \\mu \\neq 500$, while assuming that the population variance is $\\sigma = 50$.\n\nCompute the p-value. Draw a graph for the two-tailed p-value. Write down in your own words and as precise as possible the interpretation of the p-value in the answer box below. Then, discuss your response with your group.\n\n\n```{=latex}\n\n\\begin{tcolorbox}[colback=red!5!white,colframe=red!75!black,title=Explanation]\n\n```\n\n\n- The p-value represents the proportion of all possible sample means that are further away from our hypothesized mean than the observed sample mean is. \n- We have the sampling distribution with $\\mu = 500$ and $\\sigma_{\\bar{X}} = \\frac{50}{\\sqrt{60}} = 6.455$.\n- First, we compute the right-tail area: $P(\\bar{X} > 511) = P(Z > 1.70) = 0.0446$.\n- Hence, 4.66% of all possible samples is further away from $H_0$ on the right side. \n- Second, we compute the left-tail area. These are the sample means that are more than 11 points from the hypothesized mean to the left $P(\\bar{X} < 489) = P(Z < -1.70) = 0.0446$. \n- Hence, the two-tailed p-value is 0.0892.\n\n```{=latex}\n\n\\end{tcolorbox}\n```\n\n\nIs the test significant at the 5% level? TRUE / FALSE^[FALSE]\n\nIs it significant at the 1% level? TRUE / FALSE^[FALSE]\n\n\nResearchers test whether $\\mu = 90$. They assume that $\\sigma=21$. The sample mean was 85. Sample size was 50.\n\nWhat is the two-tailed p-value? ____^[0\\.09]\n\nWhat is the highest level at which the test is significant? ^[0.05]\n\n* (A) 0.05  \n* (B) 0.01  \n* (C) 0.1  \n* (D) 0.005  \n\n\n\n\nResearchers test whether $\\mu = 35$. They assume $\\sigma =16$. The sample mean was 38. Sample size was 64.\n\nCompute the two-tailed p-value and indicate which of the following statements is true.\n\n^[The test is not significant at 10%, not significant at 5% and not significant at 1%.]\n\n* (A) The test is not significant at 10%, not significant at 5% and not significant at 1%.  \n* (B) The test is significant at the 10% level, but not at 5% or 1% level.  \n* (C) The test is significant at the 10% and 5% level, but not at the 1% level.  \n* (D) The test is significant at the 10%, 5% level, and 1% level.  \n\n\n\nConsider these true- or false statements:\n\nIf a two-tailed p-value is .0567 then the test is significant at the 10% level but not at the 5% level. TRUE / FALSE^[TRUE]\n\nIf a two-tailed test is significant at the 5% level but not at the 1% level, then the two-tailed p-value will be less than 0.01. TRUE / FALSE^[FALSE]\n\nA two-tailed p-value of 0.060 indicates that we have 6% chance that the null hypothesis is true.  TRUE / FALSE^[FALSE]\n",
    "supporting": [
      "testing_files\\figure-pdf"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}