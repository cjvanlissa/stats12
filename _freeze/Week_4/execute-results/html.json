{
  "hash": "e507252f2aff6b5bc088ec4474873113",
  "result": {
    "engine": "knitr",
    "markdown": "# Philosophy of Science {#sec-testing}\n\n\n\n\n\n\n\n\n\n\n\n\n\nStudents of statistics often have the impression that this course is all about cold, hard facts.\nNothing could be further from the truth: statistics is a direct extension of philosophy of science.\nThe numbers we calculate here only have relevance to real-world research questions thanks to some complex philosophical arguments.\nWhile most of these are outside the scope of the present course,\nwe want you to be familiar with the main concepts before moving on.\n\n## Deduction and Induction in Hypothesis Testing\n\nHypothesis testing has roots in the philosophy of logic, or correct reasoning.\nIn logic, arguments consist of a set of premises, which can be true or false, that together lead to a conclusion, which can also be true or false.\nThe most famous example is:\n\n> 1. **Premise:** All men are mortal  \n> 1. **Premise:** Socrates is a man  \n> 1. **Conclusion:** Therefore, Socrates is mortal.\n\nThis is a *deductive* argument, which has the property that if the premises are true, then the conclusion must also be true.\nDeductive arguments are also often thought of as arguments from the general to the specific.\nIn this case, the general rule \"all men are mortal\" gives rise to the specific claim that one specific man, Socrates, is also mortal.\n\nThe counterpart to deductive reasoning is *inductive* reasoning,\nwhich proceeds from specific observations or claims to general rules.\nThe most famous example is:\n\n> 1. **Premise:** All swans I have ever seen are white  \n> 1. **Conclusion:** Therefore, all swans are white.\n\nUnlike the deductive argument above, however, inductive reasoning does not guarantee that true premises always produce true conclusions.\nEven if it is true that I have only seen white swans, the conclusion is false - black swans exist.\nDavid Hume introduced another famous example:\n\n> 1. **Premise:** The sun has risen in the east every morning up until now.  \n> 1. **Conclusion:**\tThe sun will also rise in the east tomorrow.\n\nHere, too, the conclusion is not supported by the premise.\nThis might make us feel uncomfortable - which sane person would reject the conclusion that the sun will rise in the east tomorrow?\nThis discomfort illustrates that people are naturally inclined to reason inductively.\nAs scientists, however, we should be very cautious to remember that this way of reasoning is not guaranteed to produce true conclusions.\n\nInductive and deductive reasoning are both used in statistical hypothesis testing.\nDeduction is used when we derive a specific prediction (hypothesis) from a general theory.\nFor example, we could say that:\n\n> 1. **Premise:** More time spent studying causes better grades.  \n> 1. **Conclusion:** In my dataset, time spent studying should correlate positively with grades.\n\nIf the premise is true, then we would expect to observe the corresponding pattern in our data.\n\nInduction comes into play when we draw general conclusions from observed data.\n\n> 1. **Premise:** I observed a positive correlation between time spent studying and grades in my dataset  \n> 1. **Conclusion:** Therefore, time spent studying causes better grades.\n\nThis conclusion does not logically follow from the premise. The problem is not resolved by removing the word \"causes\":\n\n> 1. **Premise:** I observed a positive correlation between time spent studying and grades in my dataset  \n> 1. **Conclusion:** Therefore, time spent studying correlates positively with grades in the general population of students.\n\nIt follows that we can never conclusively \"prove\" general conclusions from specific observations.\nThe philosopher David Hume wrote extensively about this \"problem of induction\":\nHow can we justify the assumption that unobserved cases will follow the same patterns as observed ones?\nHume argued that this assumption cannot be logically justified.\nOur sense that generalization is justified might be based on intuition, but not logic.\nThe problem of induction challenges the very foundation of science.\nWe cannot escape the use of induction when seeking to learn general insights from specific observations,\nbut Hume showed that induction lacks a purely rational justification.\n\n## Falsificationism\n\nIt follows from the problem of induction that it is impossible to definitively prove a theory to be true.\nNo matter how much evidence I have observed that supports a theory (white swans),\nall it takes is one refuting observation (black swan) to reject is.\nKarl Popper sought to avoid the problem of induction by devising a scientific method that relies exclusively on deduction:\n[falsificationism](https://plato.stanford.edu/entries/pseudo-science/#PopFal).\nPopper demarcated the distinction between \"pseudo-science\" and science by arguing that *\"[scientific] statements [...] must be capable of conflicting with [...] observations\"* (Popper 1962, 39).\nThe core business of science, according to Popper, should be to try to reject theories.\nNote that - while Popper's work has been heavily criticized (for good reasons),\nhis work is very influential in social science.\nTherefore, Popper is a good *starting point* for our course - even though he probably should not be the *endpoint* for students with a genuine interest in philosophy of science.\n\n## Falsificationism and Hypothesis Testing\n\nThe idea of falsificationism has been very influential in applied statistics in the social sciences, particularly in the practice of \"Null-Hypothesis Significance Testing\" (NHST).\nIn NHST, researchers proceed as follows:\n\n1. Develop a testable proposition about a population parameter; for example:\n    + \"On average, my students understand the course material. Their mean grade is $\\mu \\geq 6$\".\n    + \"On average, there is a positive association between hours studied and grade, $\\rho \\geq 0$\".\n1. Develop a second hypothesis whose sole purpose is to be rejected, to pay lip service to falsificationism. Call this the \"null hypothesis\". The \"null hypothesis\" is often taken to be the exact opposite of the researcher's true belief, or \"alternative hypothesis\":\n    + \"On average, my students **DO NOT** understand the course material. Their mean grade is $\\mu < 6$\".\n    + \"On average, there is **NO** positive association between hours studied and grade, $\\rho < 0$\".\n1. Execute a procedure to make a decision to reject (falsify) or not reject the null hypothesis (next chapters).\n1. If the null hypothesis is rejected, act as if this finding supports the alternative hypothesis.\n\nAs argued by Andrew Gelman in [this blog post](https://statmodeling.stat.columbia.edu/2014/09/05/confirmationist-falsificationist-paradigms-science/), this approach only pays lip service to falsificationism.\nA true falsificationist would put their true belief (alternative hypothesis) to the test.\nFake falsificationism is creating a meaningless, \"straw man\" null-hypothesis, whose sole purpose is to be rejected.\n\n## Moving Forward\n\nWhere does this leave us? The most important point is that there are important limitations to commonly used methods,\nincluding null-hypothesis significance testing.\nThere is no real satisfying solution.\nJust keep in mind that no statistical test can give evidence in support of a theory or hypothesis; neither a null nor an alternative hypothesis.\n\n## Causality\n\nAnother crucial philosophical issue relevant for statistics is the question of causality.\nScientists are often interested in causal questions.\nWe assume causality, for example, any time we want to *act on* knowledge derived from scientific research.\nFor example, say that I do find a strong correlation between hours studied and grade obtained.\nIf, based on this finding, you increase your study hours in order to improve your grade - then you are assuming causality.\nThe same applies for governments making evidence-based policy,\ncompanies adjusting sales strategies based on customer analytics,\nor drugs that replenish a particular neurotransmitter that has been found lacking in patients with a specific diagnosis.\n\nDespite the fact that causality is so important in scientific research,\nit is rarely defined.\nContemporary definitions are typically based on *counterfactuals*:\nA is a cause of B if B would not have happened if A had not happened.\nThis definition has important limitations, but it is sufficient for our course [@halpernModificationHalpernPearlDefinition2015].\n\nMost people have heard the phrase \"correlation does not imply causation\".\nWhat does this mean?\nOne important misunderstanding is that the *correlation coefficient* is an inappropriate statistic for investigating causal research questions.\nThis is not the case.\nThis phrase warns us that, just because observe a statistical association between variables X and Y (for example, a correlation of $r = .43$), that does not mean that X caused Y.\nImportantly, observing this correlation is consistent with a causal effect of X on Y - but also with other explanations.\nFor example, maybe Y caused X, or maybe a third variable caused both X and Y, and that is why they are correlated.\n\nThe problem is related to the previous section:\nobserving a pattern in data that is consistent with a causal association between X and Y cannot conclusively prove that X caused Y, no matter what statistic you use to describe the pattern.\n\nSo where does causality come from?\nThe short answer is: from theory or methodology.\nCausality can be assumed on theoretical grounds,\nor established using a randomized controlled experiment.\nIn such an experiment, researchers randomly assign participants to either an experimental condition (e.g., receiving a drug, instruction, treatment, et cetera), or a control condition (e.g., receiving a placebo, no instruction, non-effective treatment, et cetera).\nThe random assignment should, theoretically, result in two groups with no systematic differences that could explain between-group differences in the outcome of interest.\nOf course, due to pure chance, it could happen that there are systematic differences (more men in one group, taller people in one group, et cetera).\nBut there is no procedure that has a better chance of resulting in comparable groups than random assignment.\n\nIn the social sciences, experiments are not always feasible or ethical, so researchers often use observational data.\nDoes this preclude all causal claims?\nIt does not.\nIt is perfectly legitimate to present a theory that predicts a causal effect in the Introduction section of your scientific writing,\nand then present empirical data that show a pattern *consistent with* that effect.\nFor example, if I assume that hours studied causes improved grades,\na correlation of $r = .43$ is consistent with that assumption.\nAn alternative explanation might be that having receiving high grades in the past has motivated some students to study harder.\nJust make sure not to take the observed data as *evidence for* a causal effect.\n\nWhat is required to argue that X has a causal effect on Y?\nSeveral philosophers have addressed this issue; most notably Hume and Mill [see @morabiaHumeMillHill2013].\nThe necessary conditions for causality are sometimes summarized as association, temporal precedence, and non-spuriousness. Below, each is supported with quotes from [Hume (1902)](https://www.gutenberg.org/files/9662/9662-h/9662-h.htm)^[With thanks to [Aaron Peikert](https://www.mpib-berlin.mpg.de/person/103737) for identifying these quotes.]:\n\n1. **Association**: Cause and effect must be associated (this could be statistical association)\n    + \"When one particular species of event has always [...] been conjoined with another, we [...] call the one object, Cause; the other, Effect.\" (VII, II, 59)\n    + \"familiar objects or events to be constantly conjoined together\" (V, I, 35)\nThere must be a \"constant union\" between cause and effect, and they must be \"contiguous in space and time\" (Hume 1739,16, pp. 173–175).\n1. **Temporal precedence**: The cause must occur before the effect.\n    + observe a continual succession of objects, and one event following another (V, I, 35)\n    + \"[when] the same object is always followed by the same event; we then begin to entertain the notion of cause and connexion.\" (VII, II, 61)\n1. **Non-spuriousness**: All alternative explanations of the effect are excluded. \n    + \"Their conjunction may be arbitrary and casual. There may be no reason to infer the existence of one from the appearance of the other.\" (describing spuriousness; V, I, 35)\n    + \"we may define a cause to be an object, followed by another, and where all the objects similar to the first are followed by objects similar to the second. Or in other words where, if the first object had not been, the second never had existed.\" (VII, II, 61)\n\nThis latter definition resembles the aforementioned counterfactual definition of causality.\nNote that this definition does not *require* randomized experimentation, but randomized experiments do help us meet all three criteria.\nThe field of *causal inference* focuses on developing methods that can estimate causal effects (like you would get from a randomized controlled experiment) from observational data [@pearlCausalInferenceStatistics2009].\n\n\n# Lecture\n\nTO DO\n\n<!-- {{< video https://www.youtube.com/embed/-1J2Ge0B3Ro >}} -->\n\n# Formative Test\n\nA formative test helps you assess your progress in the course, and helps you address any blind spots in your understanding of the material. If you get a question wrong, you will receive a hint on how to improve your understanding of the material.\n\nComplete the formative test ideally after you’ve seen the lecture, but before the lecture meeting in which we can discuss any topics that need more attention\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.webex-check .webex-box}\n\n**Question 1**\n\nWhat is the main difference between deductive and inductive reasoning? <div class='webex-radiogroup' id='radio_RUAZPPMGYQ'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_RUAZPPMGYQ\" value=\"answer\"></input> <span>Deductive reasoning guarantees the conclusion if the premises are true, while inductive reasoning does not.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_RUAZPPMGYQ\" value=\"\"></input> <span>There is no real difference; both produce valid conclusions.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_RUAZPPMGYQ\" value=\"\"></input> <span>Deductive reasoning is used in science; inductive is not.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_RUAZPPMGYQ\" value=\"\"></input> <span>Inductive reasoning guarantees conclusions; deductive does not.</span></label></div>\n\n\n**Question 2**\n\nWhich of the following is an example of inductive reasoning? <div class='webex-radiogroup' id='radio_OFNZEZQAJB'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_OFNZEZQAJB\" value=\"\"></input> <span>All humans are mortal, so Socrates is mortal.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_OFNZEZQAJB\" value=\"\"></input> <span>Water boils at 100 degrees at sea level.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_OFNZEZQAJB\" value=\"answer\"></input> <span>The sun has always risen in the east, so it will rise in the east tomorrow.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_OFNZEZQAJB\" value=\"\"></input> <span>Students who study more get better grades.</span></label></div>\n\n\n**Question 3**\n\nWhat is the role of deduction in statistical hypothesis testing? <div class='webex-radiogroup' id='radio_EKKIZUCXVL'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_EKKIZUCXVL\" value=\"answer\"></input> <span>It is used to derive specific predictions from general theories.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_EKKIZUCXVL\" value=\"\"></input> <span>It determines the sample size needed.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_EKKIZUCXVL\" value=\"\"></input> <span>It tests if data supports any hypothesis.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_EKKIZUCXVL\" value=\"\"></input> <span>It is used to generalize observations to populations.</span></label></div>\n\n\n**Question 4**\n\nWhat was Karl Popper’s proposed solution to the problem of induction? <div class='webex-radiogroup' id='radio_VFRYXKEYEC'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_VFRYXKEYEC\" value=\"answer\"></input> <span>Falsification: trying to disprove theories rather than prove them.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_VFRYXKEYEC\" value=\"\"></input> <span>Only using observational data.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_VFRYXKEYEC\" value=\"\"></input> <span>Using more data to confirm theories.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_VFRYXKEYEC\" value=\"\"></input> <span>Renouncing inductively constructed theories as pseudoscience.</span></label></div>\n\n\n**Question 5**\n\nIn Null-Hypothesis Significance Testing (NHST), what role does the null hypothesis play? <div class='webex-radiogroup' id='radio_SENVWJGDFM'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_SENVWJGDFM\" value=\"answer\"></input> <span>It merely exists to be refuted.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_SENVWJGDFM\" value=\"\"></input> <span>It shows causality when rejected.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_SENVWJGDFM\" value=\"\"></input> <span>It provides definitive proof of a theory.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_SENVWJGDFM\" value=\"\"></input> <span>It reflects the researcher’s true belief.</span></label></div>\n\n\n**Question 6**\n\nWhat does the phrase 'correlation does not imply causation' mean? <div class='webex-radiogroup' id='radio_XWCDEDLTVW'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_XWCDEDLTVW\" value=\"\"></input> <span>Causation can only be studied with regression.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_XWCDEDLTVW\" value=\"answer\"></input> <span>A statistical association may not reflect a true causal relationship.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_XWCDEDLTVW\" value=\"\"></input> <span>Causal relationships cannot be studied using statistics.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_XWCDEDLTVW\" value=\"\"></input> <span>Don&apos;t use a correlation coefficient if the effect is causal.</span></label></div>\n\n\n**Question 7**\n\nAccording to a common interpretation of Hume, which three conditions are necessary for causality? <div class='webex-radiogroup' id='radio_KSNJWHFPGM'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_KSNJWHFPGM\" value=\"\"></input> <span>Observation, correlation, and prediction.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_KSNJWHFPGM\" value=\"answer\"></input> <span>Association, temporal precedence, and non-spuriousness.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_KSNJWHFPGM\" value=\"\"></input> <span>Falsifiability, deduction, and experimentation.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_KSNJWHFPGM\" value=\"\"></input> <span>Randomization, generalization, and verification.</span></label></div>\n\n\n**Question 8**\n\nHow do randomized controlled experiments support causal inference? <div class='webex-radiogroup' id='radio_ATMRVTAMWA'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_ATMRVTAMWA\" value=\"\"></input> <span>They confirm inductive conclusions.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_ATMRVTAMWA\" value=\"answer\"></input> <span>They eliminate alternative explanations through random assignment.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_ATMRVTAMWA\" value=\"\"></input> <span>They eliminate the need for statistical testing.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_ATMRVTAMWA\" value=\"\"></input> <span>They always prove causality through replication.</span></label></div>\n\n\n:::\n\n\n<div class='webex-solution'><button>Show explanations</button>\n**Question 1**\n\nDeductive reasoning leads to necessarily true conclusions if the premises are true, while inductive reasoning involves probable conclusions based on patterns.\n\n**Question 2**\n\nAssuming that the sun will rise tomorrow because it always has is an example of induction, and it is not logically justified.\n\n**Question 3**\n\nDeduction is used to derive derive specific, testable predictions from general theories, such as expecting a correlation between study time and grades if studying improves performance.\n\n**Question 4**\n\nPopper argued that science should focus on rejecting falsifiable hypotheses rather than confirming them, avoiding the pitfalls of induction.\n\n**Question 5**\n\nThe null hypothesis is a 'straw man' hypothesis, only intended to be rejected. This interpretation of Popper’s falsificationism actually never submits theories to the test, and aligns more closely with confirmationism.\n\n**Question 6**\n\nNo statistical finding can prove causation, so a correlation (or other type of association) between two variables doesn't confirm a causal link.\n\n**Question 7**\n\nA common interpretation of Hume is that for a cause-effect relationship, the variables must be associated, the cause must precede the effect, and other explanations must be ruled out.\n\n**Question 8**\n\nRandom assignment maximizes the probability that the treatment and control groups do not differ on any confounding variables, thus ensuring nonspuriousness. Furthermore, a well-designed experiment ensures association (if there is an effect) and temporal precedence.\n\n\n</div>\n:::\n\n\n\n\n\n\n# Tutorial\n\n## Assignment 1: Hypothesis Testing - Formulating Hypotheses\n\nDiscuss with your portfolio group the logic behind hypothesis testing, and how it relates to your personal (and group's) research interests.\n\nConsider the following three research descriptions. Formulate H0 and H1 in words. Discuss your answers with your group members.\n\nResearchers want to know whether it matters for test performance if an exam is completed on a computer or using paper and pencil.\nHence, the research question reads: Is there an effect of the type of administration (computer or paper and pencil) on the test performance?\n\nWhat would be the H0 and HA for this study?\n\n\n<div class='webex-solution'><button>Show answer</button>\n\nThis appears to be an undirected hypothesis about a mean difference for two independent samples, without a clearly specified alternative hypothesis. Thus, we could state:\n\n$H_0: \\mu_{computer} = \\mu_{paper}$\n$H_A: \\mu_{computer} \\neq \\mu_{paper}$\n\n</div>\n\n\nResearchers want to know whether the alcohol consumption among Dutch students differs from the alcohol consumption in the general Dutch population. Using CBS statistics, they know that in the general population the average alcohol consumption is 5.6 glasses a week. The question is whether the average alcohol consumption among students is different from this national average.\n\nWhat would be the H0 and H1 for this study?\n\n\n<div class='webex-solution'><button>Show answer</button>\n\nThis appears to be an undirected hypothesis about the difference between a mean and a hypothesized value, without a clearly specified alternative hypothesis. Thus, we could state:\n\n$H_0: \\mu = 5.6$\n$H_A: \\mu \\neq 5.6$\n\n</div>\n\n\nResearchers want to study whether social isolation is associated with income.\n\nWhat would be the H0 and H1 for this study?\n\n\n<div class='webex-solution'><button>Show answer</button>\n\nThis appears to be an undirected hypothesis about an association between two variables, without a clearly specified alternative hypothesis. We could thus state:\n\n$H_0: \\rho = 0$\n$H_A: \\rho \\neq 0$\n\n</div>\n\n\nFormulating the hypothesis is an important very first step in hypotheses testing. Continue with the next assignment, in which we will go through the steps of a hypothesis test.\n\n## Assignment 2: Test Statistics, Alpha and Significance\n\nIn this assignment we will go through the steps of a hypothesis test.\n\nWhile going through the steps we will come across the most important concepts related to hypothesis testing.\n\nFor the next steps, we consider the following situation:\n\nSuppose we are interested in the personality profile of musicians; that is, we want to know whether, on average, personality characteristics of musicians differ from those of the general population. For now, we'll only focus on Openness. We pretend that we have collected data among 25 musicians using a validated scale for which previous research has shown that in the general population the scores are normally distributed with mean 50 and SD 15. It is our task to test whether the mean of Openness for musicians differs from the mean in the general population. To keep things simple, we assume that in the population of musicians the SD is the same as in the general population; that is, we assume that LaTeX: $\\sigma = 15$. \n\n\nLet openness be the variable of interest. Let $\\mu_{musicians}$ represent the mean openness in the population of musicians. The hypothesis test amounts to testing:\n\n$H0: \\mu_{musicians} = 50$\n\n$H1: \\mu_{musicians} \\neq 50$\n\nNow, when we do the hypothesis test, we seek for evidence against the null hypothesis. More specifically, our testing procedure starts with the assumption that H0 represents the truth and as long as we don’t have convincing evidence that our assumption is false we stick to that assumption.\n\nThe question is, however, when do we have convincing evidence against H0?\n\nFinding evidence against H0 works as follows:\n\nIf H0 is true, we expect mean values close to H0.\nAnd, if we observe a mean value that is much different from the value under H0, we have convincing evidence against H0. If this happens, we reject H0 as representing the truth and accept the alternative hypothesis, H1.\n\nHypothesis testing fits Popper’s philosophy of falsification. He introduced this well-known analogy to explain the logic of falsificationism:\n\n1. Suppose we assume that all Swans are white, $H_0: Swans = white$\n2. We would then not expect to observe black ones.\n3. If we do observe black swans, our initial hypothesis is called into question.\n4. The number of white swans we see (= observations consistent with the hypothesis) does not provide evidence for $H_0$, because there could always be a black swan out there we haven't observed yet.\n\nSo, the next questions are: \n\nWhat are the sample values we can expect under H0?\nWhen is evidence \"convincing\" enough? \nTo answer the first question we have to go back to sampling distributions!\n\nFor the second question, we need a criterion. We have to realize that even if H0 is true, sample values can be far off just by sampling fluctuations (i.e., by chance). The common criterion is: if the observed value is among the 5% most unlikely samples under H0 (i.e. if H0 is true), we reject the null hypothesis.\n\n\nLet's go back to our example about musicians.\n\nLet X be openness. Under H0 we assume that X is normally distributed with mean 50 and SD equal to 15. \n\nWhat are the mean and standard deviation of the sampling distribution of the mean under H0 given that the sample size is 25? And what do we call the standard deviation of the sampling distribution? \n\n(Use what you have learned in the previous lectures. Hint: first make a drawing of the situation, then do the computations).\n\n\n<div class='webex-solution'><button>Explanation</button>\n\nSampling distribution:\n\n- Mean: $\\mu = 50$\n- Standard error ( =SD of sampling distribution!): $\\sigma_{\\bar{X}} = \\frac{15}{\\sqrt{25}}= 3$\n\n\n</div>\n\n \nSuppose we want to indicate sample means that are unlikely if H0 would be true. In particular, we want to know how far the sample mean must be from the hypothesized mean to be among the 5% of all possible samples under H0 that are furthest away from the hypothesized means.\n\nWhat should the value of the sample mean be to fall within the 5% most deviant samples if the sample size is 25?\n\n\n<div class='webex-solution'><button>Explanation</button>\n\nWe are talking about the distribution of the mean; so we need to work with the sampling distribution. We want to know the cut offs that mark the 2.5% highest and 2.5% lowest means. We first have to find the Z-values: they are 1.96 for the highest 2.5%, and (by symmetry) -1.96 marks the 2.5% lowest.\n\nHence, to be among the 5% of all possible sample means that are most unlikely under H0, the sample mean should be:\n\nlarger than 50+1.96 x 3 = 55.88\nor smaller than 50-1.96 x 3 = 44.12\n \n\n</div>\n\n\nLet's do some more exercises on the Z-test.\n \nSuppose the mean for Openness we found in our sample was 59.\n\nIf we use a significance level of 5%, would we reject the null hypothesis? <select class='webex-select'><option value='blank'></option><option value='answer'>Yes</option><option value=''>No</option></select>\n\nIn the previous step we used cut offs for the sample means to decide about significance. The cut off scores were obtained via the Z-distribution. However, doing all these computations is not necessary (there's a shortcut!!). In fact, if we know the Z-value for the sample, we can easily find out if the sample is among the 5% of the most unlikely sample means. We only have to compare the value with 1.96 and -1.96 to see whether that is the case.\n\nIn this course, we will use Z-values for different purposes. In these specific calculations, Z is used as a *Test Statistic*. A test statistic quantifies evidence against the null hypothesis. In this case, the Z test statistic expresses how far away from the mean under the null hypothesis the observed mean is, in terms of the number of standard errors.\n\nThe Z test-statistic follows the standard normal distribution. The values 1.96 and -1.96 are called the critical values and they mark the 5% most unlikely sample means under H0. In other words, the critical values mark the reject region for H0. \n\nSo, if we compute the Z-value for the sample mean, and if that sample value of Z falls in the rejection region, we reject H0 (we found something that is unlikely enough to no longer believe H0 is true). If H0 is rejected we speak of a significant result. See the graph below:\n\n![](images/LAS_3_2_Graph-1-1.jpg)\n \nFollowing these steps to test a mean is one example of performing a *\"Z-test\"*!\n\nWe can use the Z-test to test hypotheses about the population mean if we know the population $\\sigma$.\n\nThe test statistic for the Z-test is:\n\n$z  = \\frac{\\bar{X}-\\mu_{H_0}}{\\sigma_{\\bar{X}}}$\n\n\nThis statistic is computed using the mean from the sample, the hypothesized mean under H0 and $\\sigma$.\n\nH0 is rejected at the 5% significance level if z is either larger than 1.96 or smaller than -1.96.\n\nSo far, we rejected the null hypothesis if the sample is among the 5% most unlikely sample means under H0. This 5% was called the significance level, and is denoted as $\\alpha = .05$. However, we could just as well choose 1% or .5%.\n\nWhat would be the critical values for the Z-test if one tests at $\\alpha = .01$? <input class='webex-solveme nospaces' data-tol='0.01' size='4' data-answer='[\"2.58\"]'/>\n\nWhat would be the critical values for the Z-test if one tests at $\\alpha = .005\\%$? <input class='webex-solveme nospaces' data-tol='0.01' size='4' data-answer='[\"2.81\"]'/>\n\nFor historical reasons, social scientists tend to use $\\alpha = 0.05$ as a default. So in this course, if alpha is not explicitly stated, assume $\\alpha = 0.05$.\n\n\nWhen we test hypotheses we reject H0 if the sample we find is unlikely if H0 is true. However, the flip side is that, even though H0 is true, we may find a sample that is much different by chance, and erroneously reject H0. Or, in other words, we could make an error. Rejecting H0 while it is true in reality is called a Type I error!\n\nConsider the following:\n\n1. If H0 is true, and you test at $\\alpha = 0.05$, what is the probability of committing a Type I error?\n2. What is the link between the $\\alpha$-level and type I error rate?\n\n\n<div class='webex-solution'><button>Explanation</button>\n\n1. If H0 is really true (i.e., H0 should not be rejected), then the probability that the sample mean is among the 5% most unlikely is equal to 5%. \n\n2. The alpha level specifies the risk of a Type I error. So if one tests at an alpha level of .05, it means that one accepts a risk of 5% to commit a Type I error. \n\n</div>\n\n \n\nProperties of the Z-test:\n\nUsed to test hypotheses about the mean in a population, assuming $\\sigma$ known.\n\nThe test-statistic equals $z = \\frac{\\bar{X}-\\mu}{\\sigma_{\\bar{X}}}$\n\nThe test statistic is normally distributed.\n\n## Assignment 3: Z-test\n\nIn this assignment we will apply the Z-test.\n\nThis assignment first presents an example, followed by two practice questions.\n\nA researcher wants to test $H_0: \\mu = 50$ against $H_1: \\mu \\neq 50$\n\nData are available from a random sample of 26 respondents. The mean was 53.7. The researcher assumes the SD in the population is 8.5. Perform all steps of the Z-test. \n\n\n<div class='webex-solution'><button>Explanation</button>\n\nStep 1: Formulate hypotheses\n\n$H_0: \\mu = 50$\n$H_1: \\mu \\neq 50$\n\nStep 2: Compute test statistic\n\nStandard error: $\\frac{8.5}{\\sqrt{26}}=1.667$\n\nTest statistic: $z = \\frac{53.7-50}{1.667}=2.212$\n\nStep 3: Decide about significance\n\n$\\alpha = .05$, so critical values +/- 1.96.\n\nOur test statistic exceeds this critical value.\n\nThe sample mean thus falls in the rejection region, and we should conclude that the test is significant so $H_0$ s rejected.\n\nStep 4: Draw conclusion\n\nWe have convincing evidence that the population mean differs from 50.\n \n\n</div>\n\n\nA researcher wants to test whether the population mean is equal to 80.\nData are available from a random sample of 60 respondents. The mean was 74. The researchers assume the SD in the population is 40. Perform and report all steps of the Z-test. What is the resulting p-value? <input class='webex-solveme nospaces' data-tol='0.01' size='4' data-answer='[\"0.12\",\".12\"]'/>\n\nA researcher wants to test whether the population mean is equal to 500. Data are available from a random sample of 75 respondents. The mean was 546. The researchers assume that the SD in the population is 200. Perform all steps of the Z-test. Use $\\alpha = .01$. Perform and report all steps.\n\n\n<div class='webex-solution'><button>Show answer</button>\n\n\nStep 1: Hypotheses: $H_0: \\mu=500$, $H_1: \\mu \\neq 500$\n\nstep 2: Compute Statistic: \n\n- standard error: $\\frac{200}{\\sqrt{75}} = 23.094$\n- test statistic: $z  = \\frac{546-500}{23.094}=1.992$\n\nStep 3: Decide about significance. \n\nZ does not exceed +/- 2.576. This means that Z does not fall in the reject region when tested at the 1% significance level. The test is not significant.\n\n\nStep 4: Draw conclusion\n\n$H_0$ is not rejected.\n\n</div>\n\n\n## Quiz\n\n::: {.webex-check .webex-box}\n\n\n\"The null and alternative hypothesis are deduced from the data.\" <select class='webex-select'><option value='blank'></option><option value='NA'>TRUE</option><option value='answer'>FALSE</option></select>\n\n\"When performing a hypothesis test, we start by assuming $H_0$ is true.\" <select class='webex-select'><option value='blank'></option><option value='answer'>TRUE</option><option value='NA'>FALSE</option></select>\n\n\"If we reject $H_0$ with $\\alpha=0.05$, then we will also reject it at $\\alpha=0.10$, assuming all other quantities are held constant.\" <select class='webex-select'><option value='blank'></option><option value='answer'>TRUE</option><option value='NA'>FALSE</option></select>\n\n\n<div class='webex-solution'><button>Explanation</button>\n\nThe critical values of $\\alpha =0.05$ are +/- 1.96. Hence, if $H_0$ is rejected it means that z in the sample is larger than 1.96 or smaller than -1.96.\"\n\nThe critical values of $\\alpha =0.1$ are +/- 1.645. This means that for rejecting $H_0$ at this alpha level, that z should be larger than 1.645 or smaller than -1.645. That is implied by the fact that it exceeds +/- 1.96.\n\n</div>\n\n\n\"If we reject $H_0$, then $H_0$ is surely wrong.\" <select class='webex-select'><option value='blank'></option><option value='NA'>TRUE</option><option value='answer'>FALSE</option></select>\n\n\n<div class='webex-solution'><button>Explanation</button>\n\nWe should always be aware of the possibility of making a Type I error.\nThe probability of making a Type I error is equal to $\\alpha$.\n\n</div>\n\n\n\"Increasing the sample size n (and holding all the rest constant) decreases the probability of a Type I error.\" <select class='webex-select'><option value='blank'></option><option value='NA'>TRUE</option><option value='answer'>FALSE</option></select>\n\n\n<div class='webex-solution'><button>Explanation</button>\n\nIncreasing the sample size n (and holding all the rest constant) does not decrease the probability of a Type I error.\n\nThe Type I error is determined by the alpha level.\n\nIf our sample is among the 5% most unlikely sample means of all possible sample means with the same size under $H_0$, whatever that sample size N may be.\n\nIncreasing the sample size n (and holding all the rest constant) does not decrease the probability of a Type I error.\n\n</div>\n\n\n:::\n\n## Assignment 4: Z-test and Alpha-levels\n\nIn this assignment we will practice some more with the Z-test, meanwhile we will review important concepts of hypothesis testing. In particular, we will look at significance levels.\n \nTo test hypotheses, we need to specify the \"significance level\", usually denoted by $\\alpha$. The significance level is our *decision criterion* to reject H0.\n\nThe most common choice is .05. But what does this criterion exactly entail?\n\n\nDiscuss with your group what an $\\alpha$ level entails.\n\n\n<div class='webex-solution'><button>Explanation</button>\n\nIf we test at an $\\alpha$ of .05 it means that we are willing to reject H0 in favor of H1 if our sample mean belongs to the 5% most extreme scores (2.5% in each tail) under the null hypothesis.\n\nIf indeed the sample mean is among this 5%, it means that we have observed a sample in a range that is quite unlikely if the null hypothesis would be true and, therefore, justifies rejection of the null hypothesis.\n\n</div>\n\n \n\nIn the previous assignments you already used the critical values for the Z-test for specific alpha levels.\n\nFor two-tailed tests, it holds that if the absolute value of Z exceeds the critical value, we may reject $H_0$.\n\nLet $Z_\\text{crit}$ be the critical value. For the Z-test it holds that:\n\n* $Z_\\text{crit} = 1.65$, if $\\alpha = 0.10$ (two-tailed)\n* $Z_\\text{crit} = 1.96$, if $\\alpha = 0.05$ (two-tailed)\n* $Z_\\text{crit} = 2.58$, if $\\alpha = 0.01$ (two-tailed)\n\n## Quiz\n\n::: {.webex-check .webex-box}\n\nResearchers want to test whether $\\mu=70$. They assume that $\\sigma = 10$. Researchers found a mean of 72 in a random sample of 40 persons.\n\nTrue or false:\n\n$H_0$ can be rejected at one of the three levels discussed above ($\\alpha = .10, .05, .01$. <select class='webex-select'><option value='blank'></option><option value='NA'>TRUE</option><option value='answer'>FALSE</option></select>\n\n\"If the two-tailed test is significant at the 5% level, it will also be significant at the 1% level (keeping everything else fixed).\" <select class='webex-select'><option value='blank'></option><option value='NA'>TRUE</option><option value='answer'>FALSE</option></select>\n\n\"If the two-tailed test is not significant at the 10% level, it won't be significant at the 5% level either (keeping everything else fixed).\" <select class='webex-select'><option value='blank'></option><option value='answer'>TRUE</option><option value='NA'>FALSE</option></select>\n\n\"If the two-tailed test is not significant at the 5% level, it could still be significant at the 10% level (keeping everything else fixed).\" <select class='webex-select'><option value='blank'></option><option value='answer'>TRUE</option><option value='NA'>FALSE</option></select>\n\n\"If the two-tailed test is significant at the 1% level, it might not be significant at the 5% level (keeping everything else fixed).\" <select class='webex-select'><option value='blank'></option><option value='NA'>TRUE</option><option value='answer'>FALSE</option></select>\n\n:::\n\n\n## Assignment 5: P-values\n\nWe will now focus on the interpretation of the p-values and how to use the p-values to decide about significance. \n \nConsider the following situation:\n\nScores on a test measuring confidence in police are normally distributed in the general population, with $\\mu = 500$ and an $\\sigma = 50$. Researchers want to know if the average confidence level is different for those who have been a victim of crime. They collect data for 60 victims. They find a sample mean of 511. They test $H_0: \\mu = 500$ against $H_1: \\mu \\neq 500$, while assuming that the population variance is $\\sigma = 50$.\n\nCompute the p-value. Draw a graph for the two-tailed p-value. Write down in your own words and as precise as possible the interpretation of the p-value in the answer box below. Then, discuss your response with your group.\n\n\n<div class='webex-solution'><button>Explanation</button>\n\n\n- The p-value represents the proportion of all possible sample means that are further away from our hypothesized mean than the observed sample mean is. \n- We have the sampling distribution with $\\mu = 500$ and $\\sigma_{\\bar{X}} = \\frac{50}{\\sqrt{60}} = 6.455$.\n- First, we compute the right-tail area: $P(\\bar{X} > 511) = P(Z > 1.70) = 0.0446$.\n- Hence, 4.66% of all possible samples is further away from $H_0$ on the right side. \n- Second, we compute the left-tail area. These are the sample means that are more than 11 points from the hypothesized mean to the left $P(\\bar{X} < 489) = P(Z < -1.70) = 0.0446$. \n- Hence, the two-tailed p-value is 0.0892.\n\n</div>\n\n\nIs the test significant at the 5% level? <select class='webex-select'><option value='blank'></option><option value='NA'>TRUE</option><option value='answer'>FALSE</option></select>\n\nIs it significant at the 1% level? <select class='webex-select'><option value='blank'></option><option value='NA'>TRUE</option><option value='answer'>FALSE</option></select>\n\n\nResearchers test whether $\\mu = 90$. They assume that $\\sigma=21$. The sample mean was 85. Sample size was 50.\n\nWhat is the two-tailed p-value? <input class='webex-solveme nospaces' data-tol='0.01' size='4' data-answer='[\"0.09\",\".09\"]'/>\n\nWhat is the highest level at which the test is significant? <select class='webex-select'><option value='blank'></option><option value=''>0.01</option><option value=''>0.1</option><option value=''>0.005</option><option value='answer'>0.05</option></select>\n\n\nResearchers test whether $\\mu = 35$. They assume $\\sigma =16$. The sample mean was 38. Sample size was 64.\n\nCompute the two-tailed p-value and indicate which of the following statements is true.\n\n<div class='webex-radiogroup' id='radio_AFCRMVMIHS'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_AFCRMVMIHS\" value=\"answer\"></input> <span>The test is not significant at 10%, not significant at 5% and not significant at 1%.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_AFCRMVMIHS\" value=\"\"></input> <span>The test is significant at the 10% level, but not at 5% or 1% level.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_AFCRMVMIHS\" value=\"\"></input> <span>The test is significant at the 10% and 5% level, but not at the 1% level.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_AFCRMVMIHS\" value=\"\"></input> <span>The test is significant at the 10%, 5% level, and 1% level.</span></label></div>\n\n\nConsider these true- or false statements:\n\nIf a two-tailed p-value is .0567 then the test is significant at the 10% level but not at the 5% level. <select class='webex-select'><option value='blank'></option><option value='answer'>TRUE</option><option value='NA'>FALSE</option></select>\n\nIf a two-tailed test is significant at the 5% level but not at the 1% level, then the two-tailed p-value will be less than 0.01. <select class='webex-select'><option value='blank'></option><option value='NA'>TRUE</option><option value='answer'>FALSE</option></select>\n\nA two-tailed p-value of 0.060 indicates that we have 6% chance that the null hypothesis is true.  <select class='webex-select'><option value='blank'></option><option value='NA'>TRUE</option><option value='answer'>FALSE</option></select>\n",
    "supporting": [
      "week_4_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}