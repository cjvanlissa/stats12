# Lab 1: Introduction

```{r, include = FALSE}
source("R/booktem_setup.R")
source("R/my_setup.R")
```

## Introduction to Statistics (RECAP)

Today, we will work with a data set on nerdy personality types. For this study, participants completed a survey on how nerdy their personality was and what their general personality was like. Finally, they had to answer some general questions.

Open the data set: [`Nerdy.sav`](data/Nerdy.sav)
 

Researchers are interested in the following research question: “An average, do people consider themselves to be nerdy?”

We have to carry out a one sample t-test to answer this question.

Navigate to Analyze -> Compare means -> One sample T Test
Select the variable Nerdy
Insert the test value 4 (We use 4 as test value because this was the neutral option for the item “I consider myself as nerdy”)
Make sure that the 95% confidence interval is selected
Paste and run the syntax
 

True or false: On the sample level, people on average consider themselves to be nerdy. `r torf(TRUE)`


`r hide("Explanation")`
The sample mean (5.46) is higher than the neutral mid-point of the scale (4; which is also the test value), meaning that, on the sample level, people on average consider themselves to be nerdy.
`r unhide()`
 


The next thing we would like to test is whether this finding is significant; in other words - is the observed sample mean consistent with a population mean of 4?

Report:

* The null hypothesis and alternative hypothesis
* The sample results
* The t-value and p-value
* The conclusion of this test

`r hide("Explanation")`

$H_0: \mu = 4$

$H_1: \mu \ne 4$

The sample mean of 5.46 differs significantly from the hypothesized mean of 4, t(2520) = 50.933, p < .001.

`r unhide()`

Now take a look at the 95% confidence interval. As you might recall from the lectures, SPSS does not give us the confidence interval around the sample mean.

What is the lower bound of the confidence interval *around the sample mean*? `r fitb(5.4, num = T, tol = .02)`

What is the correct upper bound? `r fitb(5.51, num = T, tol = .01)`


 
Imagine that you would ask for a 99% confidence interval instead of a 95% confidence interval. What do you think happens to the width of the interval? `r mcq(c(answer = "The interval becomes wider" , "The interval becomes smaller", "The interval remains the same")[sample.int(3)])`

Next, we will run an independent samples t-test to see whether men and women differ in nerdiness.

Navigate to Analyze -> Independent-samples T Test

Insert the dependent variable Nerdy

Use Dgen as the grouping variable (this is the dummy variable for gender)

Click on Define groups and enter the values 0 and 1

Go to Options and ensure that you ask for the 95% confidence interval

Paste and run the syntax
 

Take a look at the 95% confidence interval. The boundaries are calculated around the mean difference. Explain in your own words what this mean difference entails.

`r hide("Answer")`

The mean difference in an independent samples t-test is the difference in sample means between the two groups (in this case men and women).

In our sample we see that women score somewhat higher on nerdiness than men. As a result, the mean difference is negative (X difference = −0.026).

`r unhide()`

We want to test whether this difference is significantly greater than zero significance.

Instead of looking at the p-value, however, we now want to use the confidence interval to conclude whether we are allowed to reject the null hypothesis.

To start with, write down the null hypothesis and alternative hypothesis.


`r hide("Answer")`

We can write the null and alternative hypothesis in two ways.

Either:

$H_0: \mu_{men} = \mu_{woman}$

$H_1: \mu_{men} \ne \mu_{woman}$

Or:


$H_0: \mu_{men} - \mu_{woman} = 0$

$H_1: \mu_{men}- \mu_{woman} \ne 0$

`r unhide()`
 


How can we use the 95% interval to carry out a (two-tailed) significance test?

`r hide("Explanation")`

If we want to do a significance test using the confidence interval, we have the check whether the confidence interval contains the null hypothesis test value.

If it does, there is no significant difference.
If it does not, there is a significant difference.

`r unhide()` 

True or false: We reject the null hypothesis. `r torf(FALSE)`

`r hide("Explanation")`

In this case, the 95% confidence interval contains 0. Hence, we should conclude that there is no significant difference between nerdiness between men and women.

`r unhide()`

## MRA (RECAP)

Let’s recap multiple regression analysis using the Nerdy.sav dataset.

 
Researchers want to know whether academic interest can be predicted by several independent variables. They start off with a simple question: “Is there an effect of gender on academic interest?”

Write down the general model and the hypotheses that we want to test.

`r hide("Explanation")`

Additional explanation:

Y’Academic interest = b0 + b1 * Gender

$H_0: b_{gender} = 0$

$H_1: b_{gender} \ne 0$

`r unhide()`

Let’s carry out a simple linear regression analysis.

Navigate to Analyze --> Regression --> Linear

Insert Academic_interest as dependent variable and Dgen as independent variable.

Go to Statistics and ask for the 95% confidence interval

Paste and run the syntax.

**Important:** Note that this model, with only Dgen as predictor, is completely equivalent to an independent samples t-test (as you conducted in the previous assignment). If you want, you could verify this by also using the Independent Samples t-test interface with the dependent variable Academic_interest.

 

Take a look at the 95% confidence interval.

True or false: There is a significant effect of gender on academic interest. `r torf(TRUE)`



What percentage of the variance in academic interest can be explained by gender? `r fitb(3.3, num = T, tol = .1)`%

 
Now we will move on with a hierarchical regression analysis.

In steps, we will add the variables Gender, Autism, Nerdiness and several personality variables.

Navigate to Analyze --> Regression --> Linear

Keep Academic_interest as DV and Gender as IV. Click on Next.

You arrive at Block 2. Here you can enter the variable you want to add in the second model. Insert the variable Daut. Click on Next.

You arrive at Block 3. Insert the variable Nerdy. Click on Next.

You arrive at Block 4. Insert the variables TIPI1, TIPI2, TIPI5, and TIPI8.

Go to Statistics. Ask for R square change.

Paste and run the syntax.
 
What is the most complex model that still explains significantly more variance than those nested within it? `r mcq(c("Model 1", "Model 2", "Model 3", answer = "Model 4"))`

`r hide("Explanation")`
Every subsequent model explains significantly more variance than the previous model. Hence, Model 4 is the best model (explaining the most variance with the least number of variables possible).

`r unhide()`

How much variance does Model 3 explain on top of what is already explained by Model 2? `r fitb(21.6, num = T, tol = .1)`%
 


Why is df1 of model 3 equal to 1? And why is df1 of model 4 equal to 4?

`r hide("Answer")`

From Model 2 to Model 3 we included 1 additional variable, resulting in df = 1.

From Model 3 to Model 4 we included 4 additional variables, resulting in df = 4.

`r unhide()`

Take a look at the regression coefficients of Model 4 in the table Coefficients.

What is the estimated regression coefficient of the variable Nerdy?
 `r fitb(1.423, num = T, tol = .01)`
 
Write down as precise as possible, the correct interpretation of this estimated regression coefficient.

`r hide("Explanation")`
With every unit increase in the variable Nerdy, the predicted score for Academic interest increases with 1.423.
 
`r unhide()`

Take a look at the confidence intervals of the estimated coefficients.

Using confidence intervals, which variables do not have a significant effect on academic interest controlled for the other variables in the model?

`r mcq(c(answer = "Disorganized, Open",
"Autism, Extraverted", 
"Gender, Nerdy, Critical",
"Constant")[sample.int(4)])` 
  
  
  
## Confidence Intervals

In this assignment we will work on some questions regarding the confidence interval. We focus on the confidence interval around the mean, but everything you learn can also be applied to confidence intervals around the mean difference or regression coefficients.

Finish the following sentence. The confidence interval around the mean is constructed around the `r mcq(c(answer =  "Sample mean", "Population mean (under H0)")[sample.int(2)])`


In the population the variable IQ is normally distributed with $IQ \sim N(\mu=100, \sigma=15$.

Imagine that we drew 2000 samples from the population. For each of the samples we would calculate a 90% confidence interval around the sample mean. If you had to make a guess, how many intervals would you expect to contain the value 100? `r fitb(1800, num = T)`


Imagine we drew a sample from the population and we calculated the 95% confidence interval around the sample mean for a particular variable. The lower bound of the confidence interval is equal to 85 and the upper bound to 95.

Which of the following statements is correct?

`r longmcq(c(answer = 
  "There is a 95% probability that a confidence interval calculated based on a sample from this population contains the true population value.",
  "There is a 95% probability that if we would draw a new sample for the same population, the true population value lies between 85 and 95.",
  "The probability that the population mean lies between 85 and 95 is 95%.",
  "There is a 95% probability that the population mean lies between 85 and 95.")[sample.int(4)])`
 

Confidence intervals are interpreted in terms of long-run probability. IF we could draw a huge number of samples from the population, 95% of those samples would provide a confidence interval that contains the population mean. 


We can never know whether one specific confidence interval contains the population value, however.

So we can NEVER draw a conclusion like "there is a 95% probability that the population mean lies between 85 and 95".

Recall the first lecture, in which I explained the idea of a "random experiment". Think of a 95% confidence interval as a random experiment with a 95% probability of containing the population value. One specific confidence interval is **not** a random experiment.
Whether the population mean lies within the interval is not a matter of probability. It either does or it does not. We just don’t know which of these is true. 


Imagine a population with variable X, where $X \sim N(\mu 50, \sigma = 10)$

Assume a confidence level of 95% for all intervals.

If you draw a sample with $n=20$ and compute a 95% confidence interval, what's the probability that this interval will contain 50? `r fitb(95, num = T)`%

Your colleague has drawn a sample of $n=20$. What's the probability that this sample contains 50? `r mcq(c("0%", "100%", "95%", "Can't say")[sample.int(4))`


If you would draw 20 samples, how many samples would you expect the confidence interval to contain the value 50? `r fitb(19, num = T)`

True or false: if you draw 100 samples, 95 of them will provide a confidence interval that contains the population value. `r torf(FALSE)`

`r hide("Explanation")`
This is false because the phrase "will provide" is not a probability statements, but a deterministic one.

"The number of 95% confidence intervals out of 100 samples that contain the population value" is a random experiment. We expect an outcome of 95, but if we conduct this random experiment, the observed outcome may differ a little.

`r unhide()`

 
All else being equal, what would you expect to happen to the confidence intervals of smaller samples? `r mcq(c("They stay the same", "They become wider", "They become narrower")[sample.int(3))`



`r hide("Explanation")`
By increasing the sample size, our estimate becomes more precise. This will lead to more narrow confidence intervals.

Mathematically it also makes sense, because the confidence interval is based on the standard error. Remember that the formula for the standard error is $SE = \frac{\sigma}{n}$ . A smaller sample size leads to a smaller standard error, which leads to a narrower interval.

Note that this does affect the probability of confidence intervals containing $\mu$.
`r unhide()`

If the standard deviation increases (and everything else stays the same) the confidence interval will `r mcq(c(answer = "become wider", "become narrower", "stay the same")[sample.int(3)])`.
 
If we change the confidence level to 90%, the interval will `r mcq(c("become wider",answer = "become narrower", "stay the same")[sample.int(3)])` and `r mcq(c("more",answer = "fewer", "the same number of")[sample.int(3)])` intervals will contain $\mu$.
