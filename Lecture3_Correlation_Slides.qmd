---
title: "Bivariate Descriptive Statistics: Correlation"
author:   "Caspar J. van Lissa"
date:     "`r format(Sys.Date(), '%d %b %Y')`"
format: revealjs
---
```{r}
library(kableExtra)

library(ggplot2)
options(knitr.kable.NA = '')
set.seed(1)
```


## Recap & Roadmap

* Previously: **Univariate statistics**
* Today: First **bivariate statistics**

  * Covariance
  * Correlation

---

## Motivation

* Variance: tells us how scores deviate from the mean.
* Covariance: do deviations on one variable go with deviations on another?
* Correlation: strength & direction of association.

---

## Example: Two Variables

* We'll use *X* and *Y*
    + *X = hours studied*, *Y = grade*
    + *X = extraversion*, *Y = number of friends*

---

## Example {.smaller}

High X associated with high Y:

| Person | X (Hours studied) | Y (Quiz score) |
|-------:|------------------:|---------------:|
| 1 | 2 | 4 |
| 2 | 4 | 6 |
| 3 | 6 | 8 |

High X associated with low Y:

| Person | X | Y |
|-------:|--:|-------------:|
| 1 | 2 | 8 |
| 2 | 4 | 6 |
| 3 | 6 | 4 |



---


## Scatterplots

* **Visual inspection** is crucial.
* Each dot represents the (X, Y) observations for one participant.

```{r}
df <- data.frame(X = c(2,4,6), Y = c(4, 6, 8))
p1 <- ggplot(df, aes(x = X, y = Y)) + geom_point(shape = 21, size = 3, fill = "orange") + theme_minimal()
df2 <- df
df2$Y <- rev(df2$Y)
p2 <- ggplot(df2, aes(x = X, y = Y)) + geom_point(shape = 21, size = 3, fill = "orange") + theme_minimal()

ggpubr::ggarrange(p1, p2, ncol = 2, nrow = 2, labels = "auto")
```

<!-- When X and Y increase together, we can imagine a diagonal line going upward in the data. -->

<!-- When an increase in X is associated with a decrease in Y, we can imagine a diagonal line going downward. -->

---


## Interpreting a Scatter Plot

1. **Direction** – *Positive* slopes upward; *Negative* slopes downward  
2. **Form** – Pattern must be linear for the measures of association we discuss today
3. **Strength** – Tightness of points around an imaginary diagonal line  

---


## Measuring association: Sum of Products

* **Analogy with SS** – SS measures variability of one variable; SP measures how two variables vary together (co-vary).
* **Sign of SP:** Positive: same-direction changes; Negative: opposite-direction changes.

---

### SP Formula {.smaller}


$$
SP = \sum \bigl(X - \bar{X}\bigr)\bigl(Y - \bar{Y}\bigr)
$$

---

## SP - Steps

1. Calculate Means
2. Deviations from Means
3. Multiply Deviations
4. Sum the products of deviations

---

## SP - Numerical Example

<font size = 4>

| X | Y |
|---|---|
| 1 | 2 |
| 2 | 1 |
| 3 | 3 |
| 4 | 5 |
| 5 | 4 |

Means: $\bar X = 3$, $\bar Y = 3$

| $X$ | $Y$ | $X-\bar X$ | $Y-\bar Y$ | $(X-\bar X)(Y-\bar Y)$ | $(X-\bar X)^{2}$ | $(Y-\bar Y)^{2}$ |
|----:|----:|-----------:|-----------:|-----------------------:|-----------------:|-----------------:|
| 1 | 2 | –2 | –1 | 2 | 4 | 1 |
| 2 | 1 | –1 | –2 | 2 | 1 | 4 |
| 3 | 3 | 0  | 0  | 0 | 0 | 0 |
| 4 | 5 | 1  | 2  | 2 | 1 | 4 |
| 5 | 4 | 2  | 1  | 2 | 4 | 1 |
| **Totals** |   |   |   | **SP = 8** | **$SS_X = 10$** | **$SS_Y = 10$** |

</font>

---



## SP - interpretation

* **Sign only**:  
  *Positive* → higher-than-average X accompanies higher-than-average Y  
  *Negative* → higher-than-average X accompanies lower-than-average Y  

---

## SP and Covariance

We can standardize the SP by number of participants $n$

This gives us the **covariance**: average SP

$$
\frac{SP}{n}
$$

* Still tells us direction (+/-) but not strength

---

## Covariance - Interpretation

* **Sign only**:  
  *Positive* → higher-than-average X accompanies higher-than-average Y  
  *Negative* → higher-than-average X accompanies lower-than-average Y  
* **Magnitude tied to units** (e.g., cm * kg), not comparable across studies

---

## Pearson's Correlation Coefficient


* Standardized version of covariance (drop units)
* Bounded between -1 and +1
* +1: perfect positive linear relationship
* 0: no linear relationship
* -1: perfect negative linear relationship

---


## Pearson *r* - Formula {.smaller}

From covariance:

$$
r = \frac{Cov(x,y)}{\sigma_x \sigma_y}
$$

From SP (neither numerator nor denominator standardized by $n$:

$$
r = \frac{SP}{\sqrt{SS_{X}\,SS_{Y}}}
$$

Conceptual formula:

$$
r
   = \frac{\text{raw association between } X \text{ and } Y}
          {\text{amount and units of variability in } X \text{ and } Y}
$$

---


## SP - Numerical Example

<font size = 4>

| X | Y |
|---|---|
| 1 | 2 |
| 2 | 1 |
| 3 | 3 |
| 4 | 5 |
| 5 | 4 |

Means: $\bar X = 3$, $\bar Y = 3$

| $X$ | $Y$ | $X-\bar X$ | $Y-\bar Y$ | $(X-\bar X)(Y-\bar Y)$ | $(X-\bar X)^{2}$ | $(Y-\bar Y)^{2}$ |
|----:|----:|-----------:|-----------:|-----------------------:|-----------------:|-----------------:|
| 1 | 2 | –2 | –1 | 2 | 4 | 1 |
| 2 | 1 | –1 | –2 | 2 | 1 | 4 |
| 3 | 3 | 0  | 0  | 0 | 0 | 0 |
| 4 | 5 | 1  | 2  | 2 | 1 | 4 |
| 5 | 4 | 2  | 1  | 2 | 4 | 1 |
| **Totals** |   |   |   | **SP = 8** | **$SS_X = 10$** | **$SS_Y = 10$** |

</font>

---

## Computing **r**

* $SS_{X} = \sum (X - \bar{X})^{2}$ (single-variable variability for X)  
* $SS_{Y} = \sum (Y - \bar{Y})^{2}$ (single-variable variability for Y)

---

## Numerical Example — Compute *r* {.smaller}

$$
r \;=\; \frac{8}{\sqrt{10 \times 10}} \;=\; 0.80
$$

Interpretation (Cohen, 1988):

```{r}
knitr::kable(
  data.frame("Effect size" = c("Negligible", "Small", "Medium", "Large"),
             Value = c("[0, .10]" ,"[.10, .30)", "[.30. .50)", "[.50, 1.00]"), check.names = FALSE)
)
```


---


## Limitations of *r*

* Only reflects **linear** patterns
* **Outliers** can distort it
* **Restricted range** may hide real effects
* **Correlation does not imply Causation**
    + Just because X correlates with Y does not mean X caused Y
    + You can ASSUME that X causes Y, and observing correlation is consistent with that assumption

<!-- https://youtu.be/JyoefJ68T5I?si=VamyyAeB51H8tXMF -->

---

## Anscombe’s Quartet

```{r fig-anscombe, fig.cap="Anscombe's quartet"}
plts <- lapply(1:4, function(i){
  df <- anscombe[, paste0(c("x", "y"), i)]
  names(df) <- c("X", "Y")
  ggplot(df, aes(x = X, y = Y)) + geom_point(shape = 21, size = 3, fill = "orange") + theme_linedraw()
})
ggpubr::ggarrange(plotlist = plts, ncol = 2, nrow = 2, labels = "auto")
```

---

## Interpretation: Anscombe

All four have *r = 0.82*

a. meets the assumption of linearity
b. non-linear perfect association
c. perfect association, diluted by one outlier
d. no association (X is constant, not a variable), distorted by one outlier

---

## Restricted Range Example

```{r fig-nonlin}
df <- anscombe[, paste0(c("x", "y"), 2)]
names(df) <- c("X", "Y")
p1 <- ggplot(df[df$X <= 9, ], aes(x = X, y = Y)) + geom_point(shape = 21, size = 3, fill = "orange") + theme_linedraw() + geom_smooth(method = "lm", se = FALSE)
p2 <- ggplot(df[df$X > 9 & df$X < 13, ], aes(x = X, y = Y)) + geom_point(shape = 21, size = 3, fill = "orange") + theme_linedraw() + geom_smooth(method = "lm", se = FALSE)
p3 <- ggplot(df[df$X >= 13, ], aes(x = X, y = Y)) + geom_point(shape = 21, size = 3, fill = "orange") + theme_linedraw() + geom_smooth(method = "lm", se = FALSE)
ggpubr::ggarrange(p1, p2, p3, ncol = 3, nrow = 1, labels = "auto")
```

---

## Visual Inspection

* Always **inspect your data**
* Use scatter plots
* Don’t trust summary statistics blindly; if assumptions are violated, they can be misleading

---

## Summary

* **SP**: Intermediate in the calculation of covariance
* **Covariance**: direction of relationship
* **Correlation (*r*)**: direction + strength (unit-free)
* Limitations:
    + Only linear patterns
    + Sensitive to outliers
    + Restricted range
    + Correlation does not imply causation

---
