# Lab 1: Introduction

```{r, include = FALSE}
source("R/booktem_setup.R")
source("R/my_setup.R")
```



<!-- x = factor(df$x) -->
<!-- frequencies <- table(x) -->
<!-- n.cat       <- length(table(x)) -->
<!-- omitted <- 4 -->
<!-- omitted         <- which(levels(x) == omitted) -->

<!-- new.contrasts <- contr.treatment(n.cat, base=omitted) -->
<!-- new.contrasts[omitted,] <- -1 * frequencies[-omitted] / frequencies[omitted] -->

<!-- colnames(new.contrasts) <- names(frequencies[-omitted]) -->
<!-- contrasts(x) <- new.contrasts -->
<!-- summary(lm(df$y ~x)) -->



## Group Means

In this tutorial, you will learn to use the general linear model to estimate means and to test the difference between two group means, the difference between individual group means and the overall mean, and between groups of means.

Open hiking_long.sav in SPSS.

The data file describes the result of a fictitious experiment. A hiking guide has displayed five different types of behavior towards different groups of hikers. The treatment that each person received from the guide is recorded in the variable `behavior`.

The dependent variable of this experiment is `feeling`. Higher scores on this variable indicate a more positive attitude of a participant towards the guide. In this assignment, we will use ANOVA to determine whether the mean score on the dependent variable differs between the five experimental conditions.

 
The data file contains a third variable named `weather` which can be either good or bad. For now, we will only look at the results obtained during good weather. Hence, we will use “Select cases” to select only those participants with a value of 1 on the weather variable.

Additionally, the data contains a variable named `balanced` which distinguishes between data resulting from a balanced experiment (with equal sample sizes in all groups), and from an unbalanced experiment (with unequal group sizes). For now, just ignore this variable.

Click Data > Select Cases and select “If condition is satisfied” and click the “If”-button. Now enter the following condition into the equation box:

`weather = 1`

Now click “Continue” and “Paste” to paste the resulting syntax into the syntax editor. Select Run > All to run it. You should now see in the Data View tab that half of the participants have been crossed out.

 
First, let's compute the overall mean of feeling and tabulate the group means.

What is the overall mean of feeling? `r fitb(5.4564, num = T, tol = .01)`

What are the group means:

* What is the mean of the rushing group? `r fitb(5.29, num = T, tol = .01)`
* What is the mean of the stories group? `r fitb(5.95, num = T, tol = .01)`
* What is the mean of the insulting group? `r fitb(4.81, num = T, tol = .01)`

`r hide("Answer")`
To get the mean of feeling, use Analyze -> Descriptive Statistics -> Descriptives.

To get the group means, use Analyze -> Compare Means -> Means

```
DESCRIPTIVES VARIABLES=feeling 
  /STATISTICS=MEAN STDDEV MIN MAX.
  
MEANS TABLES=feeling BY behavior
  /CELLS=MEAN COUNT STDDEV.
```

`r unhide()`

You have previously learned to include categorical variables in a linear model by using dummy coding. Today, we will build upon this principle of encoding the information from a categorical variable into several numerical variables.

First, recall that a linear model with a five-group nominal predictor can be written as follows:

$\hat{Y} = b_0 + b_1*D_1 + b_2*D_2 + b_3*D_3 + b_4*D_4$

What is $b_0$ in this equation?

`r longmcq(c(answer = "The intercept; it is the mean of the reference category.", "The slope of the reference category.", "The overall sample mean.",
"The average of the group means")[sample.int(4)])` 

To estimate the model above using regression, you could code dummy variables as follows:

behavior | D1 | D2 | D3 | D4
---------|----|----|----|----
rushing | 1 | 0 | 0 | 0
telling stories | 0 | 1 | 0 | 0
insulting | 0 | 0 | 1 | 0
making jokes | 0 | 0 | 0 | 1

What is the reference category in the coding scheme above? `r mcq(c(answer = "singing", "rushing", "jokes", "none")[sample.int(4)])`

Specify the dummies as described in the table, and estimate the model.

`r hide("Answer")`
To get the mean of feeling, use Analyze -> Descriptive Statistics -> Descriptives.

To get the group means, use Analyze -> Compare Means -> Means

```
RECODE behavior (1=1) (2=0) (3=0) (4=0) (5=0) INTO rushing.
RECODE behavior (1=0) (2=1) (3=0) (4=0) (5=0) INTO stories.
RECODE behavior (1=0) (2=0) (3=1) (4=0) (5=0) INTO insulting.
RECODE behavior (1=0) (2=0) (3=0) (4=1) (5=0) INTO jokes.
EXECUTE.

  
REGRESSION
  /MISSING LISTWISE
  /STATISTICS COEFF OUTS R ANOVA
  /CRITERIA=PIN(.05) POUT(.10)
  /NOORIGIN 
  /DEPENDENT feeling
  /METHOD=ENTER rushing stories insulting jokes.
```

`r unhide()`

What's the value of the intercept? `r fitb(5.65, num = T, tol = .01)`

In this analysis, the intercept is the mean value on feeling for the reference category (singing). Verify that this is true by comparing the intercept of this regression to the Means table you made previously.

What is the value of the coefficient for `stories`? `r fitb(.294, num = T, tol = .01)`

How can we interpret this coefficient?

`r longmcq(c(answer = "The difference between the mean of the singing group and the mean of the stories group.", "The mean of the stories group.")[sample.int(2)])` 

## Contrasts

As we've previously established, dummy variables allow us to test the significance of mean differences between one reference group and all other groups.

Now, imagine we expect rushing to have a negative effect on behavior, and we want to know which other behaviors are "better" (i.e., result in a higher score on behavior) than rushing. 

Specify your hypotheses, then check your answer.


`r hide("Answer")`

$H_0: \mu_{rushing} \leq (\mu_{stories}, \mu_{insulting}, \mu_{joking}, \mu_{singing})$

$H_1: \mu_{rushing} < (\mu_{stories}, \mu_{insulting}, \mu_{joking}, \mu_{singing})$

`r unhide()`

Use dummy variables to test this hypothesis. Note: you will need to specify one additional dummy.


`r hide("Answer")`

```
REGRESSION
  /MISSING LISTWISE
  /STATISTICS COEFF OUTS R ANOVA
  /CRITERIA=PIN(.05) POUT(.10)
  /NOORIGIN 
  /DEPENDENT feeling
  /METHOD=ENTER stories insulting jokes singing.
```

`r unhide()`

What is the $R^2$ of this model? `r fitb(.11, num = T, tol = .01)`

Compare this to the $R^2$ of your previous model. They should be identical, as should be the overall F-test and p-values. Changing the reference category doesn't change what information the dummies convey.

Do we perform one-sided or two sided tests? `r mcq(c(answer="one-sided", "two-sided"))`

Use this information to test your hypotheses.

Which behaviors are "better" than rushing?

`r longmcq(c(answer = "stories", "stories and insulting", "all behaviors", "no behaviors")[sample.int(4)])` 

You can use this technique any time you want to test the significance of the difference between one reference group and other groups.

Note that, in the first assignment, we used a different set of dummy variables than in the second assignment. This means that you can always use different sets of dummy variables when want to compare against multiple reference groups.

## Estimating group means

In the first assignment, we computed the group means. But remember that the ANOVA model allows us to estimate them using the general linear model. In this assignment, we will do so by hand. After the previous assignment, you should have five dummy variables to represent the five groups of `behavior`.

Until now, you've always included four dummy variables to represent five categories, as the last category is represented by the intercept.

However, it is also possible to represent five groups as follows:

$\hat{Y} = b_1*D_1 + b_2*D_2 + b_3*D_3 + b_4*D_4 + b_5*D_5$

What is $b_5$ in this equation?

`r longmcq(c(answer = "The intercept; it is the mean of the reference category.", "The slope of the reference category.", "The overall sample mean.",
"The mean value of group 5")[sample.int(4)])` 

To estimate the model above using regression, you could code dummy variables as follows (note that you should already have all these dummies from the previous assignment):

behavior | D1 | D2 | D3 | D4 | D5
---------|----|----|----|----|----
rushing | 1 | 0 | 0 | 0| 0
telling stories | 0 | 1 | 0 | 0| 0
insulting | 0 | 0 | 1 | 0| 0
making jokes | 0 | 0 | 0 | 1 | 0
singing | 0 | 0 | 0 | 0 | 1

Now, go to Analyze -> Regression -> Linear, and add **all five** dummies as predictors.

Then, click the Options button, and notice the option titled "Include Constant in Equation".

Turn this option off to remove the intercept from the regression equation, then paste your syntax. Notice a new line that says `/ORIGIN` instead of `/NOORIGIN`. This command removes the intercept.

Run your syntax, and examine the results.

You might notice that the $R^2$ and F-test changed. This is because these are computed relative to a null-model with only the intercept - but you told SPSS not to include an intercept, so it can't compute that null model here. It's not a big deal. As soon as you estimate models with an intercept again, the $R^2$s will be identical again, regardless of the dummy coding.

What's the value of the dummy for singing? `r fitb(5.65, num = T, tol = .01)`

Compare all coefficients to the table of means from the first assignment. They should all be identical.

This is how you estimate means using the linear model!

Now, what do the t-tests and p-values in the Coefficients table tell us?

`r longmcq(c(answer = "Whether the means are significantly different from zero.", "Whether the means are significantly different from the reference category.", "Whether the means are significantly different from each other.", "They are not meaningful.")[sample.int(4)])` 

Keep in mind that you can use the standard errors from the coefficients table to perform t-tests against other values than 0; for example, what would the test statistic be when testing whether the mean of the insulting group is significantly different from 5, so $H_0: \mu_{insulting} = 5$? t = `r fitb(-.842, num = T, tol = .01)`

Is the difference significant? `r mcq(c("Yes", answer = "No"))`

You can use regression without an intercept any time you wish to estimate *all* group means in a single analysis and/or test the group means against specific hypothesized values.

## Comparing to Overall Mean

Until now, we've represented levels of a categorical variable using *dummy variables* with values 0 or 1.

In this assignment, we introduce an alternative coding system: *effects coding*.

The main difference with dummy coding is that the reference category does not receive 0 values on all indicator variables, but instead, receives a negative value. In a balanced design (with equal sizes for each group), this value is -1.

So in a balanced design, with equal group sizes, the coding scheme for effects coding is (I now use the letters E1-E4 to clarify that these are not dummies but effect coded indicators):

behavior | E1 | E2 | E3 | E4
---------|----|----|----|----
rushing | 1 | 0 | 0 | 0
telling stories | 0 | 1 | 0 | 0
insulting | 0 | 0 | 1 | 0
making jokes | 0 | 0 | 0 | 1
singing | -1 | -1 | -1 | -1

The reference category is still "singing".

The resulting model will give us the following information:

* The overall sample mean for feeling
* The difference between each group mean, except for singing, compared to the overall mean

Most of the time, however, we will **not** have balanced designs. With this in mind, it is more useful to learn the general way to construct effect coding.

Specifically, the weights assigned for the singing category (reference category) differ for each dummy, and are computed as:

$-1 * n_{\text{this category}} / n_{\text{reference category}}$

Check the group sizes in the output from assignment 1. 

What is the sample size for the rushing group? `r fitb(25, num = T)`

What is the sample size for the reference category? `r fitb(22, num = T)`

With this in mind, what should the weight be for the singing group, on the dummy that codes for membership of the rushing group? `r fitb(-1.136364, num = T, tol = .01)`

Complete the following syntax, then run it:

RECODE behavior (1=1) (2=0) (3=0) (4=0) (5= ...) INTO Erushing.
RECODE behavior (1=0) (2=1) (3=0) (4=0) (5=`r fitb(-1, num = T)`) INTO Estories.
RECODE behavior (1=0) (2=0) (3=1) (4=0) (5=`r fitb(-1.09, num = T, tol = .005)`) INTO Einsulting.
RECODE behavior (1=0) (2=0) (3=0) (4=1) (5=...) INTO Ejokes.
EXECUTE.

Note the correct answer for the effect code for the stories group. Compare the number of people in the stories group and in the reference group. Then recall that I explained that *In a balanced design (with equal sizes for each group), this value is -1.* You see that this is true now, and why.

Calculate the effect indicators, then specify a regression model with these four effect indicators. Make sure to include the intercept again!

`r hide("Check correct syntax")`

```

RECODE behavior (1=1) (2=0) (3=0) (4=0) (5= -1.136364) INTO Erushing.
RECODE behavior (1=0) (2=1) (3=0) (4=0) (5=-1) INTO Estories.
RECODE behavior (1=0) (2=0) (3=1) (4=0) (5=-1.09) INTO Einsulting.
RECODE behavior (1=0) (2=0) (3=0) (4=1) (5=-1.227273) INTO Ejokes.
EXECUTE.


REGRESSION
  /MISSING LISTWISE
  /STATISTICS COEFF OUTS R ANOVA
  /CRITERIA=PIN(.05) POUT(.10)
  /NOORIGIN 
  /DEPENDENT feeling
  /METHOD=ENTER Erushing Estories Einsulting Ejokes.

```
`r unhide()`

Run the syntax. What is the F-value of the model? `r fitb(3.555, num = T, tol = .01)` 

Verify that this is the same value you got before in models with an intercept.

What is the value of the intercept? `r fitb(5.46, num = T, tol = .01)`

Verify that this is identical to the overall mean of the dependent variable.

Which group means differ significantly from the overall mean?

`r longmcq(c("stories", answer = "stories and insulting", "all behaviors", "no behaviors")[sample.int(4)])` 

Using the coefficients table, calculate the mean of the jokes group. What value do you get? `r fitb(5.634, num = T, tol = .01)`

This should be identical to the mean you observed in the previous assignment (using regression to estimate means), and in the first assignment (just computing the means).

## Comparing Groups of Means

Extending the methods above, it is also possible to compare *groups* of means.
For example, we might wonder whether negative behaviors (rushing and insulting) differ significantly from positive behaviors (stories, jokes, and singing).

This approach builds upon the logic of effects coding, where the weights for the reference category were based on the relative sample size of the reference category. This time, however, the weights for the category to be compared to the reference category are *also* based on a sample size.

There are some rules to follow:

1. As with effect coding, the possible values of each indicator variable must sum to 0.
1. As with effect coding, you must account for relative group size. If all groups are of equal size, the math becomes easier but the same principle applies.
1. Each group must be uniquely identified by a particular combination of the contrast variables.

Based on rule 2 above, assume for a moment that we have equal group sizes and want to compare groups 1 and 2 to groups 3, 4, and 5.

Appropriate contrasts would then be (I'm using the letter C to indicate that these are not dummies or effect indicators):

behavior | C1 | C2 | C3 | C4
---------|----|----|----|----
rushing | 1 | 1 | 0 | 0
insulting | 1 | -1 | 0 | 0
telling stories | -$\frac{2}{3}$ | 0 | 2 | 0
making jokes | -$\frac{2}{3}$ | 0 | -1 | 1
singing | -$\frac{2}{3}$ | 0 | -1 | -1

Note that this table meets all the requirements. 

* Each column sums to 0
* There are no duplicate rows
* Every level of behavior is uniquely identified by some combination of contrasts

In this case, we only care about C1; we created C2, C3 and C4 to meet requirement #3. But what do C2-C4 test?

C2 compares the two negative behaviors; C3 compares stories against jokes and singing. C4 compares jokes and singing.

You could also give these contrasts informative names to help remind yourself of their interpretation:

```
RECODE behavior (1=1) (2=-.66666) (3=1) (4=-.66666) (5= -.66666) INTO posVneg.
RECODE behavior (1=1) (2=0) (3=1) (4=0) (5= 0) INTO rushVinsult.
RECODE behavior (1=0) (2=1) (3=0) (4=-.5) (5= -.5) INTO storyVjokesing.
RECODE behavior (1=0) (2=0) (3=0) (4=1) (5= -1) INTO ? .
EXECUTE.
```

What does the final contrast encode? `r mcq(c(answer = "joke", "story",  "pos", "all")[sample.int(4))` versus `r mcq(c(answer = "sing", "joke",  "pos", "all")[sample.int(4))`

Now, we have to account for the relative sample sizes of these groups to ensure that we can interpret the coefficients as the difference between the means of those combinations of groups.




## Adjusting for Multiple Comparisons

In these assignments, we have been conducting many tests.
You have learned that the significance level $\alpha$ indicates the probability of drawing a false-positive conclusion (Type I error).
However, these probabilities add up for multiple tests! So when you perform many tests, you can be in a situation where you have a very high probability of comitting at least one Type I error.

We call the total probability of committing at least one Type I error across multiple tests in the same study the "family-wise" or experiment-wise Type I error. You compute it as:

$P(1+ Type I error) = 1 − (1 − \alpha)^{\text{number of tests}}$

So if we perform 3 comparisons, the probability of committing at least one Type I error is: `r fitb(.14, num = T, tol = .01)`

And if we perform 10 tests? `r fitb(.4, num = T, tol = .01)`

If this makes you uncomfortable - you're not alone! People often seek to maintain a low risk of drawing any false-positive conclusions, and we can do so simply by lowering $\alpha$.

### Bonferroni correction

Bonferroni proposed a simple correction of $\alpha = \alpha_{EW}/m$, where $\alpha_{EW}$ is the desired experiment-wise Type I error rate (e.g., .05), and $m$ is the number of tests.

What alpha level would you use per test if you want to achieve an experiment-wise alpha of .05 and conduct 7 tests? `r fitb(0.007142857, num = T, tol = .001)`

The Bonferroni correction is quite conservative; in other words - although Bonferroni helps you avoid false-positive conclusions, it becomes much harder to detect true effects.

<!-- Tukey's HSD: https://stats.stackexchange.com/questions/610993/the-theory-behind-tukeys-hsd-test -->
<!-- Tukey's HSD: https://real-statistics.com/one-way-analysis-of-variance-anova/unplanned-comparisons/tukey-hsd/ -->

