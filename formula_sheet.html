<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.427">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>formula_sheet</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="formula_sheet_files/libs/clipboard/clipboard.min.js"></script>
<script src="formula_sheet_files/libs/quarto-html/quarto.js"></script>
<script src="formula_sheet_files/libs/quarto-html/popper.min.js"></script>
<script src="formula_sheet_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="formula_sheet_files/libs/quarto-html/anchor.min.js"></script>
<link href="formula_sheet_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="formula_sheet_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="formula_sheet_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="formula_sheet_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="formula_sheet_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">formula_sheet</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="regression-slope" class="level2">
<h2 class="anchored" data-anchor-id="regression-slope">Regression Slope</h2>
<p>When<span class="math inline">\(\beta_1 = 0\)</span>there is no linear relationship between the two variables.</p>
<p></p>
<p><span class="math inline">\(H_o: \beta_1 = 0\)</span></p>
<p><span class="math inline">\(H_a: \beta_1 \neq 0\)</span></p>
<p><strong>Test statistic:</strong></p>
<p><span class="math inline">\(t_{\text{obs}} = \frac{\hat{\beta_1} }{s_{\hat{\beta_1}}} \sim t_{n-2}\)</span>,</p>
<p>where<span class="math inline">\(s_{\hat{\beta_1}} = \frac{s}{s_x\sqrt{n-1}}\)</span></p>
<p>Reject<span class="math inline">\(H_o\)</span>if<span class="math inline">\(|t_{\text{obs}}| \geq t_{\frac{\alpha}{2},{n-2}}\)</span></p>
<p><span class="math inline">\((1-\alpha)100\%\)</span>Confidence Interval for<span class="math inline">\(\beta_1\)</span>:</p>
<p><span class="math inline">\(\hat{\beta_1} \pm t_{\frac{\alpha}{2}, n-2} s_{\hat\beta_1}\)</span></p>
</section>
<section id="measures-of-center" class="level2">
<h2 class="anchored" data-anchor-id="measures-of-center">Measures of Center</h2>
<p>Mean:</p>
<p><span class="math inline">\(\bar{x} = \frac{\sum_{i=1}^{n}x_i}{n} = \frac{x_1 + x_2 + ... + x_n}{n}\)</span></p>
<p>Median:</p>
<ul>
<li>If n is even then <span class="math inline">\(\tilde{x}\)</span> is the mean of the two middle observations</li>
<li>If n is odd then <span class="math inline">\(\tilde{x}\)</span> is the middle observation (50th percentile)</li>
</ul>
</section>
<section id="measures-of-variability" class="level2">
<h2 class="anchored" data-anchor-id="measures-of-variability">Measures of Variability</h2>
<p>Range: <span class="math inline">\(R = x_\text{largest} - x_\text{smallest}\)</span></p>
<p>Variance: <span class="math inline">\(s^2 = \frac{\sum_{i=1}^{n}(x_i - \bar{x})^2}{n-1} = \frac{\sum_{i=1}^{n}x_i^2 - n\bar{x}^2}{n-1}\)</span></p>
<p>Standard deviation: <span class="math inline">\(s = \sqrt{\frac{\sum_{i=1}^{n}(x_i - \bar{x})^2}{n-1}} = \sqrt{\frac{\sum_{i=1}^{n}x_i^2 - n\bar{x}^2}{n-1}} = \sqrt{s^2}\)</span></p>
<p>IQR: <span class="math inline">\(\text{IQR} = \text{Q3} - \text{Q1}\)</span></p>
<p><strong>Method to compute quartiles:</strong></p>
<!-- $\text{Q_{(p)}$ -->
<ul>
<li>Sort data from smallest to largest:<span class="math inline">\(x_{(1)} \leq x_{(2)} \leq ... \leq x_{(n)}\)</span></li>
<li>Compute the number <span class="math inline">\(np + 0.5\)</span></li>
<li>If <span class="math inline">\(np + 0.5\)</span> is an integer, <span class="math inline">\(m\)</span>, then: <span class="math inline">\(\text{Q}_{(p)} = x_{(m)}\)</span></li>
<li>If <span class="math inline">\(np + 0.5\)</span> is not an integer, <span class="math inline">\(m &lt; np + 0.5 &lt; m+1\)</span> for some integer <span class="math inline">\(m\)</span>, then: <span class="math inline">\(\text{Q}_{(p)} = \frac{x_{(m)}+x_{(m+1)}}{2}\)</span></li>
</ul>
<p><strong>Outliers:</strong></p>
<ul>
<li>Values smaller than <span class="math inline">\(\text{Q1} - (1.5 \times \text{IQR})\)</span>are outliers</li>
<li>Values greater than <span class="math inline">\(\text{Q3} + (1.5 \times \text{IQR})\)</span>are outliers</li>
</ul>
</section>
<section id="measures-of-variability-1" class="level2">
<h2 class="anchored" data-anchor-id="measures-of-variability-1">Measures of Variability</h2>
</section>
<section id="discrete-random-variable-and-distributions" class="level2">
<h2 class="anchored" data-anchor-id="discrete-random-variable-and-distributions">Discrete Random Variable and Distributions</h2>
<p>Consider a <strong>discrete</strong> random variable <span class="math inline">\(X\)</span></p>
<p><strong>Probability Mass Function</strong> (pmf):<span class="math inline">\(f(x) = P(X = x)\)</span></p>
<ul>
<li><span class="math inline">\(f(x) \geq 0\)</span> for all <span class="math inline">\(x\)</span> in <span class="math inline">\(X\)</span></li>
<li><span class="math inline">\(\sum_x f(x) = 1\)</span></li>
</ul>
<p><strong>Cumulative Distributive Function</strong> (cdf):</p>
<p><span class="math inline">\(F(x) = P(X \leq x) = \sum_{k \leq x}f(k)\)</span></p>
<p>Mean (<span class="math inline">\(\mu\)</span>): <span class="math inline">\(E(X) = \sum_{x}xf(x)\)</span></p>
<p>Expected value: <span class="math inline">\(E(g(X)) = \sum_{x}g(x)f(x)\)</span></p>
<p>Variance (<span class="math inline">\(\sigma^2\)</span>): <span class="math inline">\(Var(X) = \sum_x (x-\mu)^2f(x) = E(X^2)-[E(X)]^2\)</span></p>
<p>SD (<span class="math inline">\(\sigma\)</span>): <span class="math inline">\(SD(X) = \sqrt{Var(X)}\)</span></p>
</section>
<section id="discrete-random-variable-and-distributions-header" class="level2">
<h2 class="anchored" data-anchor-id="discrete-random-variable-and-distributions-header">Discrete Random Variable and Distributions Header</h2>
at (box.north west) {Discrete Random Variables}; ## Sets and Probability (box){% <strong>Properties of Probability:</strong>
<strong>Conditional Probability:</strong>
<strong>Bayes’ Theorem:</strong> <span class="math inline">\(P(A_i|B)\)</span><span class="math inline">\(= \frac{P(B|A_i)P(A_i)}{\sum_{i=1}^{n}P(A_i)P(B|A_i)}\)</span> &amp;<span class="math inline">\(= \frac{P(B|A_i)P(A_i)}{P(B|A_1)P(A_1) + P(B|A_2)P(A_2)+ . . . + P(B|A_n)P(A_n)}\)</span> \end{tabular} }; ## Sets and Probability Header at (box.north west) {Sets and Probability}; ## Continuous Random Variable and Distributions (box){% Consider a <strong>continuous</strong> random variable<span class="math inline">\(X\)</span><br>
<strong>Probability Density Function</strong> (pdf):<span class="math inline">\(P(a \leq X \leq b) = \int_{a}^{b} f(x) dx\)</span>
<strong>Cumulative Distributive Function</strong> (cdf):<span class="math inline">\(F(x) = P(X \leq x) = \int_{-\infty}^{x} f(t) dt\)</span><br>
Median: <span class="math inline">\(x\)</span>such that<span class="math inline">\(F(x) = 0.5\)</span><br>
<span class="math inline">\(Q_1\)</span>and<span class="math inline">\(Q_3\)</span>: <span class="math inline">\(x\)</span>such that<span class="math inline">\(F(x) = 0.25\)</span>and<span class="math inline">\(x\)</span>such that<span class="math inline">\(F(x) = 0.75\)</span> Mean (<span class="math inline">\(\mu\)</span>): <span class="math inline">\(E(X) = \int^{\infty}_{-\infty} xf(x) dx\)</span><br>
Expected value: <span class="math inline">\(E(g(X)) = \int^{\infty}_{-\infty} g(x)f(x) dx\)</span><br>
Variance (<span class="math inline">\(\sigma^2\)</span>): <span class="math inline">\(Var(X) = \int^{\infty}_{-\infty} (x-\mu)^2f(x) dx = E(X^2)-[E(X)]^2\)</span> SD (<span class="math inline">\(\sigma\)</span>): <span class="math inline">\(SD(X) = \sqrt{Var(X)}\)</span> }; ## Continuous Random Variable and Distributions Header at (box.north west) {Continuous Random Variables}; ## Summarizing Main Features of f(x) (box){% Consider two random variables<span class="math inline">\(X, Y\)</span> <strong>Properties of Probability:</strong>
<strong>Covariance:</strong>
}; ## Summarizing Main Features of f(x) at (box.north west) {Summarizing Main Features of<span class="math inline">\(f(x)\)</span>}; ## Sum and Average of Independent Random Variables (box){% <strong>Sum of Independent Random Variables:</strong><br>
<span class="math inline">\(Y = a_1X_1+a_2X_2+...+a_nX_n\)</span>, for<span class="math inline">\(a_1, a_2,..., a_n \in \mathbb{R}\)</span>
If<span class="math inline">\(n\)</span>random variables<span class="math inline">\(X_i\)</span>have common mean<span class="math inline">\(\mu\)</span>and common variance<span class="math inline">\(\sigma^2\)</span>then,
<strong>Average of Independent Random Variables:</strong><br>
<span class="math inline">\(X_1,X_2,...,X_n\)</span>are<span class="math inline">\(n\)</span>independent random variables
If<span class="math inline">\(n\)</span>random variables<span class="math inline">\(X_i\)</span>have common mean<span class="math inline">\(\mu\)</span>and common variance<span class="math inline">\(\sigma^2\)</span>then,
}; ## Sum and Average of Independent Random Variables at (box.north west) {Sum and Average of Independent Random Variables}; ## Maximum and Minimum of Independent Variables (box){% Given<span class="math inline">\(n\)</span>independent random variables<span class="math inline">\(X_1, X_2,...,X_n\)</span>.<br>
For each<span class="math inline">\(X_i\)</span>, cdf<span class="math inline">\(F_X(x)\)</span>and pdf is<span class="math inline">\(f_X(x)\)</span>.<br>
<strong>Maximum of Independent Random Variables:</strong><br>
Consider<span class="math inline">\(V=max\{X_1, X_2, ... , X_n\}\)</span> <br>
<span class="math inline">\(F_V(v)\)</span><span class="math inline">\(= P(V \leq v) = P(X_1 \leq v, X_2 \leq v,..., X_n \leq v)\)</span> <span class="math inline">\(= P(X_1 \leq v)P(X_2 \leq v)...P(X_n \leq v) = F_{X_1}(v)F_{X_2}(v)...F_{X_n}(v)\)</span> <span class="math inline">\(= [F_X(v)]^n\)</span>; if<span class="math inline">\(X_i\)</span>’s are all identically distributed <br>
<span class="math inline">\(f_V(v)\)</span><span class="math inline">\(= F_V'(v) = \frac{d}{dv}F_V(v) = \frac{d}{dv}[F_X(v)]^n = n[F_X(v)]^{n-1}\frac{d}{dv}F_X(v)\)</span> <span class="math inline">\(= n[F_X(v)]^{n-1}f_X(v)\)</span> <strong>Minimum of Independent Random Variables:</strong><br>
Consider<span class="math inline">\(U=min\{X_1, X_2, ... , X_n\}\)</span> <br>
<span class="math inline">\(F_U(u)\)</span><span class="math inline">\(= P(U \leq u) = 1-P(U&gt;u) = 1-P(X_1&gt;u, X_2&gt;u,...,X_n&gt;u)\)</span> <span class="math inline">\(= 1-P(X_1&gt;u)P(X_2&gt;u)...P(X_n&gt;u)\)</span> <span class="math inline">\(= 1-[1-F_{X_1}(u)][1-F_{X_2}(u)]...[1-F_{X_n}(u)]\)</span> <span class="math inline">\(= 1-[1-F_X(u)]^n\)</span>; if<span class="math inline">\(X_i\)</span>’s are all identically distributed <br>
<span class="math inline">\(f_U(u)\)</span><span class="math inline">\(= F_U'(u) = \frac{d}{du}\{1-[1-F_X(u)]^2\} = 0 - n[1-F_X(u)]^{n-1}\frac{d}{du}(-F_X(u))\)</span> <span class="math inline">\(= n[1-F_X(u)]^{n-1}f_X(u)\)</span> \end{tabular} }; ## Maximum and Minimum of Independent Variables at (box.north west) {Maximum and Minimum of Independent Variables}; ## Some Continuous Distributions (box){% <strong>Uniform Distribution:</strong><span class="math inline">\(X \sim U(a, b)\)</span> Mean: <span class="math inline">\(\mu = E(X) = \frac{a+b}{2}\)</span><br>
Variance: <span class="math inline">\(\sigma^2\)</span>=<span class="math inline">\(Var(X) = \frac{(b-a)^2}{12}\)</span> \end{tabular}
<strong>Exponential Distribution:</strong><span class="math inline">\(X \sim Exp(\lambda)\)</span> Mean: <span class="math inline">\(\mu = E(X) = \frac{1}{\lambda}\)</span><br>
Variance: <span class="math inline">\(\sigma^2\)</span>=<span class="math inline">\(Var(X) = \frac{1}{\lambda^2}\)</span> \end{tabular}
}; ## Some Continuous Distributions Header at (box.north west) {Some Continuous Distributions}; ## Normal Distribution (box){% <strong>Normal Distribution:</strong><span class="math inline">\(X \sim N(\mu, \sigma^2)\)</span> Standardized Normal:<span class="math inline">\(Z \sim N(0, 1)\)</span>where<span class="math inline">\(Z = \frac{X-\mu}{\sigma}\)</span>
}; ## Normal Distribution Header at (box.north west) {Normal Distribution}; ## Bernoulli and Binomial Random Variables (box){% <strong>Bernoulli Random Variable:</strong><br>
Bernoulli random variable<span class="math inline">\(X\)</span>has only two outcomes, success and failure.<br>
<span class="math inline">\(P(Success) = p\)</span>and<span class="math inline">\(P(Failure) = 1 - p\)</span> <strong>Bernoulli Distribution:</strong><br>
<span class="math inline">\(X \sim Bernoulli(p)\)</span> :<span class="math inline">\(P(X=x) = p^x(1-p)^{1-x}\)</span>for<span class="math inline">\(x=0,1\)</span> Mean: <span class="math inline">\(\mu = E(X) = p\)</span><br>
Variance: <span class="math inline">\(\sigma^2 = Var(X) = p(1-p)\)</span> <strong>Binomial Random Variable:</strong><br>
Binomial random variable<span class="math inline">\(X\)</span>is the number of successes for<span class="math inline">\(n\)</span>independent trials and each trial has the same probability of success<span class="math inline">\(p\)</span>.<br>
<strong>Binomial Distribution:</strong><br>
<span class="math inline">\(X \sim Bin(n, p)\)</span> :<span class="math inline">\(P(X=x) = {n \choose x} p^x(1-p)^{n-x}\)</span>for<span class="math inline">\(x=0,1,2,...,n\)</span> :<span class="math inline">\(P(X\leq x) = \sum_{i=0}^{x} {n \choose i} p^i(1-p)^{n-i}\)</span>for<span class="math inline">\(x=0,1,2,...,n\)</span> <span class="math inline">\({n \choose x} = \frac{n!}{x!(n-x)!}\)</span> Mean: <span class="math inline">\(\mu = E(X) = np\)</span><br>
Variance: <span class="math inline">\(\sigma^2 = Var(X) = np(1-p)\)</span> \end{tabular} }; ## Bernoulli and Binomial Random Variables Header at (box.north west) {Bernoulli and Binomial Random Variables}; ## Geometric Distribution and Return Period (box){% <strong>Geometric Random Variable:</strong><br>
Geometric random variable X is the number of independent trials needed until the first success occurs.<br>
<strong>Geometric Distribution:</strong><br>
<span class="math inline">\(X \sim Geo(p)\)</span>where<span class="math inline">\(p\)</span>is the probability of success<br>
:<span class="math inline">\(P(X=x)=p(1-p)^{x-1}\)</span>for<span class="math inline">\(x=1,2,3,...\)</span> :<span class="math inline">\(P(X \leq x)=1-(1-p)^x\)</span>for<span class="math inline">\(x=1,2,3,...\)</span> Mean: <span class="math inline">\(\mu = E(X) = \frac{1}{p}\)</span><br>
Variance: <span class="math inline">\(\sigma^2 = Var(X) = \frac{1-p}{p^2}\)</span> }; ## Geometric Distribution Header at (box.north west) {Geometric Distribution}; ## Poisson Distribution (box){% <strong>Poisson Process:</strong><br>
Random variable X is the number of occurrences in a given interval.<br>
<strong>Poisson Distribution:</strong><br>
<span class="math inline">\(X \sim Poisson(\lambda)\)</span>where<span class="math inline">\(\lambda\)</span>is the rate of occurrences<br>
:<span class="math inline">\(P(X=x)=\frac{\lambda^x e^{-\lambda}}{x!}\)</span>for<span class="math inline">\(x=0,1,2,3,...\)</span> :<span class="math inline">\(P(X\leq x)=\sum_{i=0}^{x}\frac{\lambda^i e^{-\lambda}}{i!}\)</span>for<span class="math inline">\(x=0,1,2,3,...\)</span> Mean: <span class="math inline">\(\mu = E(X) = \lambda\)</span><br>
Variance: <span class="math inline">\(\sigma^2 = Var(X) = \lambda\)</span> \end{tabular}
}; ## Poisson Distribution Header at (box.north west) {Poisson Distribution}; ## Poisson Approximation to the Binomial Distribution (box){% Let<span class="math inline">\(X \sim Bin(n, p)\)</span>be a binomial random variable. If<span class="math inline">\(n\)</span>is large<span class="math inline">\((n \geq 20)\)</span>and<span class="math inline">\(p\)</span>or<span class="math inline">\(1-p\)</span>is small (<span class="math inline">\(np&lt;5\)</span>or<span class="math inline">\(n(1-p)&lt;5\)</span>), then we can use a Poisson random variable with rate<span class="math inline">\(\lambda = np\)</span>to approximate the probabilistic behaviour of<span class="math inline">\(X\)</span>.<br>
<span class="math inline">\(X \sim Poisson(np)\)</span>, approx. for<span class="math inline">\(x=0,1,2,...n\)</span> }; ## Poisson Approximation to the Binomial Distribution Header at (box.north west) {Poisson Approximation to the Binomial Distribution}; ## Central Limit Theorem (box){% Let<span class="math inline">\(X_1\)</span>,<span class="math inline">\(X_2\)</span>,…,<span class="math inline">\(X_n\)</span>be a random sample from an arbitrary population/distribution with mean<span class="math inline">\(\mu\)</span>and variance<span class="math inline">\(\sigma^2\)</span>. When<span class="math inline">\(n\)</span>is large (<span class="math inline">\(n \geq 20\)</span>) then<br>
<span class="math inline">\(\bar{X} = \frac{X_1 + X_2 + ... + X_n}{n} \sim N(\mu, \frac{\sigma^2}{n})\)</span>, approx.<br>
When dealing with sum, the CLT can still be used. Then<br>
<span class="math inline">\(T = X_1 + X_2 + ... + X_n = n\bar{X}\)</span><br>
<span class="math inline">\(T \sim N(n\mu, n\sigma^2)\)</span>, approx. }; ## Central Limit Theorem Header at (box.north west) {Central Limit Theorem}; ## Normal Approximation to the Binomial Distribution (box){% Let<span class="math inline">\(X \sim Bin(n,p)\)</span>. When<span class="math inline">\(n\)</span>is large so that both<span class="math inline">\(np \geq 5\)</span>and<span class="math inline">\(n(1-p) \geq 5\)</span>. We can use the normal distribution to get an approximate answer. Remember to use <strong>continuity correction</strong>.<br>
<span class="math inline">\(X \sim N(np, np(1-p))\)</span>, approx. }; ## Normal Approximation to the Binomial Distribution Header at (box.north west) {Normal Approximation to the Binomial Distribution}; ## Normal Approximation to the Poisson Distribution (box){% Let<span class="math inline">\(X \sim Poisson(\lambda)\)</span>. When<span class="math inline">\(\lambda\)</span>is large (<span class="math inline">\(\lambda \geq 20\)</span>) then the Normal distribution can be used to approximate the Poisson distribution. Remember to use <strong>continuity correction</strong>.<br>
<span class="math inline">\(X \sim N(\lambda, \lambda)\)</span>, approx. }; ## Normal Approximation to the Poisson Distribution Header at (box.north west) {Normal Approximation to the Poisson Distribution}; ## Continuity Correction (box){% Consider continuous random variable<span class="math inline">\(Y\)</span>and discrete random variable<span class="math inline">\(X\)</span>.
}; ## Continuity Correction Header at (box.north west) {Continuity Correction}; ## Point Estimators (box){% Suppose that<span class="math inline">\(X_1\)</span>,<span class="math inline">\(X_2\)</span>,…,<span class="math inline">\(X_n\)</span>are random samples from a population with mean<span class="math inline">\(\mu\)</span>and variance<span class="math inline">\(\sigma^2\)</span>.
}; ## Point Estimators Header at (box.north west) {Point Estimators}; ## Confidence Interval (box){% <strong><span class="math inline">\((1-\alpha)100\%\)</span>Confidence Interval for population mean<span class="math inline">\(\mu\)</span>:</strong> (point estimator of<span class="math inline">\(\mu\)</span>is<span class="math inline">\(\bar{x}\)</span>)<br>
point estimate<span class="math inline">\(\pm\)</span>margin of error<br>
When<span class="math inline">\(\sigma^2\)</span>is <strong>known</strong>:<span class="math inline">\(\bar{x} \pm z_{\frac{\alpha}{2}}\frac{\sigma}{\sqrt{n}}\)</span> When<span class="math inline">\(\sigma^2\)</span>is <strong>unknown</strong>: <span class="math inline">\(\bar{x} \pm t_{\frac{\alpha}{2}, n-1}\frac{s}{\sqrt{n}}\)</span> Typical<span class="math inline">\(z\)</span>values of<span class="math inline">\(\alpha\)</span>:<br>
<span class="math inline">\(\alpha = 0.1\)</span><span class="math inline">\(90\%\)</span><span class="math inline">\(z_{\frac{\alpha}{2}} = z_{0.05} = 1.645\)</span> <span class="math inline">\(\alpha = 0.05\)</span><span class="math inline">\(95\%\)</span><span class="math inline">\(z_{\frac{\alpha}{2}} = z_{0.025} = 1.96\)</span> <span class="math inline">\(\alpha = 0.01\)</span><span class="math inline">\(99\%\)</span><span class="math inline">\(z_{\frac{\alpha}{2}} = z_{0.005} = 2.575\)</span> <strong><span class="math inline">\((1-\alpha)100\%\)</span>Confidence Interval for<span class="math inline">\(\mu_1 - \mu_2\)</span>:</strong><br>
<span class="math inline">\((\bar{x}_1 - \bar{x}_2) \pm t_{\frac{\alpha}{2}, n_1+n_2-2}s_p\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}\)</span> }; ## Confidence Interval Header at (box.north west) {Confidence Interval}; ## Pooled Standard Deviation (box){% Requires assumptions that population variances are equal:<span class="math inline">\(\sigma_1^2 = \sigma_2^2 = \sigma^2\)</span> The pooled standard deviation<span class="math inline">\(s_p\)</span>estimates the common standard deviation<span class="math inline">\(\sigma\)</span>.<br>
<span class="math inline">\(s_p = \sqrt{\frac{(n_1-1)s_1^2+(n_2-1)s_2^2}{n_1+n_2-2}}\)</span> }; ## Pooled Standard Deviation Header at (box.north west) {Pooled Standard Deviation}; ## Testing of Hypotheses about mu (box){% <span class="math inline">\(H_o\)</span>: Null hypothesis is a tentative assumption about a population parameter.<br>
<span class="math inline">\(H_a\)</span>: Alternative hypothesis is what the test is attempting to establish.
<strong>Test Statistic:</strong><br>
Case 1:<span class="math inline">\(\sigma^2\)</span>is <br>
<span class="math inline">\(z=\frac{\bar{x}-\mu_o}{\frac{\sigma}{\sqrt{n}}} \sim N(0,1)\)</span> Case 2:<span class="math inline">\(\sigma^2\)</span>is <br>
<span class="math inline">\(t=\frac{\bar{x}-\mu_o}{\frac{s}{\sqrt{n}}} \sim t_{n-1}\)</span> <strong>Type I and Type II errors:</strong><br>
Type I error: &amp; rejecting<span class="math inline">\(H_o\)</span>when<span class="math inline">\(H_o\)</span>is true<br>
Type II error: &amp; not rejecting<span class="math inline">\(H_o\)</span>with<span class="math inline">\(H_o\)</span>is false<br>
<span class="math inline">\(P(\text{Type I error}) = \alpha\)</span> <span class="math inline">\(P(\text{Type II error}) = \beta\)</span> <strong>Power</strong> is the probability of rejecting<span class="math inline">\(H_o\)</span>, when<span class="math inline">\(H_o\)</span>is false.<br>
<span class="math inline">\(\text{Power} = 1-\beta\)</span> <strong>Comparison of two means:</strong><br>
Two independent populations with means<span class="math inline">\(\mu_1\)</span>and<span class="math inline">\(\mu_2\)</span>.<br>
Assume random samples, normal distributions, and equal variances (<span class="math inline">\(\sigma_1^2 = \sigma_2^2\)</span>).
<strong>Test Statistic:</strong><br>
<span class="math inline">\(t=\frac{(\bar{\chi}_1-\bar{\chi}_2)-\Delta_o}{s_p\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}} \sim t_{n_1+n_2-2}\)</span> <span class="math inline">\(s_p\)</span>is the pooled standard deviation<br>
<strong>Rejection Rules:</strong><br>
Consider test statistic<span class="math inline">\(z\)</span>, and significance value<span class="math inline">\(\alpha\)</span>.
}; ## Testing of Hypotheses about mu Header at (box.north west) {Testing of Hypotheses about<span class="math inline">\(\mu\)</span>}; ## ANOVA (box){% <strong>One-way ANOVA:</strong><br>
<span class="math inline">\(k =\)</span>number of populations or treatments being compared<br>
<span class="math inline">\(\mu_1 =\)</span>mean of population 1 or true average response when treatment 1 is applied.<br>
…<br>
<span class="math inline">\(\mu_k =\)</span>mean of population<span class="math inline">\(k\)</span>or true average response when treatment<span class="math inline">\(k\)</span>is applied.<br>
<strong>Assumptions:</strong>
<strong>Hypotheses:</strong><br>
<span class="math inline">\(H_o: \mu_1 = \mu_2 = ... = \mu_k\)</span> <span class="math inline">\(H_a: \mu_i \neq \mu_j\)</span>for<span class="math inline">\(i \neq j\)</span> <strong>Notation:</strong><br>
<span class="math inline">\(y_{ij}\)</span>is the<span class="math inline">\(j^{th}\)</span>observed value from the<span class="math inline">\(i^{th}\)</span>population/treatment.<br>
Total mean: <span class="math inline">\(\bar{y}_{i\cdot} = \frac{y_{i\cdot}}{n_i} = \frac{\sum_{j=1}^{n_i}y_{ij}}{n_i}\)</span> Total sample size: <span class="math inline">\(n = n_1 + n_2 + ... + n_k\)</span><br>
Grand total: <span class="math inline">\(y_{\cdot\cdot} = \sum_{i=1}^{k}\sum_{j=1}^{n_i}y_{ij}\)</span> Grand mean: <span class="math inline">\(\bar{y}_{\cdot\cdot} = \frac{y_{\cdot\cdot}}{n} = \frac{\sum_{i=1}^{k}\sum_{j=1}^{n_i}y_{ij}}{n}\)</span> <span class="math inline">\(s^2 = \frac{\sum_{j=1}^{k}(n_i-1)s_i^2}{n-k}\)</span>= MSE, where <span class="math inline">\(s_i^2 = \frac{\sum_{j=1}^{n_i}(y_{ij}-\bar{y}_{i\cdot})^2}{n_i-1}\)</span> <strong>The ANOVA Table:</strong> \begin{center} Source of Variation &amp; df &amp; Sum of Squares &amp; Mean Square &amp; F-ratio<br>
Treatment <span class="math inline">\(k-1\)</span>&amp; SSTr &amp; MSTr =<span class="math inline">\(\frac{\text{SSTr}}{k-1}\)</span><span class="math inline">\(\frac{\text{MSTr}}{\text{MSE}}\)</span><br>
Error <span class="math inline">\(n-k\)</span>&amp; SSE &amp; MSE =<span class="math inline">\(\frac{\text{SSE}}{n-k}\)</span>&amp;<br>
Total <span class="math inline">\(n-1\)</span>&amp; SST &amp; &amp;<br>
\end{tabular} \end{center} SST &amp;= SSTr + SSE<br>
SST &amp;=<span class="math inline">\(\sum_{i=1}^{k}\sum_{j=1}^{n_i}(y_{ij}-\bar{y}_{\cdot\cdot})^2 = \sum_{i=1}^{k}\sum_{j=1}^{n_i}y_{ij}^2-\frac{1}{n}y_{\cdot\cdot}^2\)</span> SSTr &amp;=<span class="math inline">\(\sum_{i=1}^{k}\sum_{j=1}^{n_i}(\bar{y}_{i\cdot}-\bar{y}_{\cdot\cdot})^2 = \sum_{i=1}^{k}\frac{1}{n_i}y_{i\cdot}^2-\frac{1}{n}y_{\cdot\cdot}^2\)</span> SSE &amp;=<span class="math inline">\(\sum_{i=1}^{k}\sum_{j=1}^{n_i}(y_{ij}-\bar{y}_{i\cdot})^2= \sum_{i=1}^{k}\sum_{j=1}^{n_i}y_{ij}^2-\sum_{i=1}^{k}\frac{y_{i\cdot}^2}{n_i} = \sum_{i=1}^{k}(n_i-1)s_i^2\)</span> <strong>Test Statistic:</strong><br>
<span class="math inline">\(F_{obs} = \frac{\text{MSTr}}{\text{MSE}} \sim F_{v_1, v_2}\)</span>&amp; <span class="math inline">\(v1 = df(\text{SSTr}) = k-1\)</span> <span class="math inline">\(v2 = df(\text{SSE}) = n-k\)</span> Reject<span class="math inline">\(H_o\)</span>if<span class="math inline">\(F_{obs} \geq F_{\alpha, v_1, v_2}\)</span> }; ## ANOVA Header at (box.north west) {Analysis of Variance (ANOVA)}; ## Covariance and Correlation Coefficient (box){% On a scatter plot, each observation is represented as a point with x-coord<span class="math inline">\(x_i\)</span>and y-coord<span class="math inline">\(y_i\)</span>.<br>
<strong>Sample Covariance:</strong><span class="math inline">\(Cov(x, y)\)</span> <span class="math inline">\(Cov(x,y)\)</span> <span class="math inline">\(=\frac{1}{n-1}\sum_{i=1}^{n}(x_i-\bar{x})(y_i-\bar{y})\)</span> <span class="math inline">\(=\frac{1}{n-1}[\sum_{i=1}^{n}x_iy_i-\frac{\sum_{i=1}^{n}x_i\sum_{i=1}^{n}y_i}{n}]\)</span> <span class="math inline">\(=\frac{1}{n-1}[\sum_{i=1}^{n}x_iy_i-n\bar{x}\bar{y}]\)</span>
<strong>Sample Correlation Coefficient:</strong><span class="math inline">\(r\)</span> <span class="math inline">\(r = \frac{1}{n-1}\sum_{i=1}^{n}(\frac{x_i-\bar{x}}{s_x})(\frac{y_i-\bar{y}}{s_y})\)</span>, where<span class="math inline">\(s_x = \sqrt{\frac{\sum_{i=1}^{n}(x_i-\bar{x})^2}{n-1}}\)</span>and<span class="math inline">\(s_y = \sqrt{\frac{\sum_{i=1}^{n}(y_i-\bar{y})^2}{n-1}}\)</span> <span class="math inline">\(r = \frac{Cov(x,y)}{s_x s_y}\)</span>
<p>}; ## Covariance and Correlation Coefficient Header at (box.north west) {Covariance and Correlation Coefficient}; ## Simple Linear Regression (box){% <strong>Regression Line:</strong><br>
Simple linear regression model:<span class="math inline">\(y = \beta_o + \beta_1x+\varepsilon\)</span> <span class="math inline">\(\beta_o\)</span>,<span class="math inline">\(\beta_1\)</span>, and<span class="math inline">\(\sigma^2\)</span>are parameters,<span class="math inline">\(y\)</span>and<span class="math inline">\(\varepsilon\)</span>are random variables.<span class="math inline">\(\varepsilon\)</span>is the error term.<br>
True regression line:<span class="math inline">\(E(y) = \beta_o + \beta_1x\)</span> Least squares regression line:<span class="math inline">\(\hat{y} = \hat{\beta_o} + \hat{\beta_1}x\)</span> <span class="math inline">\(\hat{y}\)</span>,<span class="math inline">\(\hat{\beta_o}\)</span>, and<span class="math inline">\(\hat{\beta_1}\)</span>are point estimates for<span class="math inline">\(y\)</span>,<span class="math inline">\(\beta_o\)</span>, and<span class="math inline">\(\beta_1\)</span>.<br>
Residual:<span class="math inline">\(\varepsilon_i = y_i - \hat{y_i}\)</span> <span class="math inline">\(\hat{\beta_1} = \frac{\sum_{i=1}^{n}(x_i-\bar{x})(y_i-\bar{y})}{\sum_{i=1}^{n}(x_i-\bar{x})^2} = \frac{\sum_{i=1}^{n}x_iy_i-n\bar{x}\bar{y}}{\sum_{i=1}^{n}x_i^2-n\bar{x}^2} = r\frac{s_y}{s_x}\)</span> <span class="math inline">\(\hat{\beta_o} = \frac{\sum_{i=1}^{n}y_i-\hat{\beta_1}\sum_{i=1}^{n}x_i}{n} = \bar{y} - \hat{\beta_1}\bar{x}\)</span> <strong>Coefficient of Determination:</strong><span class="math inline">\(r^2\)</span> The proportion of observed<span class="math inline">\(y\)</span>variation that can be explained by the simple linear regression model. }; ## Simple Linear Regression Header at (box.north west) {Simple Linear Regression}; ## Estimating Variance (box){% <span class="math inline">\(\hat{\sigma}^2 = s^2 = \frac{\text{SSE}}{n-2} = \frac{\sum_{i=1}^{n}(y_i - \hat{y_i})^2}{n-2}\)</span> <strong>Error Sum of Squares</strong> (SSE):<br>
SSE =<span class="math inline">\(\sum_{i=1}^{n}\varepsilon_i^2 = \sum_{i=1}^{n}(y_i - \hat{y_i})^2 = \sum_{i=1}^{n}[y_i-(\hat{\beta_o}+\hat{\beta_1}x_i)]^2\)</span> SSE is a measure of variation in<span class="math inline">\(y\)</span>left unexplained by linear regression model.<br>
<strong>Total Sum of Squares</strong> (SST):<br>
SST =<span class="math inline">\(\sum_{i=1}^{n}(y_i-\bar{y})^2\)</span> SST is sum of squared deviations about sample mean of observed<span class="math inline">\(y\)</span>values.<br>
<strong>Regression Sum of Squares</strong> (SSR):<br>
SSR =<span class="math inline">\(\sum_{i=1}^{n}(\hat{y_i}-\bar{y})^2\)</span> SSR is total variation explained by the linear regression model.<br>
SST = SSR + SSE<br>
<strong>Coefficient of Determination from SST, SSR, and SSE</strong>:<br>
<span class="math inline">\(r^2 = 1 - \frac{SSE}{SST}\)</span> or<br>
<span class="math inline">\(r^2 = \frac{SSR}{SST}\)</span> }; ## Estimating Variance Header at (box.north west) {Estimating<span class="math inline">\(\sigma^2\)</span>(SLR)}; </p>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>