# Lab 1: Introduction

```{r, include = FALSE}
source("R/booktem_setup.R")
source("R/my_setup.R")
```

## Regression Analysis

In this assignment we will make a start with regression analysis.

We will go through the different steps of running and interpreting a regression analysis.

Open the file [`Work.sav`](data/Work.sav) to get started.

Correlations and regression analyses can both be used to study the relationship between variables, but there is an important difference.

Discuss with your group mates what the similarities and differences between the two methods are.

`r hide("Answer")`
A correlation is a symmetric measure of association, meaning we are agnostic about which is the predictor and which is the outcome (or neither are predictor/outcome). The correlation between X and Y is the same as the one between Y and X.

In regression analysis, we do define an independent and dependent variable. The goal is to predict the outcome using the predictor. Most of the time, this implies an assumption of causality - but not necessarily. 

For example, we can use regression to predict sales based on customer characteristics without assuming that those characteristics CAUSE sales. But if we want to cause an increase in sales, and we look at the regression coefficients to decide where to intervene - then it suddenly matters a lot whether the predictors are causes of sales or not.

You see this a lot with online marketing when you are receiving a lot of adds for a product that you recently bought. Their regression model knows that looking at the product page is a great predictor of intention to buy it - but they don't know that the reason you were looking at that page is because you were already buying it.
`r unhide()`
 
Consider the following research question: “Does variety at work predict emotional pressure?”


What is the dependent variable in this case? `r mcq(c(answer = "Emotional pressure", "Variety at work"))`


To answer the research question, we will run a linear regression analysis.

One of the assumptions of a regression analysis is that the variables show a linear relationship.

Evaluate this assumption for the variables variety at work (scvariety) and emotional pressure (scemoti) using a scatter plot.

To make a scatter plot: Graphs > Legacy Dialogs > Scatter/Dot > Simple Scatter

Is the assumption of linearity met in this case?  `r mcq(c(answer = "Yes", "No"))``

Let's now run the regression analysis.

Analyze > Regression > Linear

Choose the dependent variable (scemoti) and independent variable (scvariety).
Paste and run the syntax.

If you look in the output, you will see that SPSS shows four tables in the output file.

In the table labeled "Model Summary" we can find the R2 value. R2 indicates the total proportion of explained variance in the dependent variable in the model.

What proportion of the variance Emotional pressure (scemoti) is explained by our single predictor Variety at work (scvariety)? `r fitb(.23, num = T, tol = .01)`

Consider the unstandardized Coefficients in the table labeled "Coefficients".

What is the value of the intercept (b0) for the regression line? `r fitb(37.86, num = T, tol = .01)`

How should we interpret the intercept (or "constant") within the context of this analysis?

`r longmcq(c(
answer = "Someone who reports zero Variety at work (meaning a score of 0 on scvariety) has an expected value of 37.863 on Emotional Pressure.",
"The sample average of Emotional Pressure is 37.863.",
"Everyone who reports zero Variety at work (meaning a score of 0 on scvariety) has a value of 37.863 on Emotional Pressure.",
"For every point in Variety at work, we expect an increase of 37.863 in Emotional Pressure.")[sample.int(4)])`

Consider the unstandardized regression coefficients again.

What is the value of the regression coefficient of scvariety on scemoti (b1)? `r fitb(-0.32, num = T, tol = .01)`

How should we interpret the regression coefficient of scvariety within the context of this analysis?

`r longmcq(c(
answer = "If someone’s score on Variety at work increases with 1 point, their score on Emotional pressure decreases by .320 points.",
"The sample average score of Variety at work is .320."
"If someone’s score on Variety at work increases with 1 SD, their score on Emotional pressure decreases by .320 SDs.",
"The sample average of Emotional pressure is .320.")[sample.int(4)])`

The "Coefficients" table also shows whether or not the effect of scvariety on scemoti is significant (i.e. if we can generalize our finding to the population).

What is the p-value for the regression coefficient for scvariety? `r fitb(0, num = T, tol = .01)`
 
Can we conclude that the effect of scvariety on scemoti is significant? (use $\alpha$ = .05). `r mcq(c(answer = "Yes", "No"))`
 
## R squared

In the previous assignment we glanced over the output of the regression analysis.

With the regression coefficients we've interpreted in the previous assignment we've explained what the relationship looks like (i.e. the trend).

However, we don’t know yet the strength of the relationship. On other words, we don't know yet how well we can predict experienced emotional pressure at work with work variety.

To learn more about the strength of the effect we have to look at the value of R2 , which shows the “explained variance”. In the next few steps we will look in more detail at this concept.

Consider the results of the regression model again.

Write down the equation of this regression and use the raw data in the Data View to answer the following question.


What is the predicted value (Y') for emotional pressure at work for the first person in the data file (i.e., the person with respondent number 1)? `r fitb(29.329, num = T, tol = .01)`

What is the prediction error (a.k.a. the residual) for the first person? `r fitb(8.771, num = T, tol = .01)`

Remember Residual = Yobserved - Ypredicted

We've just computed the predicted value and error by hand. It would be very tedious if we would have to do that for all respondents. Fortunately, SPSS offers the option to compute predicted values and errors for all cases for us!

Navigate to Analyze > Regression > Linear

Click on the ‘Save’ button. SPSS opens a new window.

Ask for the Unstandardized predicted values and the unstandardized residuals.
Paste and run the syntax.
 
Let's inspect the Data View in SPSS again and verify that SPSS added two columns in the data file. One column is labeled PRE_1 and the other RES_1. These columns show the predicted values and residuals for each person, respectively.

You may verify this for the first person (i.e., the values should be the same as you computed in the previous steps).

Now we will look at the variance of the observed values of Pleasure at work, the variance of the predicted values of pleasure at work, and variance of the residuals.

Compute the variances of Emotional pressure, as well as for the predicted values of Emotional pressure, and for the residuals.

Navigate to Analyze > Descriptive statistics > Descriptives
Select scemoti, PRE_1, and RES_1.
Click on ‘options’ and ask for the Variance.
Paste and run the syntax.
 
How large is the variance of the observed scores for Emotional pressure? `r fitb(145.168, num = T, tol = .01)`

How large is the variance of predicted values of Work pleasure? `r fitb(33.361, num = T, tol = .01)`


How large is the variance of the residuals? `r fitb(111.807, num = T, tol = .01)`


In the previous questions, we looked at three variance components.


Discuss with your group what the three variances represent.

`r hide("Answer")`
The variance in observed values of Emotional pressure is the total variance in Y (i.e., the dependent variable).
The variance in the predicted values of Emotional pressure reflects “differences in emotional pressure that can be explained because some persons have a job with a lot of variety and some have a monotonous job”. This variance component is also known as the explained variance.
The variance of the residuals, also known as the residual variance, represents differences in emotional pressure that cannot be attributed to differences in variety at work. Hence, the residual describes differences that are unrelated to variety at work.

`r unhide()` 


In the previous step, we looked at the variances itself, but the numbers are not very informative. A more convenient way to look at the explained variance is proportion wise.

So, let's use the variances we just generated to calculate the proportion of variance in Emotional pressure that can be explained by Variety at work.


What percentage of the total variance in emotional pressure can be explained by variety at work? `r fitb(22.981, num = T, tol = .01)`

Consult the output of the regression analysis again, particularly the table Model Summary.

Verify that the R-square that is reported in the table is the same as the proportion of explained variance that you have calculated yourself.

Finally, independently go through all the steps of a simple regression analysis using the data file `Work.sav`.

Your theory suggests that independence at work predicts emotional pressure.

* Construct an appropriate research question and hypotheses.
* Conduct the analysis
* Describe the relationship (i.e., regression coefficient)?
* Discuss the effect size in terms of R2.
* Perform a significance test and report your results
